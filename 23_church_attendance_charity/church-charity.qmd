---
title: "Effect of church on multi-dimensionsal well-being"
subtitle: ""
abstract: |
  Counterfactual Prediction
author: 
  - name: Joseph Bulbulia
    orcid: 0000-0002-5861-2056
    affiliation: Victoria University of Wellington, New Zealand
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: yes
  - name: Authors
    affiliation: Victoria University of Wellington
  - name: Chris G. Sibley
    affiliation: School of Psychology, University of Auckland
    orcid_id: 0000-0002-4064-8800
execute:
  warning: false
  eval: false
keywords:
  - measurement
date: last-modified
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: false

# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23_church_charity"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)
```

```{r}
#| label: clean data
#| echo: false
#| include: false
#| eval: false

# note that religion church NA we impute zero to those who are not religous in the "religion_church2" variable


table(is.na( dat$religion_church)) 
table(is.na( dat$religion_church2)) 

# Note: read this: # create dataframes, one for each level of the factor.  This allows valid multiple imputation see: 
# https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-023-01843-6

dat |> 
  select(ends_with( "siblings")| starts_with("number")) |> 
  colnames()

dat_long <- dat |>
  arrange(id, wave) |>
  mutate(urban = factor(
    ifelse(
      rural_gch2018 == "Medium Urban Accessibility" |
        # Define urban condition
        rural_gch2018 == "High Urban Accessibility",
      "urban",
      # Label 'urban' if condition is met
      "rural"  # Label 'rural' if condition is not met
    )
  )) |>
  # select variables
  # mutate(across(where(is.double), as.numeric)) |>
  mutate(male = as.numeric(male) - 1) |>
  rename(religion_religious = religious) |>  # religious yes/no
  mutate(religion_church_binary = ifelse(religion_church > 0, 1, 0)) |>
  mutate(religion_church_binary2 = ifelse(religion_church2 > 0, 1, 0)) |>
  mutate(religion_religious = as.numeric(religion_religious) - 1) |>
  dplyr::select(
    "wave",
    "year_measured",
    "id",
    # "edu",
    "sample_origin_names_combined",
    # Sample origin names combined
    #"alert_level_combined_lead",  not needed because all receive all levels by the point the outcome is measured
    # covid alert levels -> 2019-2020
    "education_level_coarsen",
    # Ordinal-Rank 0-10 NZREG codes (with overseas school quals coded as Level 3, and all other ancillary categories coded as missing)  Combined highschool levels See:https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf
    "male",
    # 0 = female, 0.5 = neither female nor male, 1 = male.
    "age",
    "born_nz",
    "hlth_disability",
    # value label 0    No 1   Yes
    "eth_cat",
    #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed",
    # Are you currently employed? (this includes self-employment or casual work)
    # "gen_cohort",
    "household_inc",
    # Please estimate your total household income (before tax) for the last year.
    "nz_dep2018",
    # see nzavs materials
    "nzsei13",
    # see nzavs materials
    "partner",
    # 0 = no, 1 = yes
    "parent",
    # 0 = no, 1 = yes
    "pol_orient",
    #Please rate how politically liberal versus conservative you see yourself as being.
    "pol_wing",
    # Please rate how politically left-wing versus right-wing you see yourself as being.
    "urban",
    # see NZAVS,
    "have_siblings", #Do you have siblings?
    "total_siblings",# sum siblings
    "number_sisters_older", #How many older sisters do you have?   
    "number_sisters_younger", #	How many younger sisters do you have? 
    "number_brothers_older",#	How many older brothers do you have?
    "number_brothers_younger", #	How many older brothers do you have?
    "agreeableness",
    # Mini-IPIP6 Agreeableness (also modelled as empathy facet)
    # Sympathize with others' feelings.
    # Am not interested in other people's problems.
    # Feel others' emotions.
    # Am not really interested in others.
    "conscientiousness",
    # see mini ipip6
    # Get chores done right away.
    # Like order.
    # Make a mess of things.
    # Often forget to put things back in their proper place.
    "extraversion",
    # Mini-IPIP6 Extraversion
    # Am the life of the party.
    # Don't talk a lot.
    # Keep in the background.
    # Talk to a lot of different people at parties.
    "honesty_humility",
    # see mini ipip6
    # Would like to be seen driving around in a very expensive car.
    # Would get a lot of pleasure from owning expensive luxury goods.
    # Feel entitled to more of everything.
    # Deserve more things in life.
    "openness",
    # see mini ipip6
    # Have a vivid imagination.
    # Have difficulty understanding abstract ideas.
    # Do not have a good imagination.
    # Am not interested in abstract ideas.
    "neuroticism",
    # see mini ipip6
    # Have frequent mood swings.
    # Am relaxed most of the time.
    # Get upset easily.
    # Seldom feel blue.
    "modesty",
    # see mini ipip6
    # I want people to know that I am an important person of high status,
    # I am an ordinary person who is no better than others.
    # I wouldn’t want people to treat me as though I were superior to them.
    # I think that I am entitled to more respect than the average person is
    # "sdo",
    # "rwa",
    # "brk_relationship",
    # "began_relationship",
    "religion_religious",
    # Do you identify with a religion and/or spiritual group?
    "religion_identification_level",
    #How important is your religion to how you see yourself?"
    "religion_church_binary",
    "religion_church_binary2",
    "religion_prayer",
    # How many times did you pray in the last week?
    "religion_scripture",
    # How many times did you read religious scripture in the last week?
    "religion_church2",
    # How many times did you attend a church or place of worship in the last month?
    "religion_believe_spirit",
    #Do you believe in some form of spirit or lifeforce?
    "religion_believe_god",
    #Do you believe in a God
    "religion_spiritual_identification",
    #w8,w10,w12-13 "I identify as a spiritual person."
    "religion_perceive_religious_discrim",
    #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
    # "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers
    "w_gend_age_euro",
    # sample_weights.
    "vengeful_rumin",
    # Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "gratitude",
    ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of peopl
    "modesty",
    # see above
    "charity_donate",
    #How much money have you donated to charity in the last year?
    "hours_charity",
    #,#Hours spent in activities/Hours spent … voluntary/charitable work
    "warm_asians",
    "warm_chinese",
    #"warm_disabled" ,  missing at time 0
    # begins w9
    "warm_immigrants",
    "warm_indians",
    "warm_elderly",
    # warm_lgbtq starts w12
    "warm_maori",
    "warm_mental_illness",
    "warm_muslims",
    "warm_nz_euro",
    "warm_overweight",
    "warm_pacific",
    "warm_refugees",
    "religion_perceive_religious_discrim",
    # "issue_same_sex_marriage", not in range
     "support", # three items as below
    # "support_help",
    # # 'There are people I can depend on to help me if I really need it.
    # "support_turnto",
    # # There is no one I can turn to for guidance in times of stress.
    # "support_rnoguidance",
    #There is no one I can turn to for guidance in times of stress.
    "family_time",
    "friends_time",
    "community_time",
    "family_money",
    "friends_money",
    "community_money",
    # Received help and support - hours
    # family
    # friends
    # others in my community
    # Received help and support - money
    # family
    # friends
    # others in my community
  )|> 
  dplyr::rename(sample_weights = w_gend_age_euro) |>
  dplyr::filter((wave == 2018 & year_measured  == 1) |
                  (wave == 2019  &
                     year_measured  == 1) |
                  (wave == 2020)) |>  # Eligibility criteria  Observed in 2018/2019 & Outcomes in 2020 or 2021
  group_by(id) |>
  dplyr::mutate(k_18 =  ifelse(wave == 2018 &
                                 !is.na(religion_church_binary2), 1, 0)) |>   # creating an indicator for the first wave
  dplyr::mutate(h_18 = mean(k_18, na.rm = TRUE)) |>   # Hack
  dplyr::mutate(k_19 =  ifelse(
    wave == 2019 &
      year_measured == 1 &
      !is.na(religion_church_binary2),
    1,
    0)) |>   # creating an indicator for the first wave; note that we allow people t
  dplyr::mutate(h_19 = mean(k_19, na.rm = TRUE)) |>  # Hack
  dplyr::filter(h_18 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_19 > 0) |>  # hack to enable repeat of baseline
  dplyr::mutate(
    friends_money = ifelse(friends_money < 0, 0, friends_money), # someone gave neg number
    household_inc_log = log(household_inc + 1)
  ) |> 
  droplevels() |>
  select(-c("h_19", "k_19", "h_18", "k_18")) |>
  data.frame()


## Why we did the conversions -- zero inflation
table(round( log(dat_long$family_money+1), 0))
table(round( log(dat_long$friends_money+1), 0))
table(round( log(dat_long$community_money+1),0))

## Why we did the conversions -- zero inflation
table(round( log(dat_long$family_time+1), 0))
table(round( log(dat_long$friends_time+1), 0))
table(round( log(dat_long$community_time+1),0))


table(round( (dat_long$family_time), 0))
table(round( (dat_long$friends_time), 0))
table(round( (dat_long$community_time),0))

hist(log(dat_long$family_time+1))
hist(log(dat_long$friends_time+1))
hist(log(dat_long$community_time+1))

table(round( log(dat_long$family_money+1), 0))
table(round( log(dat_long$friends_money+1), 0))
table(round( log(dat_long$community_money+1),0))

# try neg binomial
dt_test <- dat_long |> 
  filter(wave == 2018) 
dat_long$religion_religious

table1::table1(data = dt_test, ~ total_siblings | religion_religious)

min( dat_long$family_money, na.rm=TRUE)

m_fam_ps <- glm(family_money ~ religion_church_binary2, data = dt_test, family = poisson)
m_frm_ps <- glm(friends_money ~ religion_church_binary2, data = dt_test, family = poisson)
m_com_ps <- glm(community_money ~ religion_church_binary2, data = dt_test, family = poisson)

m_fam_time_ps <- glm(family_time ~ religion_church_binary2, data = dt_test, family = poisson)
m_frm_time_ps <- glm(friends_time ~ religion_church_binary2, data = dt_test, family = poisson)
m_com_time_ps <- glm(community_time ~ religion_church_binary2, data = dt_test, family = poisson)

m_vol_ps <- glm(hours_charity ~ religion_church_binary2, data = dt_test, family = poisson)
summary(m_vol_ps)

## summary of poisson models.
summary(m_fam_ps)
summary(m_frm_ps)
summary(m_com_ps)

summary(m_fam_time_ps)
summary(m_frm_time_ps)
summary(m_com_time_ps)



dt_18_19_full <- dat_long |>
  mutate(
    religion_church_coarsen = cut(
      religion_church2,
      breaks = c(-Inf, 0, 1, 3.99, Inf),
      labels = c("0", "(0_1]", "(1_4)", "[4,inf]"),
      include.lowest = TRUE,
      right = TRUE
    )
  ) %>% 
  mutate(
    religion_church_coarsen_n = as.numeric(religion_church_coarsen)-1
  )

out <- msm::statetable.msm(round(religion_church_coarsen_n, 0), id, data = dt_18_19_full)

# for a function I wrote to create state tables
state_names <- c("zero", "one", "one_to_four", "four_above")

# transition table

t_tab <- transition_table(out)

cat(t_tab$explanation)
print(t_tab$table, state_names)

# binary

out <- msm::statetable.msm(round(religion_church_binary2, 0), id, data = dt_18_19)

# for a function I wrote to create state tables
#state_names <- c("q_1", "q_2", "q_3", "q_4")

# transition table

t_tab <- transition_table(out)

cat(t_tab$explanation)
print(t_tab$table)


## Check only religious

####################### select religious ############

# sample n
n_unique(dat_long$id)

dt_18_religious_18 <- dt_18_19 %>% 
  filter(wave == 2018 & religion_religious == 1) 

n_unique(dt_18_religious_18$id)

table1::table1(data= dat_long, ~as.factor( religion_religious) |wave)

religious_ids_2018 <- dt_18_religious_18$id

length(religious_ids_2018)

nrow(dt_18_religious_18)

#  select data of these individuals from the entire dataset
dt_18_19_religious <- dt_18_19 %>%
  filter(id %in% religious_ids_2018) %>%  
  mutate(
    religion_church_coarsen = cut(
      religion_church2,
      breaks = c(-Inf, 0, 1, 3.99, Inf),
      labels = c("0", "(0_1]", "(1_4)", "[4,200]"),
      include.lowest = TRUE,
      right = TRUE
    )
  ) %>% 
  mutate(
    religion_church_coarsen_n = as.numeric(religion_church_coarsen)-1
  )

n_unique(dt_18_19_religious$id)

table( dt_18_19_religious$religion_church_coarsen)

table( dt_18_19_religious$religion_church2)


n_unique(dt_18_19_religious)


t_tab <- transition_table(out)

cat(t_tab$explanation)
print(t_tab$table, state_names)

out <- msm::statetable.msm(religion_church_binary2, id, data = dt_18_19_religious)

# transition table

t_tab <- transition_table(out)

cat(t_tab$explanation)
print(t_tab$table, state_names)

#check
n_unique(dat_long$id)


##
dt_18_religious <- dat_long %>% 
  filter(wave == 2018 & religion_religious == 1) 

nrow(dt_18_religious)

# get unique identifiers of these individuals (replace `id` with your actual id variable)
religious_ids <- dt_18_religious$id

#  select data of these individuals from the entire dataset
dat_long_t  <- dat_long %>%
  filter(id %in% religious_ids) %>%  
  mutate(
    religion_church_coarsen = cut(
      religion_church2,
      breaks = c(-Inf, 0, 1, 3.99, Inf),
      labels = c("zero", "one", "less_four", "four_up"),
      include.lowest = TRUE,
      right = TRUE
    )
  ) %>% 
  mutate(
    religion_church_coarsen_n = as.numeric(religion_church_coarsen)-1
  ) |> 
  droplevels() |> 
  arrange(id, wave) |> 
  data.frame()

# check
n_unique(dat_long_t$id)

# check path
push_mods

# only look at vars at baseline
dat_18 <- dat_long_t |> 
  dplyr::filter(wave == 2018)

saveRDS(dat_18, here::here(push_mods, "dat_18"))


# better for imputation
# rename to work with workflow
dat_long_t <- dat_long_t |> 
  mutate( eth_cat = as.integer( eth_cat),
          urban = as.numeric(urban),
          education_level_coarsen = as.integer(education_level_coarsen))


saveRDS(dat_long_t, here::here(push_mods, "dat_long_t"))

dat_long_t <- readRDS(here::here(push_mods, "dat_long_t"))

#check
n_unique(dat_long_t$id)
```





```{r}
#|label: data wrangling for imputatons
# Create wide data frame
baseline_vars = c(
    "male",
    "age",
    # Sample origin names combined
    "education_level_coarsen", # factors
    "eth_cat", #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed", # Are you currently employed? (this includes self-employment or casual work)
    #"gen_cohort", #age
    "nz_dep2018",
    "nzsei13",
    "total_siblings",# added
    "born_nz",  # added 
    "hlth_disability",  # added 
    "household_inc_log", # added: measured with error but OK for imputations
    "partner",
    "parent",
    "pol_orient", #Please rate how politically liberal versus conservative you see yourself as being.
    #"pol_wing", # Please rate how politically left-wing versus right-wing you see yourself as being.
    "sample_origin_names_combined",
    "urban",
    "agreeableness",
    "conscientiousness",
    "extraversion",
    "honesty_humility",
    "openness",
    "neuroticism",
    "modesty", # I want people to know that I am an important person of high status, I am an ordinary person who is no better than others. , I wouldn’t want people to treat me as though I were superior to them. I think that I am entitled to more respect than the average person is.
  #  "religion_religious", # Do you identify with a religion and/or spiritual group?
    #"religion_identification_level", #How important is your religion to how you see yourself?"
    "sample_weights"
)



# check
baseline_vars

exposure_var = c("religion_church_coarsen") # we could construct this after imputation. # "perfectionism_high" to be replace by "perfectionism_coarsen" - do the data wrangling after imputation.


outcome_vars_donate = c(
   "hours_charity",
   "charity_donate"
  )

outcome_vars_warmth = c(
    "warm_asians",
    "warm_chinese",
   # "warm_disabled" , not at time 10
    # begins w9
    "warm_immigrants",
    "warm_indians",
    "warm_elderly",
    # warm_lgbtq starts w12
    "warm_maori",
    "warm_mental_illness",
    "warm_muslims",
    "warm_nz_euro",
    "warm_overweight",
    "warm_pacific",
    "warm_refugees",
    "religion_perceive_religious_discrim"
  )


outcome_vars_support = c(
    "family_time",
    "friends_time",
    "community_time",
    "family_money",
    "friends_money",
    "community_money",
    "support"
)


# data for mice
prep_donate <- create_wide_data_general(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_donate)

str(prep_donate)
nrow(prep_donate)
prep_donate <-data.frame(prep_donate)

prep_warmth <- create_wide_data_general(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_warmth)

str(prep_warmth)
prep_warmth<-data.frame(prep_warmth)



outcome_vars_support

prep_support <- create_wide_data_general(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_support)

str(prep_support)
prep_support<-data.frame(prep_support)


## data for mice
exposure_vars = "t1_religion_church_coarsen"

table(round(prep_support$t2_community_time,0))


# prepare data for mice. We impute within stratums of exposure 
prep_multiple_donate <- create_filtered_wide_dataframes(prep_donate, exposure_vars = exposure_vars) 

prep_multiple_warmth <- create_filtered_wide_dataframes(prep_warmth, exposure_vars = exposure_vars) 

prep_multiple_support <- create_filtered_wide_dataframes(prep_support, exposure_vars = exposure_vars) 

#test 
a <- nrow( prep_multiple_support$zero)
b <- nrow( prep_multiple_support$one)
c <- nrow( prep_multiple_support$less_four)
d <-nrow( prep_multiple_support$four_up)

# check
a + b + c + d == nrow(prep_support)
```





```{r}
#| label: imputations-donate
#| echo: false
#| include: false
#| eval: false

naniar::vis_miss(prep_donate, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_donate)


# impute
mice_donate <- impute_and_combine(prep_multiple_donate, m = 10)

push_mods
# save imputed data
saveRDS(mice_donate,
        here::here(push_mods, "mice_donate"))


mice_donate <- readRDS(here::here(push_mods, "mice_donate"))

mice_donate_c  <- mice::complete(mice_donate, action = 'long', include = TRUE)

mice_donate_c <-mice_donate_c |> select(-c(.id.1, .imp.1))

# check data
skimr::skim(mice_donate_c)

# prepare
row.names(mice_donate_c) <- NULL


mice_donate_mids <- mice_donate_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
        t0_education_level_coarsen = as.factor(t0_education_level_coarsen),
        t0_hours_charity_log =   log(t0_hours_charity+1),# to improve model convergence
        t2_hours_charity_log =   log(t2_hours_charity+1),# to improve model convergence
        t0_charity_donate_log =  log(t0_charity_donate+1), # to improve model convergence
        t2_charity_donate_log =   log(t2_charity_donate+1),# to improve model convergence
        t0_volunteers = as.factor(ifelse(t0_hours_charity > 1,1,0)),
        t2_volunteers = as.factor(ifelse(t2_hours_charity > 1,1,0))) |> 
  select(-t0_hours_charity, -t0_charity_donate) %>%
  dplyr::group_by(.imp) |>
  rowwise() |>
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights & !t2_volunteers, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    t2_hours_charity_log,
    t2_charity_donate_log,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(id, .before = sample_weights)  %>%
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  droplevels() |> 
  as.mids()
  

mice_donate_long <- mice::complete(mice_donate_mids, "long", inc = TRUE)

# rar
skim(mice_donate_long)
table(mice_donate_long$t2_hours_charity_log)
table(mice_donate_long$t2_hours_charity_log_z)

table(mice_donate_long$t2_volunteers)

test <- dat_long |> 
  filter(wave == 2020) |> 
  select(hours_charity) |> 
  mutate(volunteers = ifelse(hours_charity>1, 1, 0))

# save
saveRDS(mice_donate_mids, here::here(push_mods, "mice_donate_mids"))
saveRDS(mice_donate_long, here::here(push_mods, "mice_donate_long"))
```




```{r}
#| label: imputations-warmth
#| echo: false
#| include: false
#| eval: false

naniar::vis_miss(prep_warmth, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_warmth)


# impute
mice_warmth <- impute_and_combine(prep_multiple_warmth, m = 10)

# check
push_mods
# save imputed data
saveRDS(mice_warmth,
        here::here(push_mods, "mice_warmth"))


mice_warmth <- readRDS(here::here(push_mods, "mice_warmth"))

mice_warmth_c  <- mice::complete(mice_warmth, action = 'long', include = TRUE)

mice_warmth_c <-mice_warmth_c |> select(-c(.id.1, .imp.1))

# check data
skimr::skim(mice_warmth_c)

# prepare
row.names(mice_warmth_c) <- NULL

mice_warmth_mids <- mice_warmth_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
mutate(t0_eth_cat = as.factor(t0_eth_cat),
        t0_education_level_coarsen = as.factor(t0_education_level_coarsen)
         )|>
  dplyr::group_by(.imp) |>
  rowwise() |>
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(id, .before = sample_weights)  %>%
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  droplevels() |> 
  as.mids()
  

mice_warmth_long <- mice::complete(mice_warmth_mids, "long", inc = TRUE)

# save
saveRDS(mice_warmth_mids, here::here(push_mods, "mice_warmth_mids"))
saveRDS(mice_warmth_long, here::here(push_mods, "mice_warmth_long"))
```



```{r}
#| label: imputations-support
#| echo: false
#| include: false
#| eval: false

naniar::vis_miss(prep_support, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_support)


# impute
mice_support <- impute_and_combine(prep_multiple_support, m = 10)

# check
push_mods
# save imputed data
saveRDS(mice_support,
        here::here(push_mods, "mice_support"))


mice_support <- readRDS(here::here(push_mods, "mice_support"))

mice_support_c  <- mice::complete(mice_support, action = 'long', include = TRUE)

mice_support_c <-mice_support_c |> select(-c(.id.1, .imp.1))

# check data
skimr::skim(mice_support_c)

# prepare
row.names(mice_support_c) <- NULL

mice_support_mids <- mice_support_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
        t0_education_level_coarsen = as.factor(t0_education_level_coarsen),
        t0_family_time_log =   log(t0_family_time+1),# to improve model convergence
        t2_family_time_log =   log(t2_family_time+1),# to improve model convergence
        t0_friends_time_log =   log(t0_friends_time+1),# to improve model convergence
        t2_friends_time_log =   log(t2_friends_time+1),# to improve model convergence
        t0_community_time_log =   log(t0_community_time+1),# to improve model convergence
        t2_community_time_log =   log(t2_community_time+1),# to improve model convergence
        t0_family_money_log =   log(t0_family_money+1),# to improve model convergence
        t2_family_money_log =   log(t2_family_money+1),# to improve model convergence
        t0_friends_money_log =   log(t0_friends_money+1),# to improve model convergence
        t2_friends_money_log =   log(t2_friends_money+1),# to improve model convergence
        t0_community_money_log =   log(t0_community_money+1),# to improve model convergence
        t2_community_money_log =   log(t2_community_money+1),# to improve model convergence
        t2_family_time_binary = ifelse(t2_family_time > 0, 1, 0),
        t2_friends_time_binary = ifelse(t2_friends_time > 0, 1, 0),
        t2_community_time_binary = ifelse(t2_community_time > 0, 1, 0),
        t2_family_money_binary = ifelse(t2_family_money > 0, 1, 0),
        t2_friends_money_binary = ifelse(t2_friends_money > 0, 1, 0),
        t2_community_money_binary = ifelse(t2_community_money > 0, 1, 0)
  ) |>
  dplyr::select(-t0_family_time, -t0_friends_time, -t0_community_time, -t0_family_money, -t0_friends_money,-t0_community_money) |>  # we only worry about removing unneccessary baseline measures, because  the outcomes will not be used for prediction
  dplyr::group_by(.imp) |>
  rowwise() |>
  dplyr::ungroup() |>
  dplyr::mutate(
    across(
      where(is.numeric) & !sample_weights & 
        !t2_family_time_binary &
        !t2_friends_time_binary &
        !t2_community_time_binary &
        !t2_family_money_binary &
        !t2_friends_money_binary &
        !t2_community_money_binary,
      ~ scale(.x),
      .names = "{col}_z"
    )
  ) %>%
  select(-c(.imp_z, .id_z)) %>%
  select(
    where(is.factor),
    sample_weights,
      t2_family_time_binary,
      t2_friends_time_binary, 
      t2_community_time_binary, 
      t2_family_money_binary,
      t2_friends_money_binary, 
      t2_community_money_binary,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(id, .before = sample_weights)  %>%
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  droplevels() |> 
  as.mids()
  

mice_support_long <- mice::complete(mice_support_mids, "long", inc = TRUE)

skim(mice_support_long)

table(mice_support_long$t2_family_time_binary)
table(mice_support_long$t2_friends_time_binary)
table(mice_support_long$t2_community_time_binary)

# save
saveRDS(mice_support_mids, here::here(push_mods, "mice_support_mids"))
saveRDS(mice_support_long, here::here(push_mods, "mice_support_long"))
```



```{r}
#| label: models-donate-cat
#| eval: false

mice_donate_mids <- readRDS(here::here(push_mods, "mice_donate_mids"))

# longform data if necessary
mice_donate_long <- readRDS(here::here(push_mods, "mice_donate_long"))

# check
skim(mice_donate_long)


mice_social_long$t1_religion_church_coarsen
# Set exposure 
X <- "t1_religion_church_coarsen"

baseline_vars_donate = mice_donate_long |> 
  dplyr::select(starts_with("t0"))|> colnames() # strange to include these -- as they  are income by other names

baseline_vars_donate
outcome_vars_donate = mice_donate_long |> dplyr::select(starts_with("t2")) |> colnames()

outcome_vars_donate

estimand = "ATE"
# ebalance
mice_donate_ebal <- match_mi_general(data = mice_donate_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_donate, 
                                 estimand = estimand,  
                                # focal = "zero",
                                 method = "ebal", 
                                 sample_weights = "sample_weights")
saveRDS(mice_donate_ebal, here::here(push_mods, "mice_donate_ebal"))

# summary
sum_ebal <- summary(mice_donate_ebal)
sum_ebal

plot(sum_ebal)
bal.tab(mice_donate_ebal)

# if trim is needed
mice_donate_ebal_trim <- WeightIt::trim(mice_donate_ebal, at = .99)
sum_ebal_trim <- summary(mice_donate_ebal_trim)
sum_ebal_trim

plot(sum_ebal_trim)
bal.tab(mice_donate_ebal_trim,stats = c("m", "ks"), abs = TRUE)
love.plot(mice_donate_ebal_trim, binary = "std", thresholds = c(m = .1))

# settings 
 dt_donate = mice_donate_ebal_trim
# cores
cl =  parallel::detectCores () 
cores =  parallel::detectCores () 
#levels(dat_long_t$religion_church_coarsen)
nsims = 1000

#check
treat_0 = "zero"
#check
treat_1 = "four_up" 
 


### Model by hand
X
Y = "t2_charity_donate_log_z"
Y = "t2_hours_charity_log_z"

#formula_str_A <- paste(X, "~", paste(baseline_vars_health, collapse = "+"))
formula_str_Y <- paste(Y, "~", X , "*", "(", paste(baseline_vars_donate, collapse = "+"), ")")

# check
formula_str_Y

fits <- lapply(complete(dt_donate, "all"), function(d) {
  glm(formula_str_Y, data = d,
      family = gaussian,
      weights = weights
     )
})
pool(fits) |> summary() |> select(term, estimate, std.error)

sim.imp <- misim(fits, n = 100, vcov = "HC")

sim.att <- sim_ame(sim.imp, var = X,
                   subset = t1_religion_church_coarsen == treat_1, cl = 4,
                   verbose = TRUE)


est_1 <- transform(sim.att, RD = `E[Y(four_up)]` - `E[Y(zero)]`)

sum_mod <- summary( est_1, level = .9)
sum_mod

plot(sim.att ,  ci = TRUE, level = .95, reference = FALSE, method = "wald")



treat_0
treat_1


### Models 

mod_donate_volunteer_RR  <- gcomp_sim(
  df = dt_donate,  # note change
  Y = "t2_volunteers",
  X = X, 
  baseline_vars = 1,# baseline_vars_donate,# will not converge
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RR",
  type = "RR",
  nsims = nsims,
  cores = cores,
  family = quasibinomial(),
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "Volunteers_y/n",
  vcov ="HC"
)

mod_donate_volunteer_RR
saveRDS(mod_donate_volunteer_RR, here::here(push_mods, "mod_donate_volunteer_RR"))

############


mod_hours_charity_RD  <- gcomp_sim(
  df = dt_donate,  # note change
  Y = "t2_hours_charity_log_z",
  X = X,
  baseline_vars = baseline_vars_donate,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  type = "RD",
  nsims = nsims,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = "HC",
  new_name = "Hours Volunteer (log_z)"
)
mod_hours_charity_RD

# save model
saveRDS(mod_hours_charity_RD, here::here(push_mods, "mod_hours_charity_RD"))






mod_donate_charity_RD  <- gcomp_sim(
  df = dt_donate,  # note change
  Y = "t2_charity_donate_log_z",
  X = X,
  baseline_vars = baseline_vars_donate,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  type = "RD",
  nsims = nsims,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = "HC",
  new_name = "charity_donate(log_z)"
)
mod_donate_charity_RD

# save model
saveRDS(mod_donate_charity_RD, here::here(push_mods, "mod_donate_charity_RD"))



mod_donate_volunteer_RD  <- gcomp_sim(
  df = dt_donate,  # note change
  Y = "t2_volunteers",
  X = X,
  baseline_vars = baseline_vars_donate,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RR",
  type = "RR",
  nsims = 50,
  cores = cores,
  family = quasibinomial(),
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "Volunteers_y/n",
  vcov ="HC"
)



# DOES NOT CONVERGE
mod_donate_volunteer_RR  <- gcomp_sim(
  df = dt_donate,  # note change
  Y = "t2_volunteers",
  X = X,
  baseline_vars = baseline_vars_donate,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RR",
  type = "RR",
  nsims = 50,
  cores = cores,
  family = quasibinomial(),
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "Volunteers_y/n",
  vcov ="HC"
)



mod_donate_volunteer_RR 
group_tab_social <- group_tab(tab_social, type = "RD")
# save model
saveRDS(mod_social_volunteers_RR, here::here(push_mods, "mod_social_volunteers_RR"))


tab_social <- rbind(
 # mod_social_belong,
 # mod_social_support,
  mod_social_permeability_individual,
  mod_social_impermeability_group,
  mod_social_neighbourhood_community,
  mod_social_support_help,
  mod_social_support_turnto,
  mod_social_support_rnoguidance,
  mod_social_belong_accept,
  mod_social_belong_routsider,
  mod_social_belong_beliefs,
  mod_social_charity_donate
)

tab_social


group_tab_social <- group_tab(tab_social, type = "RD")

group_tab_social

saveRDS(group_tab_social, here::here(push_mods, "group_tab_social"))

group_plot_ate_social <- group_plot_ate(
  group_tab_social,
  type = "RD",
  title = "ATE: causal contrast:second to fourth quartile of extraversion", 
  subtitle = "Social Outcomes",
  xlab = "(sd units)",
  ylab = "test",
  x_offset = -.7,
  x_lim_lo = -.7,
  x_lim_hi = .3
)
group_plot_ate_social

ggsave(
  group_plot_ate_social,
  path = here::here(here::here(push_mods, "group_plot_ate_social")),
  width = 8,
  height = 4,
  units = "in",
  filename = "group_plot_ate_social.png",
  device = 'png',
  limitsize = FALSE,
  dpi = 600
)

```



