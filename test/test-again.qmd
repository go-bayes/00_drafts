---
title: "Better causal diagrammes (DAGS) for counterfactual data science"
author:
  - name: Joseph A. Bulbulia
orcid: 0000-0002-5861-2056
affiliation: Victoria University of Wellington, New Zealand
email: joseph.bulbulia@vuw.ac.nz
corresponding: yes
date-format: short
format:
  html:
    html-math-method:
      method: mathjax
execute:
  warning: false
  eval: true
  echo: false
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: false

# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23_perfectionism_ken"
  )
```

## Abstract

## Introduction

$$A \coprod Y(a)$$
$$A \cancel{\coprod} Y(a)| L$$

### Objective

Correlation is not causation. However, across many human sciences, persistent confusion in the analysis and reporting of correlations has limited scientific progress. The correlations in observed data are frequently biased indicators of causality. This problem is widely known. Nevertheless, many researchers report correlations using hedging language that may suggest causation. Widespread practices of reporting correlations -- in which I have regrettably participated -- has led to a "causality crisis" [@bulbulia2022]. The problem is a crisis, because we cannot generally estimate causal effects from observational data. Widely adopted strategies for "control" fail. Addressing the causality crisis is arguably among science's most pressing issues.

When integrated into methodologically rigorous workflows, causal diagrammes or causal directed acyclic graphs -- causal "DAGs" -- may be powerful tools for identifying causation.[^1] Yet unscrupulous DAGs operate in much the same way as hedging correlational language, suggesting entitlement to causal inferences where none are warrented. For example, when researchers lack time-series data they cannot generally estimate unbiased causal effects[@vanderweele2015]. Thus, cross-sectional researchers who use DAGs to report the unrealistic assumptions embedded in their analyses use the tool to disguise unwarrented confidence. Ideally causal diagrammes would be equipped with safety mechanisms that prevent such self-inflicted injuries.

[^1]: The term "DAG" is unfortunate because not all directed acyclic graphs are causal. For a graph to be causal it must satisfy the conditions of markov factorisation (see Appendix A). In my utopia, I would preferred that causal diagrammes were called markov factorisation graphs (see Appendix A).

Here, I develop a guide to writing causal diagrammes that is grounding in temporally ordered representations of their key elements -- what might be called *chronologically conscientious* causal DAGs. We shall see that attention to temporal order in the spatial organisation of a DAG may greatly assist researchers in avoiding the pitfalls of unscrupulous DAGs. Although no inferential tool is user-proof, the application of chronologically conscientious DAGs may improve saftey. Chronologically conscientious causal diagrammes are DAGs with airbags.

There are many excellent resources for drawing causal diagrammes [@rohrer2018; @hernan2023; @cinelli2022; @barrett2021; @mcelreath2020].[^hernan_course] One may reasonably question whether another tutorial merely adds clutter. The approach to drawing causal diagrammes that I present hopes to contributes to previous attempts in five ways. First, I link graphs to the counterfactual frameworks that are necessary for conceptualising causality. Second, as mentioned, I underscore the importance of chronology in the presentation of the graph. Along the way, I use causal graphs to examine the concepts of interaction and mediation, again with the aim of guiding applied researchers clear of trouble. Third, I show how causal diagrammes to recommend a three-wave panel design for recording cultural evolutionary dynamics in the present. Fourth, I consider the problem of selection bias three-wave panel designs, and develop recommendations for applied researchers. Fifth, I consider the problem of measurement bias in three-wave panel designs, and develop recommendations for applied researchers. I conclude with a brief compendium of practical advice to help researchers avoid abominable DAGs and causal inferences.
 
[^hernan_course]: In my view, currently the best resource is Miguel Hernan's free course, here: [https://pll.harvard.edu/course/causal-diagrams-draw-your-assumptions-your-conclusions](https://pll.harvard.edu/course/causal-diagrams-draw-your-assumptions-your-conclusions).

The article is organised as follows:

**Part 1.** develops the connection between causal diagrammes and the potential outcomes framework. Understanding this connection is important. Whereas causal diagrammes help researchers to answer questions, we must first understand how to ask causal questions. Without such comprehension, causal graphs can be, at best, unproductive, and at worst, deceptive.

**Part 2.** reviews the four elemental types of confounding, and uses chronologically conscientious causal diagrammes to elucidate their properties. Although this discussion replicates material from other tutorials, by emphasising the temporal order in spatial structure of the graph the conditions in which we may identify causality in the presence of confounding become more apparent. Here, I show how causal graphs may clarify concepts of interaction, mediation, and treatment-confounder feedback of the kind we may expect to be pervasive time-series data. Finally, I describe a simple template that may be useful for evolutionary human scientists, which clarifies how three-waves of data collection may be used to estimate causal effects.

**Part 3.** Applies chronologically conscientious causal diagrammes to motivate three-wave panel designs for evolutionary social sciences


**Part 4**  Addresses substanative problems of selection bias, focussing attention on the imperatives for adequate sampling and retention in the three-wave panel design.

**Part 5.** Addresses substanative problems of measurement error, focussing attention on the imperatives of (a) ensuring good measures (b) assessing pathways for confounding (c) performing sensitivity analyses.

 Technical details are presented in an Appendix.

## Part 1. Identifiability assumptions

Causal diagrammes are powerful tools for answering causal questions. However before we can answer a causal question, we must first understand what is involved when we ask a causal question. In this section I review key concepts and identification assumptions.

### The fundamental problem of causal inference

We say that $A$ causes $Y$ if changing $A$ would have made a difference to the outcome of $Y$. The use of the subjective "would have" reveals the need for counterfactuals when conceiving of causal effects. To infere a causal effect requires *counterfactual data-science*.

Suppose there is evidence that cultures believing in Big Gods demonstrate greater social complexity. We are interested in estimating the causal effect of belief in Big Gods on social complexity. Here, the belief in Big Gods is the "exposure" or "treatment" of interest.

We define two counterfactual (or "potential") outcomes for each culture in a population:

-   $Y_i(a = 1)$: The social complexity of culture $i$ if they believed in Big Gods. This is the counterfactual outcome when $A_i = 1$.
-   $Y_i(a = 0)$: The social complexity of culture $i$ if they did not believe in Big Gods. This is the counterfactual outcome when $A_i = 0$.

Within a counterfactual framework, the causal effect of belief in Big Gods on social complexity for culture $i$ may be defined as a contrast, on the difference scale, between two potential outcomes ($Y_i(a)$) under the two different levels of the exposure ($A_i = 1$ (belief in Big Gods); $A_i = 0$ (no belief in Big Gods)). For simplicity we assume these exposures are exhaustive, and well-defined. Under these assumptions:

$$
\text{Causal Effect of Belief in Big Gods}_i = Y_i(1) - Y_i(0) 
$$

We require a contrast between two states of the world only one of which the culture might actually receive [^2]. When the culture receives one level of the belief in Big Gods the outcome under the other level(s) is ruled out by the natural order. The same holds for groups of cultures who are exposed or unexposed. This is called "the fundamental problem of causal inference" [@rubin1976; @holland1986]. As shown in @tbl-consistency, at least half the counterfactual outcomes we require for estimating individual causal effects are missing. For this reason, causal inference has been described as a missing data problem [@westreich2015; @edwards2015].

[^2]:The counter-factual outcome under the exposure $A = a$ may be written in different ways, such as $Y(a)$ (the notation we use here), $Y^a$, and $Y_a$.

@tbl-consistency expresses the relationship between observable and counterfactual outcomes as a contingency table (This table is modified from a table in [@morgan2014]).

```{r }
#| echo: false
#| code-fold: true
#| warnings: false
#| message: false
#| label: tbl-consistency
#| tbl-cap: Causal estimation as a missing data problem.

library(tidyverse)
library(knitr)
library(kableExtra)

# create data frame
my_data <- tibble(
  Group = c(
    "Y(1)",
    "Y(0)"
  ),
  "Units that receive exposure (A=1)" = c("Observable", "Counterfactual"),
  "Units that recieve no exposure (A=0)" = c("Counterfactual", "Observable"),
)

# create table 
my_data %>%
  kbl(format = "markdown")

```



```{tikz}
#| label: fig-dag-mediation-assuptions
#| fig-cap: "Assumptions for mediation analysis"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [rectangle, draw=black] (L1) at (0, 2) {L1$_{t0}$};
\node [rectangle, draw=black] (L3) at (0, -2) {L3$_{t0}$};
\node [ellipse, draw=white] (A) at (3, 0) {A$_{t1}$};
\node [rectangle, draw=black](L2) at (6, -2) {L2$_{t2}$};
\node [rectangle, draw=white](M) at (9, 0) {M$_{t2*}$};
\node [rectangle, draw=white](Y) at (12, 0) {Y$_{t3}$};


\draw [-latex, draw=brown] (L1) to (A);
\draw [-latex, draw=brown, bend left] (L1) to (Y);
\draw [-latex, draw=green] (L3) to (A);
\draw [-latex, draw=green] (L3) to (M);
\draw [-latex, draw= gray, dashed] (A) to (M);
\draw [-latex, draw= gray, dashed, bend left] (A) to (Y);
\draw [-latex, draw=red] (A) to (L2);
\draw [-latex, draw=blue] (L2) to (M);
\draw [-latex, draw=blue] (L2) to (Y);
\draw [-latex, draw= gray, dashed] (M) to (Y);

\end{tikzpicture}

```




