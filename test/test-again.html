<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Better causal diagrammes (DAGS) for counterfactual data science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="test-again_files/libs/clipboard/clipboard.min.js"></script>
<script src="test-again_files/libs/quarto-html/quarto.js"></script>
<script src="test-again_files/libs/quarto-html/popper.min.js"></script>
<script src="test-again_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="test-again_files/libs/quarto-html/anchor.min.js"></script>
<link href="test-again_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="test-again_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="test-again_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="test-again_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="test-again_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Better causal diagrammes (DAGS) for counterfactual data science</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "/Users/joseph/GIT/00_drafts"</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dag-coarsen-measurement-error-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig-dag-coarsen-measurement-error-3-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Where there are many indicators of a psychological construct, there are many opportunities for additional confounding by directed measureemnt error.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="how-controlling-for-baseline-measures-mitigates-against-correlated-measurement-errors" class="level2">
<h2 class="anchored" data-anchor-id="how-controlling-for-baseline-measures-mitigates-against-correlated-measurement-errors">How controlling for baseline measures mitigates against correlated measurement errors</h2>
<p>Controlling for a baseline measure of the exposure and the outcome is essentially controlling for potential confounding caused by any time-invariant characteristics that might influence both the exposure and the outcome. Such confounding is suppressed because any effect of these characteristics on the outcome is supposed to be the same at baseline and at follow-up, assuming no interaction with time.</p>
<p>When it comes to measurement error, the situation is somewhat different. If the exposure and outcome are both measured with error, and the errors are correlated, this would typically introduce bias in our estimate of the causal effect. We have seen that if this this error is systematic and non-differential, it may lead to an attenuation of the estimated causal effect.</p>
<p>Including baseline measurements of the exposure and outcome in our model can, in theory, help mitigate this bias. This is because the model would, in effect, be using the change in the exposure and outcome from baseline to follow-up to estimate the causal effect. If the measurement error is consistent across time (i.e., it is a constant amount or a constant proportion of the true value), then using these change scores could help to control for it.</p>
<p>However, this assumes that the measurement error has no directionality and is not differential with respect to time. If the measurement error varies over time or in relation to other variables in the model, then controlling for baseline measurements may not fully correct for it.</p>
<p>Here is a simple mathematical representation of the conditions. Let <span class="math inline">\(A_0\)</span>, <span class="math inline">\(A_1\)</span> denote the exposure at baseline and follow-up, and let <span class="math inline">\(Y_0\)</span>, <span class="math inline">\(Y_1\)</span> denote the outcome at baseline and follow-up. The true values are denoted without primes, and the measured values with primes. We assume the measurement error is additive:</p>
<p><span class="math inline">\(A'_0 = A_0 + U_0\)</span>,</p>
<p><span class="math inline">\(A'_1 = A_1 + A_1\)</span>,</p>
<p><span class="math inline">\(Y'_0 = Y_0 + V_0\)</span>,</p>
<p><span class="math inline">\(Y'_2 = Y_2 + V_2\)</span>,</p>
<p>where <span class="math inline">\(U_0\)</span>, <span class="math inline">\(U_1\)</span> are the measurement errors for the exposure at baseline and follow-up, and <span class="math inline">\(V_0\)</span>, <span class="math inline">\(V_2\)</span> are the measurement errors for the outcome at baseline and follow-up. If the errors are correlated, then <span class="math inline">\(Cov(U_0, V_0) \neq 0\)</span> and/or <span class="math inline">\(Cov(U_1, V_2) \neq 0\)</span>.</p>
<p>In a model that includes <span class="math inline">\(A'_0\)</span> and <span class="math inline">\(Y'_0\)</span> as covariates, the estimated effect of <span class="math inline">\(A'_1\)</span> on <span class="math inline">\(Y'_2\)</span> is essentially the estimated effect of the change in the exposure from baseline to follow-up on the change in the outcome from baseline to follow-up, controlling for the baseline measures. This will mitigate the bias arising from to correlated errors if the following conditions hold:</p>
<p><span class="math inline">\(E(U_0) = E(U_1)\)</span> and <span class="math inline">\(E(V_0) = E(V_2)\)</span> (i.e., the expectation of the measurement errors does not change over time),</p>
<p><span class="math inline">\(Cov(U_0, V_2) = Cov(U_1, V_2)\)</span> (i.e., the correlation between the errors does not change over time).</p>
<p>If these conditions do not hold, then the bias may not be fully controlled for, and other methods may be needed.</p>
<p>This has assumed that the measurement errors are additive and have no directionality. If the errors are multiplicative or have some other form, or if they vary with the level of the true values or with other variables in the model, then this analysis may not apply.</p>
<section id="casual-diagrams-clarify-the-structural-assumptions-underlying-classical-measurement-theory" class="level3">
<h3 class="anchored" data-anchor-id="casual-diagrams-clarify-the-structural-assumptions-underlying-classical-measurement-theory">Casual diagrams clarify the structural assumptions underlying classical measurement theory</h3>
<p>Researchers working in cultural evolution often incorporate multi-item constructs into their panel study designs, a practice which is aligned with the recommendations of conventional psychometric theory. However, classical psychometric theory emerged devoid of causal theories, and as noted by Tyler VanderWeele, issues arise when evaluating the causal assumptions of formative and reflective models <span class="citation" data-cites="vanderweele2022">(<a href="#ref-vanderweele2022" role="doc-biblioref">Tyler J. VanderWeele 2022a</a>)</span>. This discussion will summarise these issues and expand on how they manifest in repeated measures research.</p>
<p>There are two prevailing approaches in this area: formative and reflective models. The focus here will be on reflective models, though it should be noted that the issues identified also apply to formative models, as outlined by VanderWeele [<span class="citation" data-cites="vanderweele2022">Tyler J. VanderWeele (<a href="#ref-vanderweele2022" role="doc-biblioref">2022a</a>)</span>]<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In a reflective model, researchers posit that a latent variable gives rise to the observed indicators. Each observed variable (or indicator) is seen as a ‘reflection’ or manifestation of the latent variable. If <span class="math inline">\(X_i\)</span> is an observed variable (indicator), <span class="math inline">\(\lambda_i\)</span> is the factor loading for <span class="math inline">\(X_i\)</span>, <span class="math inline">\(\eta\)</span> is the latent variable, and <span class="math inline">\(\varepsilon_i\)</span> is the error term associated with <span class="math inline">\(X_i\)</span>, the reflective model can be formulated as:</p>
<p><span class="math display">\[X_i = \lambda_i \eta + \varepsilon_i\]</span></p>
<p>Factor analysis typically assumes a common latent variable, which is responsible for the correlations observed among the indicators. The causal assumptions linked to this concept are demonstrated in Figure <a href="#fig-dag-latent-1">Figure&nbsp;2</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dag-latent-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig-dag-latent-1-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Reflective model: assume univariate latent variable η giving rise to indicators X1…X3. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434</figcaption>
</figure>
</div>
</div>
</div>
<p>The statistical implications of the <strong>reflective model</strong> suggest that the observed variables (indicators) are reflections or manifestations of the latent variable, which is mathematically expressed as <span class="math inline">\(X_i = \lambda_i \eta + \varepsilon_i\)</span>. The factor analytic tradition goes one step further by proposing a structural assumption that a univariate latent variable causally affects the observed variables. Hence, the reflective model yields <span class="math inline">\(X_i = \lambda_i \eta + \varepsilon_i\)</span>, which is assumed to underpin the structural assumptions shown in Figure <a href="#fig-structural-assumptions-reflective-model">Figure&nbsp;3</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-structural-assumptions-reflective-model" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig-structural-assumptions-reflective-model-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Reflective Model: causal assumptions. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434</figcaption>
</figure>
</div>
</div>
</div>
<p>VanderWeele contends that while the statistical model <span class="math inline">\(X_i = \lambda_i \eta + \varepsilon_i\)</span> concurs with the structural assumptions in Figure <a href="#fig-structural-assumptions-reflective-model">Figure&nbsp;3</a>, it can also align with various causal models. For instance, the statistical model is compatible with the depiction in Figure <span class="citation" data-cites="fig_dag_multivariate_reality_again">(<a href="#ref-fig_dag_multivariate_reality_again" role="doc-biblioref"><strong>fig_dag_multivariate_reality_again?</strong></a>)</span>, where unique latent variables give rise to distinct indicators, some of which (but not necessarily all) have a causal effect on the outcome. The statistical model does not provide clarity on which structural model is accurate. Additionally, the assumption that a univariate underlying reality forms the basis of the formative and reflective latent factor models, which is more robust than previously acknowledged in psychometric literature, fails to withstand empirical scrutiny for certain frequently used measures <span class="citation" data-cites="vanderweele2022b">(<a href="#ref-vanderweele2022b" role="doc-biblioref">Tyler J. VanderWeele and Vansteelandt 2022</a>)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig_dag_multivariate_reality_again-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Multivariate reality gives rise to the indicators, from which we draw our measures. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434</figcaption>
</figure>
</div>
</div>
</div>
<p>VanderWeele suggests that construct measures can still be utilised in applied research by extending the theory of causal inference under multiple interventions to factor models <span class="citation" data-cites="vanderweele2022a">(<a href="#ref-vanderweele2022a" role="doc-biblioref">Tyler J. VanderWeele 2022b</a>)</span> (for a detailed discussion, refer to Appendix 2).</p>
<p>By expressing our measured variables as functions of indicators, and assuming the true underlying reality as a coarsened measure of a potentially complex latent reality, we can consistently estimate causal effects under this extended theory. This approach is illustrated in <a href="#fig-dag-multiple-version-treatment-applied-measurement">Figure&nbsp;4</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dag-multiple-version-treatment-applied-measurement" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig-dag-multiple-version-treatment-applied-measurement-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Multiple Versions of treatment applied to measuremen.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="measurement-error-and-construct-measures" class="level3">
<h3 class="anchored" data-anchor-id="measurement-error-and-construct-measures">Measurement Error and Construct Measures</h3>
<p>Consider a three wave panel where, for simplicity, we assume no unmeasured confounding is present. Our exposure <span class="math inline">\(A\)</span> can be measured by a function of indicators, denoted as <span class="math inline">\(A_{f(A_1, A_2, ..., A_n)}\)</span>, forming a coarsened state from a multivariate reality. Each element of this reality has a corresponding structural component, denoted as <span class="math inline">\(\eta_{A_1}, \eta_{A_2}, ..., \eta_{A_n}\)</span>. These components are measured with their respective error terms, <span class="math inline">\(U\eta_{A_1}, U\eta_{A_2}, ..., U\eta_{A_n}\)</span>.</p>
<p>Similar to the exposure, our outcome Y can be conceptualised as a function of indicators, <span class="math inline">\(Y_{f(Y_1, Y_2, ..., Y_n)}\)</span>, of a latent reality. This reality is expressed through the latent components <span class="math inline">\(\eta_{Y_1}, \eta_{Y_2}, ..., \eta_{Y_n}\)</span>, each having their associated error term <span class="math inline">\(U\eta_{Y_1}, U\eta_{Y_2}, ..., U\eta_{Y_n}\)</span>.</p>
<p><a href="#fig-dag-coarsen-measurement-error">Figure&nbsp;5</a> illustrates the assumed reality. It shows possible paths for confounding via directed measurement error. Each path is represented by a structural component <span class="math inline">\(\eta_{A_n}\)</span> and its associated error term <span class="math inline">\(U\eta_{Y_n}\)</span>. Here we present three possible confounding paths that are possible from directed measurement error.</p>
<p>Note that the potential for confounding arising from measurement error in panel designs depends fundamentally on the particular relationships and dependencies among variables, not merely their quantity. However, we can see here that, theoretically, a larger number of latent states or error terms could amplify the possibilities for confounding, In a simplistic scenario, every latent variable associated with an exposure could affect each error term of an outcome, leading to an expansive network of confounding paths</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dag-coarsen-measurement-error" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="test-again_files/figure-html/fig-dag-coarsen-measurement-error-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5: For</figcaption>
</figure>
</div>
</div>
</div>
<!-- ### Measurement Error and Construct Measures -->
<!-- Three-wave panel designs in observational research often operate under some key assumptions related to the measurement of constructs and measurement error. We'll discuss these implications within a framework where statistical and structural models interplay, shaping measurement theory and practice. The focus will be on an exposure, denoted as A, and an outcome, denoted as Y, measured at A1 and Y2 respectively.  -->
<!-- Consider a situation where no unmeasured confounding is present. Now, our exposure A can be measured by a function of indicators, denoted as $A_{f(A_1, A_2, ..., A_n)}$, forming a coarsened state from a multivariate reality. Each element of this reality has a corresponding structural component, denoted as $\eta_{A_1}, \eta_{A_2}, ..., \eta_{A_n}$. These components are measured with their respective error terms, $U\eta_{A_1}, U\eta_{A_2}, ..., U\eta_{A_n}$. -->
<!-- Similar to the exposure, our outcome Y can be conceptualised as a function of indicators, $Y_{f(Y_1, Y_2, ..., Y_n)}$, of a latent reality. This reality is expressed through the latent components $\eta_{Y_1}, \eta_{Y_2}, ..., \eta_{Y_n}$, each having their associated error term $U\eta_{Y_1}, U\eta_{Y_2}, ..., U\eta_{Y_n}$. -->
<!-- The following diagram @fig-dag-coarsen-measurement-error illustrates the assumed reality. It shows possible paths for confounding via directed measurement error. Each path is represented by a structural component $\eta_{A_n}$ and its associated error term $U\eta_{Y_n}$. -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-coarsen-measurement-error -->
<!-- #| fig-cap: "TBA" -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (aa1) at (0, 0) {$\eta_{A1}$}; -->
<!-- \node [rectangle, draw=white] (aa2) at (2, 0) {$\eta_{A2}$}; -->
<!-- \node [rectangle, draw=white] (aa3) at (4, 0) {$\eta_{A3}$}; -->
<!-- \node [rectangle, draw=white] (a1) at (0, 1) {$A_1$}; -->
<!-- \node [rectangle, draw=white] (a2) at (2, 1) {$A_2$}; -->
<!-- \node [rectangle, draw=white] (a3) at (4, 1) {$A_3$}; -->
<!-- \node [rectangle, draw=white] (Uaa1) at (0, 2) {$U_{A1}$}; -->
<!-- \node [rectangle, draw=white] (Uaa2) at (2, 2) {$U_{A2}$}; -->
<!-- \node [rectangle, draw=white] (Uaa3) at (4, 2) {$U_{A3}$}; -->
<!-- \node [rectangle, draw=white] (yy1) at (10, 0) {$\eta_{Y1}$}; -->
<!-- \node [rectangle, draw=white] (yy2) at (12, 0) {$\eta_{Y2}$}; -->
<!-- \node [rectangle, draw=white] (yy3) at (14, 0) {$\eta_{Y3}$}; -->
<!-- \node [rectangle, draw=white] (y1) at (10, 1) {$Y_1$}; -->
<!-- \node [rectangle, draw=white] (y2) at (12, 1) {$Y_2$}; -->
<!-- \node [rectangle, draw=white] (y3) at (14, 1) {$Y_3$}; -->
<!-- \node [rectangle, draw=white] (Uyy1) at (10, 2) {$U_{Y1}$}; -->
<!-- \node [rectangle, draw=white] (Uyy2) at (12, 2) {$U_{Y2}$}; -->
<!-- \node [rectangle, draw=white] (Uyy3) at (14, 2) {$U_{Y3}$}; -->
<!-- \node [rectangle, draw=white] (A) at (6, 1) {$A_{f(A_1,A_2,A_3)}$}; -->
<!-- \node [rectangle, draw=white] (Y) at (16, 1) {$Y_{f(Y_1,Y_2,Y_3)}$}; -->
<!-- \draw [-latex, draw=black] (aa1) to (a1); -->
<!-- \draw [-latex, draw=black] (aa2) to (a2); -->
<!-- \draw [-latex, draw=black] (aa3) to (a3); -->
<!-- \draw [-latex, draw=black] (Uaa1) to (a1); -->
<!-- \draw [-latex, draw=black] (Uaa2) to (a2); -->
<!-- \draw [-latex, draw=black] (Uaa3) to (a3); -->
<!-- \draw [-latex, draw=black] (yy1) to (y1); -->
<!-- \draw [-latex, draw=black] (yy2) to (y2); -->
<!-- \draw [-latex, draw=black] (yy3) to (y3); -->
<!-- \draw [-latex, draw=black] (Uyy1) to (y1); -->
<!-- \draw [-latex, draw=red] (Uyy2) to (y2); -->
<!-- \draw [-latex, draw=red] (Uyy3) to (y3); -->
<!-- \draw [-latex, draw=red] (a3) to (A); -->
<!-- \draw [-latex, draw=red] (y3) to (Y); -->
<!-- \draw [-latex, draw=red, bend left = 60] (aa3) to (Uyy2); -->
<!-- \draw [-latex, draw=red, bend left = 60] (aa3) to (Uyy3); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-coarsen-measurement-error-2 -->
<!-- #| fig-cap: "TBA" -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (aa1) at (0, 0) {$\eta_{a1}$}; -->
<!-- \node [rectangle, draw=white] (aa2) at (2, 0) {$\eta_{a2}$}; -->
<!-- \node [rectangle, draw=white] (aa3) at (4, 0) {$\eta_{a3}$}; -->
<!-- \node [rectangle, draw=white] (a1) at (0, 1) {$\{ a1$}; -->
<!-- \node [rectangle, draw=white] (a2) at (2, 1) {$a2$}; -->
<!-- \node [rectangle, draw=white] (a3) at (4, 1) {$a3 \}$}; -->
<!-- \node [rectangle, draw=white] (Uaa1) at (0, 2) {$U_{a1}$}; -->
<!-- \node [rectangle, draw=white] (Uaa2) at (2, 2) {$U_{a2}$}; -->
<!-- \node [rectangle, draw=white] (Uaa3) at (4, 2) {$U_{a3}$}; -->
<!-- \node [rectangle, draw=white] (yy1) at (10, 0) {$\eta_{y1}$}; -->
<!-- \node [rectangle, draw=white] (yy2) at (12, 0) {$\eta_{y2}$}; -->
<!-- \node [rectangle, draw=white] (yy3) at (14, 0) {$\eta_{y3}$}; -->
<!-- \node [rectangle, draw=white] (y1) at (10, 1) {$\{ y1$}; -->
<!-- \node [rectangle, draw=white] (y2) at (12, 1) {$y2$}; -->
<!-- \node [rectangle, draw=white] (y3) at (14, 1) {$y3  \}$}; -->
<!-- \node [rectangle, draw=white] (Uyy1) at (10, 2) {$U_{y1}$}; -->
<!-- \node [rectangle, draw=white] (Uyy2) at (12, 2) {$U_{y2}$}; -->
<!-- \node [rectangle, draw=white] (Uyy3) at (14, 2) {$U_{y3}$}; -->
<!-- \node [rectangle, draw=white] (A) at (6, 1) {$A_{f(a1,a2,a3)}$}; -->
<!-- \node [rectangle, draw=white] (Y) at (16, 1) {$Y_{f(y1,y2,y3)}$}; -->
<!-- \draw [-latex, draw=black] (aa1) to (a1); -->
<!-- \draw [-latex, draw=black] (aa2) to (a2); -->
<!-- \draw [-latex, draw=black] (aa3) to (a3); -->
<!-- \draw [-latex, draw=black] (Uaa1) to (a1); -->
<!-- \draw [-latex, draw=black] (Uaa2) to (a2); -->
<!-- \draw [-latex, draw=black] (Uaa3) to (a3); -->
<!-- \draw [-latex, draw=black] (yy1) to (y1); -->
<!-- \draw [-latex, draw=black] (yy2) to (y2); -->
<!-- \draw [-latex, draw=black] (yy3) to (y3); -->
<!-- \draw [-latex, draw=black] (Uyy1) to (y1); -->
<!-- \draw [-latex, draw=red] (Uyy2) to (y2); -->
<!-- \draw [-latex, draw=red] (Uyy3) to (y3); -->
<!-- \draw [-latex, draw=red] (a3) to (A); -->
<!-- \draw [-latex, draw=red] (y3) to (Y); -->
<!-- \draw [-latex, draw=red, bend left = 60] (aa3) to (Uyy2); -->
<!-- \draw [-latex, draw=red, bend left = 60] (aa3) to (Uyy3); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- #### **2. The formative model**   -->
<!-- In a formative measurement model, the observed variables are assumed to cause the latent variable. Here again, there is a single latent variable. However this latent variable is taken to be an effect of the underlying indicators. The formative model may be expressed: -->
<!-- $$\eta = \sum_i\lambda_i X_i + \varepsilon$$ -->
<!-- Where $\eta$ is the latent variable, $\lambda_i$ is the weight for $X_i$ (the observed variable), and $\varepsilon$ is the error term. The latent variable $\eta$ is a composite of the observed variables $X_i$. In the context of a formative model, correlation or interchangeability between indicators is not required. Each indicator contributes distinctively to the latent variable. As such, a modification in one indicator does not automatically imply a corresponding change in the other indicators. -->
<!--  @fig-dag-latent-formative_0 presents the structural assumptions of this model on a causal diagram -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-latent-formative_0 -->
<!-- #| fig-cap: "Formative model:: assume univariate latent variable from which the indicators X1...X3 give rise. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434" -->
<!-- #| out-width: 80% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=black] (X1) at (0, 1) {X1}; -->
<!-- \node [rectangle, draw=white] (X2) at (0, 0) {$\vdots$}; -->
<!-- \node [rectangle, draw=black] (Xn) at (0, -1) {X$_n$}; -->
<!-- \node [rectangle, draw=white] (eta) at (6, 0) {$\eta$}; -->
<!-- \draw [-latex, draw=black] (X1) to (eta); -->
<!-- \draw [-latex, draw=black] (X2) to (eta); -->
<!-- \draw [-latex, draw=black] (Xn) to (eta); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- VanderWeele has recently raised a host of problems arising for formative and reflective models that become clear when we examine their causal assuptions [@vanderweele2022]. -->
<!-- > However, this analysis of reflective and formative models assumed that the latent η was causally efficacious. This may not be the case (VanderWeele 2022) -->
<!-- VanderWeele distinguishes between statistical and structural interpretations. -->
<!-- 1.  **Statistical Model:** a mathematical construct that shows how observable variables, also known as indicators, are related to latent or unseen variables. These are presented in the psychometric equations above. -->
<!-- 2.  **Structural Model:** A structural model refers to the causal assumptions or hypotheses about the relationships among variables in a statistical model. The assumptions of the factor analytic tradition are presented in @fig-dag-latent-formative_0 and @fig-dag-latent-1 are structural models. -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-formative-assumptions-compatible -->
<!-- #| fig-cap: "Formative model is compatible with indicators causing outcome. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434" -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- %\node [rectangle, draw=white] (L) at (0, 0) {L}; -->
<!-- \node [rectangle, draw=white] (eta) at (2, 0) {$\eta$}; -->
<!-- \node [rectangle, draw=white] (X1) at (4, 1) {X1}; -->
<!-- \node [rectangle, draw=white] (X2) at (4, 0) {$\vdots$}; -->
<!-- \node [rectangle, draw=white] (Xn) at (4, -1) {X$_n$}; -->
<!-- \node [rectangle, draw=white] (Y) at (6, 0) {Y}; -->
<!-- %\draw [-latex, bend right=80, draw=black] (L) to (Y); -->
<!-- %\draw [-latex, bend left=60, draw=black] (L) to (X1); -->
<!-- %\draw [-latex, bend left=40, draw=black] (L) to (X2); -->
<!-- %\draw [-latex, bend right=60, draw=black] (L) to (Xn); -->
<!-- \draw [-latex, draw=black] (eta) to (X1); -->
<!-- \draw [-latex, draw=black] (eta) to (X2); -->
<!-- \draw [-latex, draw=black] (eta) to (Xn); -->
<!-- \draw [-latex, draw=red] (X1) to (Y); -->
<!-- \draw [-latex, draw=red] (X2) to (Y); -->
<!-- \draw [-latex, draw=red] (Xn) to (Y); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- Similarly, while the statistical model $\eta = \sum_i\lambda_i X_i + \varepsilon$ agrees with @fig-dag-reflective-assumptions_note but it also agrees with @fig-dag-reflectiveassumptions-compatible_again. Here too, cross-sectional data cannot decide between these two potential structural interpretations. -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-uu-null-2 -->
<!-- #| fig-cap: "Uncorrelated non-differential  easurement error does not bias estimates under the null. However, with measurement error, a biasing path opens between the exposure and outcome. The path is coloured red in the graph." -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (UL) at (0, 1) {U$_L$}; -->
<!-- \node [rectangle, draw=white] (UA) at (6, 2) {U$_A$}; -->
<!-- \node [rectangle, draw=white] (UY) at (9, 3) {U$_Y$}; -->
<!-- \node [rectangle, draw=black] (L0) at (3, 1) {$L_{f(l_1 \dots l_n::)}^{t0}$}; -->
<!-- \node [rectangle, draw=black] (A1) at (7, 1) {$A_{f(a_1\dots a_n)}^{t1}$}; -->
<!-- \node [rectangle, draw=black] (Y2) at (11, 1) {$Y_{f(y_1\dots y_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=white] (Leta0) at (3, 0) {$\eta^{t0}_L$}; -->
<!-- \node [rectangle, draw=white] (Aeta1) at (7, 0) {$\eta^{t1}_A$}; -->
<!-- \node [rectangle, draw=white] (Yeta2) at (11, 0) {$\eta^{t2}_Y$}; -->
<!-- \draw [-latex, draw=black] (UL) to (L0); -->
<!-- \draw [-latex, draw=black,bend left=20] (UA) to (A1); -->
<!-- \draw [-latex, draw=black,bend left=30] (UY) to (Y2); -->
<!-- \draw [-latex, draw=red] (Leta0) to (L0); -->
<!-- \draw [-latex, draw=red] (Leta0) to (Aeta1); -->
<!-- \draw [-latex, draw=red, bend right=30] (Leta0) to (Yeta2); -->
<!-- \draw [-latex, draw=red] (Aeta1) to (A1); -->
<!-- \draw [-latex, draw=red] (Yeta2) to (Y2); -->
<!-- \draw [cor, draw=black, dashed,bend right=80] (UL) to (Leta0); -->
<!-- \draw [cor, draw=black, dashed, bend right = 80] (UA) to (Aeta1); -->
<!-- \draw [cor, draw=black, dashed, bend right = 80] (UY) to (Yeta2); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
</section>
</section>
<section id="introduction" class="level2">

<!-- ```{tikz} -->
<!-- #| label: fig-dag-dep-undir-effect-confounders-3wave -->
<!-- #| fig-cap: "With time series data comes great promise, and also great opportunity for measurement confounding. Where errors are correlated, many paths for confounding are opened (denoted by red). The take home is not despair, but rather an emphasis on sensitivity analysis." -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (ULY) at (0, 5) {U$_{LY}$}; -->
<!-- \node [rectangle, draw=white] (ULA) at (0, 4) {U$_{LA}$}; -->
<!-- \node [rectangle, draw=white] (UL) at (4, 3) {U$_{LAY_{t0}}$}; -->
<!-- \node [rectangle, draw=white] (UA) at (8, 4) {U$_{A_{t1}}$}; -->
<!-- \node [rectangle, draw=white] (UY) at (12, 5) {U$_{Y_{t2}}$}; -->
<!-- \node [rectangle, draw=black] (L0) at (4, 1)  {$LAY_{f(lay_1\dots lay_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=black] (A1) at (8, 1) {$A_{f(a_1\dots a_n)}^{t1}$}; -->
<!-- \node [rectangle, draw=black] (Y2) at (12, 1) {$Y_{f(y_1\dots y_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=white] (Leta0) at (4, 0) {$\eta^{t0}_{LAY}$}; -->
<!-- \node [rectangle, draw=white] (Aeta1) at (8, 0) {$\eta^{t1}_A$}; -->
<!-- \node [rectangle, draw=white] (Yeta2) at (12, 0) {$\eta^{t2}_Y$}; -->
<!-- \draw [-latex, draw=red] (ULA) to (UA); -->
<!-- \draw [-latex, draw=red] (ULA) to (UL); -->
<!-- \draw [-latex, draw=red] (ULY) to (UY); -->
<!-- \draw [-latex, draw=red] (ULY) to (UL); -->
<!-- \draw [-latex, draw=red] (UA) to (A1); -->
<!-- \draw [-latex, draw=red] (UL) to (L0); -->
<!-- \draw [-latex, draw=red] (Leta0) to (L0); -->
<!-- \draw [-latex, draw=red] (Leta0) to (Aeta1); -->
<!-- \draw [-latex, draw=red, bend right=30] (Leta0) to (Yeta2); -->
<!-- \draw [-latex, draw=red] (UY) to (Y2); -->
<!-- \draw [-latex, draw=red] (Aeta1) to (A1); -->
<!-- \draw [-latex, draw=red] (Yeta2) to (Y2); -->
<!-- \draw [cor, draw=red, dashed,bend right=120] (UL) to (Leta0); -->
<!-- \draw [cor, draw=red, dashed, bend right = 120] (UA) to (Aeta1); -->
<!-- \draw [cor, draw=red, dashed, bend right = 120] (UY) to (Yeta2); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-dep-dir-effect-confounders-3wave -->
<!-- #| fig-cap: "With time series data comes great promise, and also great opportunity for measurement confounding. Where errors are correlated, many paths for confounding are opened (denoted by red). The take home is not despair, but rather an emphasis on sensitivity analysis." -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (UL) at (4, 3) {U$_{LAY_{t0}}$}; -->
<!-- \node [rectangle, draw=white] (UA) at (8, 4) {U$_{A_{t1}}$}; -->
<!-- \node [rectangle, draw=white] (UY) at (12, 5) {U$_{Y_{t2}}$}; -->
<!-- \node [rectangle, draw=black] (L0) at (4, 1)  {$LAY_{f(lay_1\dots lay_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=black] (A1) at (8, 1) {$A_{f(a_1\dots a_n)}^{t1}$}; -->
<!-- \node [rectangle, draw=black] (Y2) at (12, 1) {$Y_{f(y_1\dots y_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=white] (Leta0) at (4, 0) {$\eta^{t0}_{LAY}$}; -->
<!-- \node [rectangle, draw=white] (Aeta1) at (8, 0) {$\eta^{t1}_A$}; -->
<!-- \node [rectangle, draw=white] (Yeta2) at (12, 0) {$\eta^{t2}_Y$}; -->
<!-- \draw [-latex, draw=black] (UA) to (A1); -->
<!-- \draw [-latex, draw=black] (UL) to (L0); -->
<!-- \draw [-latex, draw=black] (Leta0) to (L0); -->
<!-- \draw [-latex, draw=black] (Leta0) to (Aeta1); -->
<!-- \draw [-latex, draw=black, bend right=30] (Leta0) to (Yeta2); -->
<!-- \draw [-latex, draw=black] (UY) to (Y2); -->
<!-- \draw [-latex, draw=black] (Aeta1) to (A1); -->
<!-- \draw [-latex, draw=black] (Yeta2) to (Y2); -->
<!-- \draw [cor, draw=black, dashed,bend right=120] (UL) to (Leta0); -->
<!-- \draw [cor, draw=black, dashed, bend right = 120] (UA) to (Aeta1); -->
<!-- \draw [cor, draw=black, dashed, bend right = 120] (UY) to (Yeta2); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- ```{tikz} -->
<!-- #| label: fig-dag-dep-udir-effect-confounders-3wave22 -->
<!-- #| fig-cap: "Measurement error opens an additional pathway to confounding if either there are correlated errors, or a directed effect of the exposure on the errors of measured outcome." -->
<!-- #| out-width: 100% -->
<!-- #| echo: false -->
<!-- #| eval: true -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- \tikzset{blackArrowRedTip/.style={ -->
<!--   decoration={markings, mark=at position 1 with {\arrow[red, thick]{latex}}}, -->
<!--   postaction={decorate}, -->
<!--   shorten >=0.4pt}} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->
<!-- \node [rectangle, draw=white] (ULAY) at (0, 5) {$U_{L}$}; -->
<!-- \node [rectangle, draw=white] (UA) at (5, 4) {$U_{A}$}; -->
<!-- \node [rectangle, draw=white] (UY) at (10, 5) {$U_{Y}$}; -->
<!-- \node [rectangle, draw=black] (L0) at (0, 2) {L$_{f(X_1\dots X_n)}^{t0}$}; -->
<!-- \node [rectangle, draw=black] (A1) at (5, 2) {A$_{f(X_1\dots X_n)}^{t1}$}; -->
<!-- \node [rectangle, draw=black] (Y2) at (10, 2) {Y$_{f(X_1\dots X_n)}^{t2}$}; -->
<!-- \node [rectangle, draw=white] (Leta0) at (0, 0) {$\eta_L^{t0}$}; -->
<!-- \node [rectangle, draw=white] (Aeta1) at (5, 0) {$\eta_A^{t1}$}; -->
<!-- \node [rectangle, draw=white] (Yeta2) at (10, 0) {$\eta_Y^{t2}$}; -->
<!-- \draw [-latex, draw=red] (ULAY) to (UA); -->
<!-- \draw [-latex, draw=red] (ULAY) to (UY); -->
<!-- \draw [-latex, draw=black] (UA) to (A1); -->
<!-- \draw [-latex, draw=red] (UY) to (Y2); -->
<!-- \draw [-latex, draw=black] (ULAY) to (L0); -->
<!-- \draw [-latex, draw=black] (Leta0) to (L0); -->
<!-- \draw [-latex, draw=black] (Leta0) to (Aeta1); -->
<!-- \draw [-latex, draw=black, bend right=30] (Leta0) to (Yeta2); -->
<!-- \draw [-latex, draw = black] (Aeta1) to (A1); -->
<!-- \draw [-latex, draw=black] (Yeta2) to (Y2); -->
<!-- \draw [-latex, draw=red] (Aeta1) to (UY); -->
<!-- \draw [-latex, draw=red] (Leta0) to (UA); -->
<!-- %\draw [-latex, draw=black] (Leta0) to (UA); -->
<!-- \draw [cor, draw=red, dashed,bend right=80] (ULAY) to (Leta0); -->
<!-- \draw [cor, draw=red, dashed, bend right = 80] (UA) to (Aeta1); -->
<!-- \draw [cor, draw=red, dashed, bend left = 80] (UY) to (Yeta2); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- ### Selection bias at the start of study -->
<!-- Selection bias may be defined generally the bias that arises when the parameter of interest in a target population differs from the parameter of interest in the subset of the population available for analysis -- that is from the source population [@hernán2017]. The source population may differ from the target population in descriptive parameters. In causal inference we are typically interested in selection bias for causal effect measures -- that is, in how such difference effect causal contrasts on the some scale of interest (difference, risk ratio, etc.) -->
<!-- Causal graph can facilitate progress both in understanding how causal effect estimates might be affected by differences between the sources and target population. Before examining how, consider the following topology of confounding developed by Suzuki and colleagues[@suzuki2016; @suzuki2014; @suzuki2020], building on work by Tyler VanderWeele [@vanderweele2012]: -->
<!-- 1: **Confounding in distribution**: there is no confounding in distribution of the effect of exposure on outcome if the group that received a level exposure is representative of what would have occurred in the target population.  -->
<!-- 2.  **Confounding in expectation**: there is no confounding in expectation of the effect of exposure on outcome if the exposure assignment mechanism results in balance.[^note_suzuki] -->
<!-- [^note_suzuki]: Suzuki and colleagues also describe the following distinctions: (3) **Confounding in measure**: there is no confounding in measure of the effect of exposure on outcome if a particular measure of interest is equivalent to the corresponding causal measure in the target population. This concept is important because, as we noted in our discussion of interaction, inference may depend on the scale at which a causal effect is measured. An effect may be present on the difference scale but not present on the relative-risk scale, and vice versa. If selection introduces an effect modifier, the scale at which an effect is measured may be an important consideration to whether there is what the authors call "confounding in distribution in confounding in expectation." (4) **Realised confounding**: there is no realised confounding of the effect of exposure on outcome if a particular exposure assignment results in balance, irrespective of the exposure assignment mechanism. This concept is important because even in randomised experiments, randomisation may fail to remove chance imbalances in the distributions of confounders in the exposures. We may have no confounding in expectation yet the experimental effect estimate might differ from the experiment to the population. All four concepts are variously used in discussions of "confounding." All are important to consider when evaluating a study. Yet each concept brings a different focus.Causal diagrams help to clarify the relationship of selection bias to the different theoretical and applied interests with might have in confounding. -->
<!-- With these distinction to hand, consider @fig-selection-under-the-null, which presents a scenario in which there is no (marginal) causal effect of the exposure on the outcome, yet there is selection into the study. We imagine randomisation such that there is no path from any other node into $A$. Let us assume randomisation succeeded.  Finally, we imagine there there is no causal path from $A \to Y$. As evident in @fig-selection-under-the-null there is no confounding in the expectation, nor is there confounding in distribution. The null effect estimate returned from the study will honour the true null effect in the population. We might say that selection does lead to "confounding in distribution for confounding in expectation." Or more simply, despite selection the null effect in the source population is unbiased for the target population. Our null results generalise (see: [@hernán2004b], see also [@greenlands.1977a]). -->
<!-- ```{tikz} -->
<!-- #| label: fig-selection-under-the-null -->
<!-- #| fig-cap: "Selection under the null. An unmeasured variable affects selection into the study and the outcome. D-separation is preserved there is no confounding in expectation." -->
<!-- #| out-width: 60% -->
<!-- #| echo: false -->
<!-- #|  -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations.markings} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[every node/.append style={draw}] -->
<!-- \node [rectangle, draw=white] (U) at (0, 0) {U}; -->
<!-- \node [rectangle, draw=black] (S) at (2, 0) {S}; -->
<!-- \node [rectangle, draw=white] (A) at (4, 0) {A}; -->
<!-- \node [rectangle, draw=white] (Y) at (6, 0) {Y}; -->
<!-- \draw [-latex, draw=black, bend left=30] (U) to (Y); -->
<!-- \draw [-latex, draw=black] (U) to (S); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- @fig-selection-off-the-null presents a different scenario in which there selection bias for the population parameter: the association in the population of selected individuals differs from the causal association in the target population. Hernán calls this "selection bias off the null" [@hernán2017] and Lu et al call this "type 2 selection bias" [@lu2022a] This bias occurs because the selection into the study occurs on an effect modifier for the effect of the exposure on the outcome. In this scenario there is what Suzuki et al call "confounding in distribution for the confounding in expectation." That is, although the causal effect of $A\to Y$ is unbiased for the exposed and unexposed in the source population, the effect estimate does not generalise to the exposed and unexposed in the target population: $PATE \cancel{\approx} ATE_{\text{sample}}$.  -->
<!-- ```{tikz} -->
<!-- #| label: fig-selection-off-the-null -->
<!-- #| fig-cap: "Selection off the null). An unmeasured variable affects selection into the study and the outcome. Here the exposure affects the outcome. Although D-separation is preserved, there is no confounding in expectation, there is confounding in distribution." -->
<!-- #| out-width: 60% -->
<!-- #| echo: false -->
<!-- #|  -->
<!-- \usetikzlibrary{positioning} -->
<!-- \usetikzlibrary{shapes.geometric} -->
<!-- \usetikzlibrary{arrows} -->
<!-- \usetikzlibrary{decorations.markings} -->
<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->
<!-- \tikzset{>=latex} -->
<!-- % Define a simple decoration -->
<!-- \tikzstyle{cor} = [-, dotted, preaction = {decorate}] -->
<!-- \begin{tikzpicture}[every node/.append style={draw}] -->
<!-- \node [rectangle, draw=white] (U) at (0, 0) {U}; -->
<!-- \node [rectangle, draw=black] (S) at (2, 0) {S}; -->
<!-- \node [rectangle, draw=white] (A) at (4, 0) {A}; -->
<!-- \node [rectangle, draw=white] (Y) at (6, 0) {Y}; -->
<!-- \draw [-latex, draw=black, bend left=30] (U) to (Y); -->
<!-- \draw [-latex, draw=black] (U) to (S); -->
<!-- \draw [-latex, draw=black] (A) to (Y); -->
<!-- \end{tikzpicture} -->
<!-- ``` -->
<!-- There has been considerable work investigating the conditions under which causal estimates for a target population may be identified when the source population differs from the target population [@lu2022a], i.e. whether we may obtain a function such that $PATE =  f(ATE_{\text{source}}, W)$. Whether results tranport to populations that systematically differ is also an area of active research [@bareinboim2022a; @deffner2022a], i.e. whether we may obtain a function such that $ATE_{\text{target}} \approx f(ATE_{\text{source}}, T)$. As @@lu2022a point out:  The authors also point out that "Type 2 selection bias, which results from restricting to one or more level(s) of an efect measure modiier, is likely ubiquitous and underappreciated..." The practical take hope is that addressing type 2 selection bias during the design and analytic stage by accurately measuring and properly adjust for a sufficient set of covariates that affect selection $\framebox{S}$ and the outcome. This advice covers selection bias at baseline. In panel designs there is a constant threat of selection occurring after enrolment into the study.  We next use causal diagrams to make sense of this threat and to derive practical advice. -->
<!-- To simplify, consider a randomised experiment in which there is no confounding of the exposure and outcome. Suppose have reason to think there might be effect modification of the exposure that differs among those who affiliate with religion and those who do not. Suppose further we have under-sampled religious people. Can causal diagrams help us to understand the structure of the bias? -->

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Introduction</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-vanderweele2022" class="csl-entry" role="listitem">
VanderWeele, Tyler J. 2022a. <span>“Constructed Measures and Causal Inference: Towards a New Model of Measurement for Psychosocial Constructs.”</span> <em>Epidemiology</em> 33 (1): 141. <a href="https://doi.org/10.1097/EDE.0000000000001434">https://doi.org/10.1097/EDE.0000000000001434</a>.
</div>
<div id="ref-vanderweele2022a" class="csl-entry" role="listitem">
———. 2022b. <span>“Constructed Measures and Causal Inference: Towards a New Model of Measurement for Psychosocial Constructs.”</span> <em>Epidemiology</em> 33 (1): 141. <a href="https://doi.org/10.1097/EDE.0000000000001434">https://doi.org/10.1097/EDE.0000000000001434</a>.
</div>
<div id="ref-vanderweele2022b" class="csl-entry" role="listitem">
VanderWeele, Tyler J, and Stijn Vansteelandt. 2022. <span>“A Statistical Test to Reject the Structural Interpretation of a Latent Factor Model.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 84 (5): 20322054.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In a formative model, the observed variables are thought to cause the latent variable. As in the reflective model, there is a single latent variable. This latent variable, however, is considered the effect of the underlying indicators. In mathematical terms, if <span class="math inline">\(\eta\)</span> represents the latent variable, <span class="math inline">\(\lambda_i\)</span> denotes the weight for <span class="math inline">\(X_i\)</span> (the observed variable), and <span class="math inline">\(\varepsilon\)</span> is the error term, the latent variable <span class="math inline">\(\eta\)</span> can be described as a composite of the observed variables <span class="math inline">\(X_i\)</span>, expressed as: <span class="math inline">\(\eta = \sum_i\lambda_i X_i\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>