---
title: "Causal inference in three wave panels: a step-by-step guide"
abstract: | 
 This article offers a guide for addressing causal questions in psychology using three-wave panel designs. We focus on three-wave panel studies for the New Zealand Attitudes and Values Study (NZAVS), however the principles and strategies we describe may generalise. **Part 1** lays the foundation by introducing key definitions, notation, and assumptions required for causal inference. **Part 2** describes the three-wave panel "outcome-wide" design. **Part 3** provides a step-by-step giod for conducting three-wave outcome-wide design using NZAVS data. **Part 4** explains common estimators and their options, again focussing on NZAVS designs. **Part 5** explores more complex causal questions and approaches required for $n > 3$ wave designs. Overall, this article aims to equip pyschological scientists with the tools and understanding needed for robust causal inferences using panel data.
author: 
  - name: Joseph A. Bulbulia
    orcid: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    affiliation: 
      - name: Victoria University of Wellington, New Zealand, School of Psychology, Centre for Applied Cross-Cultural Research
        department: Psychology/Centre for Applied Cross-Cultural Research
        city: Wellington
        country: New Zealand
        url: www.wgtn.ac.nz/cacr
execute:
  warning: false
  eval: true
  echo: false
  include: true
keywords:
  - DAGS
  - Causal Inference
  - Confounding
  - History
  - Psychology
  - Panel
format:
  pdf:
    sanitize: true
    keep-tex: true
    link-citations: true
    colorlinks: true
    documentclass: article
    classoption: [singlecolumn]
    lof: false
    lot: false
    geometry:
      - top=30mm
      - left=20mm
      - heightrounded
    include-in-header:
       - text: |
           \usepackage{cancel}
date: last-modified
csl: camb-a.csl
---

```{r}
#| label: load-libraries
#| echo: false
#| include: true
#| eval: true

# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# for latex graphs
# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


### ALWAYS RESTART R IN A FRESH SESSION ####

# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    #"/Users/joseph/v-project\ Dropbox/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs_refactor/nzavs_data_23"
    "/Users/joseph/Library/CloudStorage/Dropbox-v-project/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs-current/r-data/nzavs_data"
  )

# read data: note that you need use the arrow package in R

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23-ow-methods"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)

# check path:is this correct?  check so you know you are not overwriting other directors
#push_mods

```

```{r}
#| label: ideas
#| echo: false
#| eval: false

# Notes 
# - introduction on counterfactaul contrasts
# - assumptions for casual inference. 
# - benefits of counterfactual data science
# - limitations of counterfactual data science.
# - add section on multiple imputation
# - note the benefits of outcome-wide approach - dimensions accross a domiain 
# - researchers must explain how the determined their domain
# - note: total effect vs other types of effect. here we discuss interventions 
# - effect modification: 
# - continuous outcomes: continuous exposures 
# - poisson & dispersion: currently e-values not useful. 

```

## Introduction

### Purpose

This article describes how to address causal questions in psychology using panel data. We primarily focus on the simple case of estimating total effects in three-wave panel designs. A second and related purpose of this article is to guide applied researchers   the New Zealand Attitudes and Values Study in developing studies that address causal questions.

**Part 1** introduces definitions and notation, and outlines how causal inference works. The purpose of this section is to introduce readers who are not familiar with causal inference to its conceptual basis.

**Part 2** outlines the three-wave panel, and its motivations. Here, I introduce the concept of an "outcome-wide study," an concept introduced by Tyler VanderWeele [@vanderweele2017a; @vanderweele2020a]. I review important theoretical motivations for outcome-wide studies, describe pitfalls, and discuss methods for addressing their limitations. To foreshadow, and outcome-wide study quantifies the total effects of a single intervention on multiple outcomes. This approach affords more rapid scientific progress than would be possible were researchers to focus on single outcomes. This approach also avoids selection bias arising from cherry-picking outcomes in the service of a publishable story.

**Part 3** develops a the step-by-step guide for conducting causal inference within a three-wave panel design. Here, our focus shifts from theoretical to applied interests. To make theory concrete, we use the New Zealand Attitudes and Values Study (NZAVS). The NZAVS is a national probability study that has been repeatedly measuring individuals since 2009. In 2018-2019 (NZAVS wave 10), the NZAVS conducted a large booster that enrolled 1.5% of the adult population of New Zealand. Our focus here will be on describing causal inference methods as they apply to NZAVS waves 10-13. Part of the purpose of this guide is to assist NZAVS researchers in developing causal inferential studies using NZAVS data. Again, we will focus on outcome-wide approaches.

**Part 4** describes common estimators, and options. The material in this section may appear somewhat technical. However, we encourage readers to worth through the technical details, which have been limited to the essentials required for understanding the move from stating causal questions to answering them using time-series data.

**Part 5** discusses more complex designs where there is scope for treatment-confounder feedback.

An Appendix describes custom functions written for executing the workflows in the NZAVS, again with a focus on three-wave panel designs.


## Part 1 Foundational Concepts


### Observed Outcome ($Y|A=a$)

A critical aspect of causal inference is the temporal sequence of events. Specifically, the outcome variable, denoted $Y$, is observed after the treatment or exposure, which is symbolised as $A=a$. This ordering is imperative; causality implies a forward motion in time, from cause to effect. Therefore, $Y$ must be measured post-intervention or post-exposure to be considered as a potential effect of $A$.

The nature of the outcome variable can be diverse. In psychological science, it may be a quantitative measure such as test scores, or a binary outcome like presence or absence of a mental disorder. We might be interested in estimating several outcomes simultaneously.  Whatever the outcome, we must ensure that it has been measured after the occurence of the exposure or treatment. 

### Counterfactual Outcome ($Y(a)$)

The counterfactual outcome $Y(a)$ stands for the unobserved outcome that each unit would have experienced under a specific treatment level $a$. This counterfactual serves as the cornerstone for estimating causal effects, allowing us to consider what would have happened the treatments differed  It is crucial to remember that these are theoretical constructs; conterfactuals are not observable because $Y$ can only be measured after a particular level of treatment $A=a$ has actually occurred.

For instance, if an individual receives treatment $a$, we observe the outcome $Y|A=a$. What we cannot observe is how the outcome would have varied under different treatments, denoted as $Y(a')$ for $a' \neq a$. This predicament, known as the "fundamental problem of causal inference," will require advanced methods to approximate the counterfactual outcomes from observations.[^note_terminology]

[^note_terminology]: In the literature on causal inference, the conventions $Y(a)$ $Y_a$ and $Y^a$  are all equivalent, and may be used interchangeably.  For consistency, we use the notation $Y(a)$ for counterfactual outcomes throughout this article.
 
### Measuring Causal Effects

In the arena of causal inference, the aim is not merely to detect associations or patterns but to quantify the effect of an intervention. The core tool for this is the counterfactual model, which aids in developing *causal contrasts*. These contrasts are essentially differences in potential outcomes under different treatment levels. They serve as the building blocks for quantifying causal effects.

### Individual Level Causal Contrast

At the individual level, a causal contrast for a specific unit $i$ is defined as $Y_i(a) - Y_i(a')$. However, this is inherently unobservable for any individual. The problem stems from the fact that we can only observe $Y_i | A_i = a$ or $Y_i | A_i = a'$ but never both for the same unit. This limitation is often referred to as the "fundamental problem of causal inference" because it restricts our ability to make conclusive causal claims at the individual level.

### Average (Marginal) Causal Contrasts

While individual-level contrasts may be unobservable, it is often possible to estimate average causal contrasts, particularly when certain assumptions hold. The average or marginal causal contrast is defined as $E[Y(a)] - E[Y(a')]$. It provides a summary measure of the treatment effect across the entire population. When data meet specific criteria, these aggregate measures can be identified and estimated even in observational settings.

### Causal Contrasts In Experiments

In the experimental paradigm, participants are randomly allocated to treatment groups, and outcomes are observed post-intervention. Although individual-level contrasts remain unobservable, the randomisation process allows for the estimation of average causal contrasts. This is possible because random assignment ensures that, in expectation, each treatment group is a fair representation of the population. Hence, we can generalise the average effect of the treatment across groups.

### Causal Contrasts In Observational Studies: Three Fundamental Assumptions

In observational settings, the aim is to approximate the rigour of randomised experiments. This involves meeting three crucial assumptions:

1.  **Causal Consistency**: This principle ensures that the treatments being compared correspond to well-defined interventions [@hernán2023]. Causal consistency helps resolve the inherent *missing data problems* of causal inference. For instance, when causal consistency holds, observed outcomes can be linked to counterfactual outcomes as follows:

$$
Y_i^{observed}|A_i = 
\begin{cases} 
Y_i(a^*) & \text{if } A_i = a^* \\
Y_i(a) & \text{if } A_i = a
\end{cases}
$$

For two treatment levels $A=1$ and $A=0$, the counterfactuals are then:



$$
Y = A \cdot Y(1) + (1-A) \cdot Y(0)
$$

2.  **Exchangeability**: Also known as the "no unmeasured confounding" condition. It posits that after adjusting for observed covariates, potential outcomes are independent of the treatment received [@hernán2023].

$$
Y(a) \coprod  A|L
$$

3.  **Positivity**: This condition asserts that for every level of measured covariates, there is a positive probability of receiving each treatment level [@hernán2023].

$$
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall l \in L
$$
That is, there must be a non-zero probability of receiving each treatment level for every combination of covariates that occurs in the population.

When these assumptions hold, causal inference in observational data may be possible. Importantly, these assumptions are theoretical and often challenging to verify in practice. For example, the assumption of no unmeasured confounders (implicit in conditional exchangeability) is particularly challenging because it involves variables that are, by definition, not observed (see: @bulbulia2023a)

#### Scales of causal contrast

We cannot generally obtain causal contrasts for individual units. By definition, treatments are exclusive.  

However, when assumptions are satisfied (describe below), we may obtain average treatment effects. 


$$
ATE = f_{\text{causal contrast}}(E[Y_a], E[Y_a'])
$$


For example, an average treatment affect for the exposure $A = a$ and $A=a'$ may be expressed on the difference scale as:

$$
ATE_{A,A'} = E[Y(a)] - E[Y(a')]
$$

This function computes the average effect by subtracting the average of the expected outcomes under two specific treatment levels $A$ and$A'$. We say there is an average or marginal effect of A on Y on the causal difference scale if: 

$$ ATE_{A,A'} \neq 0$$





Similarly, a causal contrast between the averages of one treatment and the average of another treatment can also be expressed on the ratio scale:

$$
ATE_{A/A'} = \frac{E[Y(a)]}{E[Y(a')]}
$$


We say there is an average or marginal effect of A on Y on the causal difference scale if: 

$$ ATE_{A/A'}  \neq 1$$

Unless otherwise specified, we will discuss causal contrasts on the difference scale:

$$
\delta_{\text{ATE}} = E[Y(a) - Y(a')]
$$

This is the average or "marginal" contrast between the outcome under treatment $a$ and the outcome under the alternative $a'$, averaged over the entire population. This metric provides an aggregate snapshot of the effect size, ignoring any possible heterogeneities or subgroup-specific variations in treatment effects.

####  Conditional Average Treatment Effect (CATE)

The effect of treatments are not the same for everyone. What works for one subgroup might not work for another, or not work in quite the same way. This brings us to the concept of the Conditional Average Treatment Effect, or CATE.

We define the CATE as the ATE in subgroup $G = g$. Call this quantity: $\delta_{\text{CATE},g}$. It may be computed:

$$
\delta_{\text{CATE},g} = E[Y(a)|G=g] - E[Y(a')|G=g]
$$

For example, if $G$ may denote different age groups —say, young adults and the elderly. Let $\delta_{\text{CATE}_{young}}$ denote a treatment effect specifically on young adults, while  $\delta_{\text{CATE}_{elderly}}$ would do the same for the elderly.[^errors]  

[^errors]: To quantify this contrast, we use statistical methods such as simulation-based inference to estimate standard errors and confidence intervals [@greifer2023].


#### Distinguishing Between ATE and CATE in Group Comparisons

Suppose we wish to understand how treatment effects vary between different groups, you might want to look into $ \gamma_g $. This term reflects the *differential* average treatment effect between groups $G = g$ and $G = g'$.

To articulate this notion more clearly, let us redefine $\gamma_g$ as follows:

$$
\gamma_g = \delta_{\text{CATE},g} - \delta_{\text{CATE},g'}
$$

This notation allow us to distinguish between the ATE in a subgroup, $\delta_{\text{CATE},g}$,  from the concept of effect measure modification $\gamma_g$.


#### Example: differential effects of screen-time on well-being among age groups

To illustrate the application of $\gamma_g$, consider a psychological intervention aimed at reducing screen-time to improve well-being. In this context, let $G = \text{'adolescents'}$ and $G' = \text{'adults'}$. Assume that we estimate $\delta_{\text{CATE}, \text{adolescents}} = 10$-point increase in a well-being scale and $\delta_{\text{CATE}, \text{adults}} = 4$-point increase.

We can calculate $\gamma_{\text{adolescents}}$ as:

$$
\gamma_{\text{adolescents}} = \delta_{\text{CATE}, \text{adolescents}} - \delta_{\text{CATE}, \text{adults}} = 10 - 4 = 6
$$

In this example, $\gamma_{\text{adolescents}}$ indicates that the intervention is differentially more effective in improving well-being for adolescents compared to adults by an average of 6 points on the well-being scale.

This serves as an instance of "Effect Modification" (or equivalently "Effect Measure Modification"), indicating that the treatment effect of reduced screen-time is not uniformly beneficial across age groups. The term $\gamma_g$ becomes a critical metric for assessing this heterogeneity.


#### Relating Average Treatment Effect (ATE) to Differential Effects Across Groups


Consider the quantity $\delta_{\text{ATE}}$ as it relates to subgroup-specific treatment effects ($\delta_{\text{CATE},g}$) and the differential treatment effect ($ \gamma_g $).

The ATE represents an average across all subgroups, weighted by their population sizes. If we denote $ p_{\text{adolescents}} $ and $ p_{\text{adults}}$ as the proportion of adolescents and adults in the population, respectively, then:

$$
\delta_{\text{ATE}} = p_{\text{adolescents}} \cdot \delta_{\text{CATE}_{\text{adolescents}}} + p_{\text{adults}} \cdot \delta_{\text{CATE}_{\text{adults}}}
$$

In our example, if adolescents make up 30% of the sample and adults make up 70%, then:

$$
\delta_{\text{ATE}} = 0.3 \cdot 10 + 0.7 \cdot 4 = 3 + 2.8 = 5.8
$$

Here, $\delta_{\text{ATE}}$ approximates the weighted average of $\delta_{\text{CATE}_{\text{adolescents}}}$ and$\delta_{\text{CATE}_{\text{adults}}}$. It should be noted that $\gamma_{\text{adolescents}} = 6$ underscores how the treatment effect is differentially stronger for adolescents. This differential effect is essentially obscured when looking solely at $\delta_{\text{ATE}}$.

By examining both $\delta_{\text{ATE}}$ and $\gamma_g$, we can make more precise inferences about the heterogeneous effects of interventions across different subpopulations. 


#### Formal definition of Effect Modification (or Effect Measure Modification)

Effect Modification occurs when the treatment effect varies across levels of a third variable, often termed the "modifier" or "effect modifier." Formally, it's defined as the interaction between the treatment variable $a$  and the modifier  $G$  in their effect on the outcome  $Y$ .

Mathematically, Effect Measure Modification is said to be present if:

$$ 
E[Y(a) | G=g_1] - E[Y(a') | G=g_1] \neq E[Y(a) | G=g_2] - E[Y(a') | G=g_2]
$$ 

Or in terms of our average treatment effects within subgroups ($\delta_{\text{CATE},g}$):

$$ 
\delta_{\text{CATE},g_1} \neq \delta_{\text{CATE},g_2}
$$ 

The term $\gamma_g$ which we defined as $\delta_{\text{CATE},g} - \delta_{\text{CATE},g'}$  would be a non-zero value when Effect Measure Modification is present.

Effect Measure Modification implies that the treatment does not act uniformly across different strata of the effect modifier, warranting subgroup-specific estimates of the treatment effect. Again, this concept is pivotal for tailoring interventions and identifying whom they benefit or harm the most.

### Populations

For whom do we estimate causal effects? A multitude of overlapping "groups" demands precise terminology.

#### Source Population

Source population: the origin of our study sample. This population harbours its own true average treatment effect $ATE_{\text{source}}$. 

<!-- This effect is essentially a weighted sum of the various subgroup effects. The representativeness of the sample sets the boundary for causal claims: a skewed sample undermines the generalisability of the ATE to the source population. -->


#### Target Population

Target population: the is the population fwe actually care about. It could be defined by location, demographics, or specific conditions unrelated to the source population. The closer the source matches the target in ways that are relevant to our causal questions, the stronger our causal inferences about the target population will be.


#### **Generalisability**

Results generalise when they are applicable to the broader population from which the sample is drawn -- the $PATE$, or is the population average treatment effect. We can approximate the PATE from the ATE using survey weights $W$:

$$
\text{Generalisability} = PATE \approx f_{W}(ATE_{\text{source}}, W)
$$

#### **Transportability**

Results are transportable when they apply to a different population than the one from which the sample was drawn. To express this:

$$
\text{Transportability} = ATE_{\text{target}} \approx f_{T}(ATE_{\text{source}}, T)
$$

Here, $T$ is a function mapping results from the source to the target population. Achieving transportability requires both data and scientific knowledge to understand how relationships between treatment, outcome, and covariates vary between source and target populations.



#### National Population

The Population Average Treatment Effect $ PATE_{\text{New Zealand}}$ is a weighted sum of the CATEs for each age group, using the proportions of each group within the population as weights:

$$
PATE_{\text{New Zealand}} = w_{20-30} \times \delta_{\text{CATE}, 20-30} + w_{31-40} \times \delta_{\text{CATE}, 31-40} + w_{41-50} \times \delta_{\text{CATE}, 41-50}
$$

For example, suppose:

- $\delta_{\text{CATE}, 20-30} = -2$ (screen time decreases well-being by 2 units for age 20-30)
- $\delta_{\text{CATE}, 31-40} = -1$ (screen time decreases well-being by 1 unit for age 31-40)
- $\delta_{\text{CATE}, 41-50} = 0$ (no effect for age 41-50)

Suppose the population weights are:

- $w_{20-30} = 0.4$
- $w_{31-40} = 0.3$
- $w_{41-50} = 0.3$

The $PATE_{\text{New Zealand}}$ would be:


$$
PATE_{\text{New Zealand}} = 0.4 \times (-2) + 0.3 \times (-1) + 0.3 \times 0 = -0.8 - 0.3 + 0 = -1.1
$$


So, the $PATE_{\text{New Zealand}}$ indicates that, on average, screen time reduces well-being by 1.1 units across the New Zealand population. This takes into account the age distribution and estimated treatment effects for each age group.[^noterestricted]

[^noterestricted]: Technically we have computed a *restricted PATE* because the age groups in New Zealand are wider than the 20-50 year old range described here.


#### **Full Data and Observed Data**

The full data is the random vector $(Y(1), Y(0), A, L)$ for covariates $L$, while the observed data $(Y, A, L)$ is a coarsening of the full data with $Y = A \cdot Y(1) + (1-A) \cdot Y(0)$ [@ogburn2021].

Absent assumptions, we cannot learn about contrasts from the observed data, because they are functionals of (partially) unobserved potential outcomes.


| Data Type      | $Y(1)$                | $Y(0)$                | $A$          |
|----------------|---------------------------|---------------------------|------------------|
| Full Data      | Counterfactual $Y(1)$ | Counterfactual $Y(0)$ | Observed $A$ |
| Observed Data  | Observed $Y$ if $A=1$| Observed $Y$ if $A=0$ | Observed $A$ |


### **Confounding**

A condition in which the observed association between the treatment and the outcome in the data does not reflect a causal association.

#### **Confounder**

Any variable that when conditioned upon, perhaps in conjunction with other confounders, reduces or minimises confounding. In the scientific investigation of causality, one must often grapple with confounders. These may be categorised into two distinct types:

-   **Measured Confounder** ($L$): A variable that has been meticulously documented in the study. The symbol $L$ is used to represent this kind of confounder, and it is a variable that has influence on both the treatment and the outcome of interest. By incorporating this information into the analysis, researchers can diminish or eradicate bias in the causal estimation.

-   **Unmeasured Confounder** ($U$): Represented by the symbol $U$, an unmeasured confounder is a variable that is influential on both the treatment and the outcome but, regrettably, has not been captured in the study's data. The inability to control for $U$ can potentially introduce an erroneous bias in the estimation of the causal relationship, a situation that can complicate the understanding of true causal effects. This scenario is a subject of considerable concern, especially in observational studies where information on all confounders might not be attainable.

#### **Causal Estimand**

A causal estimand names the causal contrast of interest, specifying the levels of exposure to be contrasted, potential outcomes of interest, the scale of the causal contrast, and the target population for whom the causal contrast applies.

#### **Statistical Estimand**

A statistical estimand is a functional of the observed data that corresponds to the causal estimand of interest. It reduces the causal question to a statistical one, identifying a quantity in the observed data that will provide information about the causal estimand.

#### **Estimator**

An estimator is a statistical function of the observed data, denoted as $\hat{\theta}(Y, A, L)$, that provides an estimate of the statistical estimand. It translates the observed data into a single value, approximating the unknown parameter. In the context of causal inference, an estimator is used to estimate the statistical estimand, thereby providing information about the corresponding causal estimand.

#### **Elicitation**

Elicitation refers to the process of gathering expert opinion or knowledge to inform a model or analysis. We shall see the importance of elicitation throughout.

### Experiments

### **Average Causal Effects in Experiments**

Estimating a causal effect means comparing what actually happened to what would have happened if things had been different.

In an experiment, we place people into groups, give a treatment, and then see what happens. But we can never see what would have happened to a person in a different group. We only see what happens in the group they were placed in.

When we talk about average effects of a treatment, things are different. In a perfect experiment, we can compare the groups because we know the assignment to groups is random. We can work out the average effect of the treatment by comparing what generally happened in the treatment group to what generally happened in the control group.

The random way we place people in groups means that, in theory, anyone in one group could have been in the other. So, we can work out the average effect without having to know exactly what would have happened to each individual in both groups.

#### **Conditional Causal Effects in Experiments**

The effect of a treatment might change based on factors such as age or education.

In an experiment, we can study people who are similar in some way, like being the same age. We compare how the treatment works for them against a control group without the treatment.

This is a conditional causal effect. It tells us how the treatment might work for certain groups of people. It helps us understand who the treatment helps the most.

Randomisation is essential here, too. Because we put people into groups randomly, we can trust that differences in how the groups respond, on average, owe to the treatment, not to other factors. We do not need to guess what would have happened members of a different group had they been assigned to a different condition. Random assignment enables us to compute group-level responses within conditions, bypassing the need to observe what cannot, in reality, ever be observed -- individual-level contrasts.

#### **Estimating Causal Effects outside of Experiments Requires Assumptions**

Experiments are the best method for estimating causal effects. They use randomisation and control to identify causation. However, experiments are not always possible or ethical. In those cases, researchers turn to observational studies. These studies are more complex. They do not have random assignment to treatment conditions, and the conditions may vary widely. Some individuals might not even have a chance to receive one or both levels of the treatment being studied.

Therefore, to estimate causal effects in observational settings, certain assumptions must be met $citations$. These assumptions are crucial. Without them, it is risky to draw conclusions about causation outside of experimental settings $cite$.

The three fundamental assumptions are the exchangeability assumption, the causal consistency assumption, and the positivity assumption. Each one serves a unique role in ensuring that the causal effects identified in observational studies are valid and reliable.

### Three fundamental assumptions of causal inference

#### **The Exchangeability Assumption**

In observational studies, the lack of randomisation can lead to challenges in identifying causal effects.

Specifically, the assumption requires that, after controlling for measured variables, the potential outcomes under various exposure levels must be independent of the actual exposure level experienced [@hernán2023].

The exchangeability assumption addresses this issue. It requires balance in the treatment conditions, considering factors that might influence the outcome. When the data do have balance across the treatment conditions, we say there is "confounding." The task is removing confounding is one of obtaining balance of the kind that randomisation provides in experimental settings.

In the following sections, we will outline methods for addressing the exchangeability assumption. Because the data do not typically clarify whether counfounding has been fully addressed, we recommend sensitivity analysis. Such analyses describe how much unmeasured confounding would be required to explain away the observed association between the exposure and the outcome.

#### **The Causal Consistency Assumption**

In observational studies, researchers lack control over the treatment, creating complexity in discerning causal effects.

The causal consistency assumption helps navigate this complexity. It mandates that the exposures being compared align with specific, well-defined interventions in the data [@hernán2023].

This means that the exposure or treatment must be consistent across the study, and it should not change over time or vary among subjects in ways that might alter the outcome (see also: @chatton2020).

Consider a multifaceted "treatment" such as weight loss. In real-world weight loss, various means may be employed: dieting, exercise, stress, severe disease, surgical procedures like stomach stapling. Each constitutes a different exposure with unique effects.

In experiments, experimental control allows us to define the exposure precisely, such as weight loss by dieting. By controlling other factors, we can isolate the causal effect of that specific intervention. In this scenario, the causal consistency assumption is satisfied because the intervention does not vary in ways that would affect the result.

In observational studies, ensuring causal consistency becomes more challenging. Studies might include individuals losing weight through various means, with differing motivations, methods, and individual characteristics [@hernan, @tyler]. Without control over these factors, the causal consistency assumption may be violated, complicating the isolation of a specific intervention's effect like dieting.

Though estimating causal effects in heterogeneous treatment settings is complex, it is not incoherent. A mathematical framework, known as causal inference under multiple versions of treatment, shows that unbiased estimation is feasible if all treatment versions meet the exchangeability assumption. Practical challenges do arise, though. Without observing the many versions of treatment, evaluating the exchangeability assumption may become difficult, and the utility of the estimation can be limited. For example, estimating the effect of weight loss through a random assignment to either dieting or heart disease may provide little meaningful insight due to the heterogeneous nature of the treatments.

Unfortunately, the causal consistency assumption typically cannot be verified by inspecting the data. Rather, researchers must rely on a clear understanding of the subject matter, make informed decisions about the definitions of exposures and treatments, and use thorough study design and statistical methods. They must ensure that the exposure or intervention being studied is consistently defined and measured across subjects in the study, without variation that could affect the outcome. This often involves careful consideration of the context, consultation with domain experts, and methodological choices that reflect the underlying science of the phenomenon being studied.

The protocols we describe below are aimed to help researchers obtain sensible inference by focussing their attention these demands for contextual attention informed by expert advice.

#### **The Positivity Assumption**

There is a non-zero probability of receiving every exposure value within all strata of covariates [@hernán2023].

In simpler terms, it means that every subject in the study has some chance of receiving each level of the exposure or treatment.

If this assumption is not met, it becomes impossible to make meaningful comparisons between different levels of exposure, as some of the comparisons would be based on groups where the exposure was never applied.

Unlike the exchangeability and causal consistency assumptions, we can sometimes verify whether the positivity assumption is satisfied by inspecting the data.

#### **Identification Strategy**

An identification strategy refers to the set of assumptions and methodologies employed to ensure that a causal estimand (recall -- a quantity representing a causal effect) can be determined uniquely from the observed data. It is the process through which researchers make a bridge from the statistical estimand, derived from the observed data, to the causal estimand that represents the actual causal effect of interest. Identifiability relies on assumptions such as exchangeability, positivity, and consistent measurement. The validity of these assumptions enables a unique mapping of the causal estimand from the statistical estimand, facilitating causal inference from observational data.




<!-- ### Scale of effect -->

<!-- Average causal effects can be inferred by contrasting the expected outcome when a population is exposed to an exposure level, $E[Y(A = a)]$, with the expected outcome under a different exposure level, $E[Y(A=a')]$. -->

<!-- For a binary treatment with levels $A=0$ and $A=1$, the Average Treatment Effect (ATE), on the difference scale, is expressed: -->

<!-- $$ATE_{\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]$$ -->

<!-- On the risk ratio scale, the ATE is expressed: -->

<!-- $$ATE_{\text{risk ratio}} = \frac{E[Y(1)|L]}{E[Y(0)|L]}$$ -->

<!-- Other effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest. We can also define the Average Treatment Effect on the Treated (ATT) : -->

<!-- $$ATT_{\text{risk difference}} = E[Y(1) - Y(0)|A=1,L]$$ -->

<!-- $$ATT_{\text{risk ratio}} = \frac{E[Y(1)|A=1,L]}{E[Y(0)|A=1, L]}$$ -->

<!-- Another common estimand is the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the entire population if applied universally to that population. This quantity can be expressed: -->

<!-- $$PATE_{\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)$$ -->

<!-- $$PATE_{\text{risk ratio}} = f\left(\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\right)$$ -->

<!-- where $f$ is a function that incorporates weights $W$ into the estimation of the expected outcomes. These weights are given from census estimates for the wider population. Note: I will show you how to use weights in future seminars. -->

<!-- We might also be interested in identifying effects specific to certain strata, such as risk differences or risk ratios, as they are modified by baseline indicators. Denote a stratum of interest by $G$. We may then compute: -->

<!-- $$ATE_{G,\text{risk difference}} = E[Y(1) - Y(0)|G, L]$$ -->

<!-- $$ATE_{G,\text{risk ratio}} = \frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}$$ -->

#### Considerations

-   In the causal inference literature, the concept we use to make sense of stratum specific comparisons is called "effect modification."
-   By inferring effects within strata, we may evaluate whether the effects of different exposures or treatments on some well-defined outcome (measured in some well-defined time-period after the exposure) differ depending on group measurement.
-   The logic of effect modification differs slightly from that of interaction.



## Part 2: Three-Wave Panel Designs

Our goal is to explain how researchers can use three waves of data to satisfy the assumptions needed for causal inference.

Put differently, we aim to demonstrate how, with three waves of data, researchers can emulate the conditions found in a randomised experiment so that they may address causal questions out of experiments.

To begin, some definitions:

-   **Wave**: a wave is a time interval where measurements are taken. It is placed on a timeline, so there are earlier and later intervals. The length can vary, but the order is specific.

-   **Treatment (or Exposure)**: a treatment refers to an event or condition applied to some individuals but not others. In causal terms, it is what we consider the "cause." Our discussion here will be limited to investigating the effects of one cause.

-   **Outcome**: an outcome is what we study as the effect of the treatment. It is the result we are interested in measuring.

-   **Confounding**: when the observed relationship between the treatment and the outcome may be influenced by another variable, not just the treatment itself, we say there may be confounding.

-   **Confounder**: a confounder is a variable that reduces confounding when it is accounted for in the study.

-   **Panel Design**: a panel design follows the same individuals over time. It enables baseline controls and connects treatments to outcomes.

-   **Baseline**: wave 0, or the baseline, is the interval in which we measure confounders to deal with confounding in a three-wave panel design.

-   **Treatment Wave**: wave 1 is the interval in which we measure the treatment or exposure is measured. Other variables at this wave are generally not included. However, we will explain how to address causal questions in which the effect of a treatment may vary between groups measured at baseline. That is, we will explain how to identify conditional causal effects.

-   **Outcome Wave**: wave 2 is the interval is the interval in which we measure, you guessed it, the outcome. There may be more than one outcome measured.

### Step 1. Defining the exposure: measure it at wave 0 and wave 1

We begin with a well-defined exposure.

Consider the causal effect of attending religious services. The first critical step involves defining the exposure in the context of a hypothetical intervention. What aspect is of interest to us? Is it a comparison of attendance versus non-attendance? Are we distinguishing between weekly and monthly attendees? Perhaps, we are interested in a different facet altogether? Visualising a hypothetical experiment - even when it is not feasible - reveals the need for a precise intervention specification [@hernán2022; @hernán2016a; @bulbulia2022].

The exposure is measured at wave 1 (i.e. +1 interval from baseline, wave 0). When estimating causal effects, the inclusion of exposure at the baseline carries three critical advantages:

a.  **Incidence effect interpretation**: incorporating the baseline exposure allows us to interpret the effect of exposure measured post-baseline as an incidence effect, not a prevalence effect [@vanderweele2020]. This means we can interpret the effect as the change due to a new occurrence (incidence) of the exposure, rather than the overall presence (prevalence) of the exposure. For example, in a study investigating the impact of weekly religious service attendance, including the baseline measure of attendance enables us to understand the effect of starting to attend weekly services (incidence), as opposed to simply being a regular attendee (prevalence).

<!-- -->

2.  **Confounding control**: the baseline exposure's inclusion helps to reduce unmeasured confounding arising from time-invariant confounders. These are variables that do not change over time and could confound the association between the exposure and the outcome if not properly accounted for. For instance, personal attributes such as unmeasured childhood religiosity could confound the association between religious service attendance and outcomes if not considered [@vantongeren2020].

3.  **Better evaluation of sample adequacy for rare exposures**: Particularly when the exposure is uncommon, such as switching from no religious service attendance to weekly attendance, measuring the baseline exposure and outcome exposure can help assess adequacy of a sample size. Suppose this switch occurs rarely in the non-religious population, say 1 in 1,000 non-attenders per year. To estimate causal effects while conditioning on a rich set of baseline covariates, we would need a large sample, potentially comprising hundreds of thousands of participants. Ideally researchers would understake investigations prior to data collection to assess feasiblity of causal inference. In this example, it might be more practical to examine changes within the religious population, that is -- assuming changes are more common within this group -- than it would be to investigate conversion events. However, by restricting to only religious people who change in their religious habits, we would then typically estimate a causal effect generalisable to the religious population from which the sample was drawn, rather than one that could be applied to the non-religious population. In any case, including the baseline exposure can help address these issues by providing a reference point for changes within the population studied.




### Step 2. Specify the Outcome(s) measure them at wave 0 and wave 2

After defining the exposure, we need to determine a well-defined outcome (or potentially several outcomes). For instance, we might be interested in understanding the effect of acquiring or losing religious service attendance on the frequency of volunteering (e.g., weekly, monthly, yearly). We have seen that statements like "the causal effects of religious change" are not insightful. We must articulate clearly the phenomenon under study and its timing (e.g., the +1-year effect on weekly volunteering from a shift of 0 to weekly or more religious service attendance).

Measuring the outcome at baseline offers several advantages:

a.  **Temporal Ordering**: controlling for the baseline measure of the outcome helps confirm the temporal order of the cause-effect relationship, thereby guarding against reverse causation.

b.  **Confounding Control**: when we also control for the exposure at baseline, an unmeasured confounder would have to negate the association between the exposure at one wave post-baseline and the outcome at two waves post-baseline, independent of the baseline effect, as show in @fig-dag-1. Note, this figure shows that **reduction of bias is preferable to no reduction if bias**. This is an important practical point: although it may not be possible to eliminate all confounding (the dashed arrows symbolise potential sources of uncontrolled bias), the processes of data collection and analysis can help reduce it. Putting this point more sharply, there is a great danger in allowing automated confounding control strategies to govern an analysis. Again, a minimal adjustment set cannot be insured. Our task is always to reduce confounding in the presence of unmeasured confounders. A strategy must be carefully considered at the design phase in light both of the problem at hand, and the data that might be collected.[^1]

[^1]: Given the typical uncertainty about having accounted for all unmeasured confounding, it is prudent for researchers to conduct sensitivity analyses [@shi2021].

```{tikz}
#| label: fig-dag-1
#| fig-cap: "Causal diagram adapted from Vanderweele et al.'s three-wave panel design. The dotted line indicates a reduction in bias arising from including baseline measures for the exposure and outcome. For an unmeasured confounder U to bias the exposure-outcome association, it would need to do so independently of these outcome and exposure baseline measures. The graph clarifies that by measuring confounders before the exposure and the exposure before the outcome, we reduce the potential for reverse causation, collider stratification, and mediator biases."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
\tikzstyle{cor} = [-, dashed, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {L$_{t0}$ \\A$_{t0}$ \\Y$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (Y) at (6, 0) {Y$_{t2}$};
\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [cor, draw = black, dotted] (A) to (Y);
\draw [-latex, bend left=50, draw =black] (L) to (Y);
\draw [-latex, bend right=50, draw =black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);


\end{tikzpicture}
```

### Step 3. Identify observable common causes of the exposure and the outcome

Next, we should identify all the potential confounders that, when adjusted for, can eliminate any non-causal association between the exposure and outcome. We should group these confounders under standard labels wherever they share the same functional dependencies in the graph. In a three-wave panel design, confounders are recorded during the baseline wave. As illustrated in @fig-dag-mediator-solution, recording confounders before the occurrence of the exposure minimises the potential for mediation bias. For example in @fig-dag-6, the variable $L$ on the graph might denote rich set of indicators such as Age, Gender, Education,Political Orientation, SES,$\dots$ Again, causal diagrams are meant to be human read. We should not include these additional nodes when including a single node will suffice for clarity and thoroughness.

### Step 4. Gather data for proxy variables of unmeasured common causes at the baseline wave

Recall @fig-dag-descendent-solution-2: if any unmeasured confounders influence both the exposure and outcome, but we lack direct measurements, we should make efforts to include proxies for them. Again, even if this strategy cannot eliminate all bias from unmeasured confounding, it will generally reduce bias.

### Step 5. State the target population for whom the causal question applies

We need to define for whom our causal inference applies. For this purpose, it is helpful to distinguish the concepts of source population and target population and between the concepts of generalisability and transportability.

1.  **The source population** is the population from whom our sample is drawn.

2.  **The target population** is the larger population for whom we aim to apply our study's results. The closer the source population matches the target population in structural features relevant to our causal questions, the stronger our causal inferences about the target population will be.

3.  **generalisability**: when the causal effect estimated from a sample applies to the target population beyond the sample population, we say the causal effect estimates are generalisable. This concept is also known as "external validity."

Let $PATE$ denote the population average treatment effect for the target population. Let $ATE_{\text{source}}$ denote the average treatment effect in the source population. Let $W$ denote a set of variables upon which the source and target population structurally differ. We say that results *generalise* if there is a function such that

$$PATE =  f(ATE_{\text{source}}, W)$$

4.  **Transportability**: when causal effects estimates may generalise to different settings and populations from which the source population was sampled, we say effects are transportable. Where $T$ denotes a set of variables upon which the source and the target population structurally differ, we say that results are transportable if there is a function such that

$$ATE_{\text{target}} \approx f(ATE_{\text{source}}, T)$$

This function similarly maps the average treatment effect from the source population to a target population. The function over $T$ might be more complex, as it must handle potential heterogeneity of effects and unobserved sources of bias. To assess transportability, we generally require information about the source and target populations and a specialist understanding. In Section 4, we will return to the concepts of generalisability and transportability as they pertain to sample selection.

### Step 6. Retention is a mission-critical imperative

for reasons we clarify in Part 4, sample retention is a mission-critical imperative because panel attrition opens novel pathways for bias. Researchers must develop protocols for tracking individuals as they change addresses, emails, phone numbers, and names. Moreover, developing and implementing strategies for motivating retention across the entire population of interest (not merely those willing to volunteer for science) is critical for causal human science. These strategies must be developed with specialist knowledge of the population under study and the participation and insights of the people being studied.

## Part 2. The Steps

### STEP 1 Formulate the Research Question

-   **Stating the Question:** Is my question clearly stated? If not, state it.
-   **Relevance of the Question:** Have I explained its importance? If not, explain.
-   **Ethical Considerations** How might this question affect people? How might not investigating this question affect people?
-   **Causality of the Question:** Is my question causal? If not, refine your question.
-   **Subgroup Analysis:** Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.
-   **Understanding the Framework:** Can I explain the potential outcomes framework, individual causal effects, the experimental method to obtain average causal effects, the fundamental assumptions of causal inference, and the estimation of causal effects in observational data? If not, review course materials.

### Data Requirements

-   **Type of Data:** Are my data experimental? If yes, your project may not fit this course.
-   **Time-Series Data:** Are my data time-series? If not, reconsider your causal question.
-   **Data Waves:** Do I have at least three waves of data? If not, beware of confounding control issues.
-   **Data Source:** Are my data from the NZAVS simulated data set? If not, consult with me.

### Defining the Outcome

-   **Outcome Variable:** Is the outcome variable *Y* defined? If not, define it.
-   **Multiple Outcomes:** Are there multiple outcomes? If yes, write them down.
-   **Outcome Relevance:** Can I explain how the outcome variable/s relate to my question? If not, clarify.
-   **Outcome Type:** Is my outcome binary and rare? If yes, consider logistic regression. If my outcome is continuous, consider z-transforming it or categorising it (consult an expert).
-   **Outcome Timing:** Does the outcome appear after the exposure? It should.

### Determining the Exposure

-   **Exposure Variable:** Is the exposure variable *A* defined? If not, define it.
-   **Multiple Exposures:** Are there multiple exposures? If yes, reassess; if only one exposure, proceed.
-   **Exposure Relevance:** Can I explain how the exposure variable relates to my question? If not, clarify.
-   **Positivity:** Can we intervene on the exposure at all levels of the covariates? We should be able to.
-   **Consistency:** Can I interpret what it means to intervene on the exposure? I should be able to.
-   **Exchangeability:** Are different versions of the exposure conditionally exchangeable given measured baseline confounders? They should be.
-   **Exposure Type:** Is the exposure binary or continuous? If continuous, z-transform it or consider categorising it (consult an expert).
-   **Exposure Timing:** Does the exposure appear before the outcome? It should.

### Accounting for Confounders

-   **Baseline Confounders:** Have I defined my baseline confounders *L*? I should have.
-   **Justification:** Can I explain how the baseline confounders could affect both *A* and *Y*? I should be able to.
-   **Timing:** Are the baseline confounders measured before the exposure? They should be.
-   **Inclusion:** Is the baseline measure of the exposure and the baseline outcome included in the set of baseline confounders? They should be.
-   **Sufficiency:** Are the baseline confounders sufficient to ensure balance on the exposure, such that *A* is independent of *Y* given *L*? If not, plan a sensitivity analysis.
-   **Confounder Type:** Are the confounders continuous or binary? If so, consider converting them to z-scores. If they are categorical with three or more levels, do not convert them to z-scores.

### Drawing a Causal Diagram with Unmeasured Confounders

-   **Unmeasured Confounders:** Does previous science suggest the presence of unmeasured confounders? If not, expand your understanding.
-   **Causal Diagram:** Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding? I should have.
-   **M-Bias:** Have I considered the possibility of M-Bias? If not familiar, we'll discuss later.
-   **Measurement Error:** Have I described potential biases from measurement errors? If not, we'll discuss later.
-   **Temporal Order:** Does my DAG have time indicators to ensure correct temporal order? It should.
-   **Time Consistency:** Is my DAG organized so that time follows in a consistent direction? It should.

### Identifying the Estimand

-   **Causal Estimand:** Is my causal estimand one of the following:

$$ATE_{G,(A,A')} = E[Y(1) - Y(0)|G, L]$$

$$ATE_{G,(A/A')} = \frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}$$

If yes, you're on the right track.

### Understanding Source and Target Populations

-   **Populations Identified:** Have I differentiated between my source and target populations? I should have.
-   **Generalisability and Transportability:** Have I considered whether my results generalise to the source population and transport to a different population? I should have.

### Setting Eligibility Criteria

-   **Criteria Stated:** Have I stated the eligibility criteria for the study? I should have.

### Describing Sample Characteristics

-   **Descriptive Statistics:** Have I provided descriptive statistics for demographic information taken at baseline? I should have.
-   **Exposure Change:** Have I demonstrated the magnitudes of change in the exposure from baseline to the exposure interval? I should have.
-   **References:** Have I included references for more information about the sample? I should have.

### Addressing Missing Data

-   **Missing Data Check:** Have I checked for missing data? I should have.
-   **Missing Data Plan:** If there is missing data, have I described how I will address it? I should have.

### Selecting the Model Approach

-   **Approach Decision:** Have I decided on using G-computation, IPTW, or Doubly-Robust Estimation? I should have.
-   **Interaction Inclusion:** Have I included the interaction of the exposure and baseline covariates? I should have.
-   **Large Data Set:** If I have a large data set, should I include the interaction of the exposure, group, and baseline confounders? I should consider it.
-   **Model Specification:** Have I double-checked the model specification? I should.
-   **Outcome Specifics:** If the outcome is rare and binary, have I specified logistic regression? If it's continuous, have I considered converting it to z-scores?
-   **Sensitivity Analysis:** Am I planning a sensitivity analysis using simulation? If yes, describe it (e.g. E-values.)

### d. Highlight unmeasured pre-treatment covariates

Let **U** denoted unmeasured pre-treatment covariates that may potentially bias the statistical association between *A* and *Y* independently of the measured covariates.

### Consider:

-   To affect *Y* and *A*, *U* must occur before *A*.
-   It is useful to draw a causal diagramme to illustrate all potential sources of bias.
-   Causal diagrammes are qualitative tools that require specialist expertise. We cannot typically obtain a causal graph from the data.
-   A causal diagramme should include only as much information as is required to assess confounding. See @fig-dag-outcomewide for an example.
-   Because we cannot ensure the absence of unmeasured confounders in observational settings, it is vital to conduct sensitivity analyses for the results. For sensitivity analyeses, we use E-values, a topic for a latter seminar.

```{tikz}
#| label: fig-dag-outcomewide
#| fig-cap: "Causal graph: three-wave panel design." 
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {t0/L \\t0/A \\t0/Y};
\node [rectangle, draw=white] (A) at (4, 0) {t1/A};
\node [ellipse, draw=white] (Y) at (6, 0) {t2/Y};
\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, draw=red, dotted] (A) to (Y);
\draw [-latex, bend left=50, draw =black] (L) to (Y);
\draw [-latex, bend right=50, draw =black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);


\end{tikzpicture}
```

### Summary Step 1: Consider how much we need to do when asking a causal question!

We discover that asking a causal question is a multifaceted task. It demands careful definition of the outcome, including its timing, the exposure, and covariates. It also requires selecting the appropriate scale for causal contrast, controlling for confounding, and potentially adjusting for sample weights or stratification. Finally, when asking a causal question, we must consider for whom the results apply. Only after following these steps can we then ask: "How may we answer this causal question?"

## STEP 2: ANSWER A CAUSAL QUESTION

#### Obtain longitudinal data

Note that causal inference from observational data turns on the appropriate temporal ordering of the key variables involved in the study.

Recall we have defined.

-   **A**: Our exposure or treatment variable, denoted as **A**. Here we consider the example of 'Church attendance'.

-   **Y**: The outcome variable we are interested in, represented by **Y**, is psychological distress. We operationalise this variable through the 'Kessler-6' distress scale.

-   **L**: The confounding variables, collectively referred to as **L**, represent factors that can independently influence both **A** and **Y**. For example, socio-economic status could be a confounder that impacts both the likelihood of church attendance and the levels of psychological distress.

Given the importance of temporal ordering, we must now define time:

-   **t** $\in$ T: Let $t$ denote within a multiwave panel study with **T** measurement intervals.

Where $t/\text{{exposure}}$ denotes the measurement interval for the exposure. Longitudinal data collection provides us the ability to establish a causal model such that:

$$t_{confounders} < t_{exposure}< t_{outcome}$$

To minimise the posibility of time-varying confounding and obtain the clearest effect estimates, we should acquire the most recent values of $\mathbf{L}$ preceding $A$ and the latest values of $A$ before $Y$.

Note in @fig-dag-outcomewide, We use the prefixes "t0, t1, and t2" to denote temporal ordering. We include in the set of baseline confounders the pre-exposure measurement of *A* and *Y*. This allows for more substantial confounding control. For unmeasured confounder to affect both the exposure and the outcome, it would need to do so independently of the pre-exposure confounders. Additionally, including the baseline exposure gives us an effect estimate for the incidence exposure, rather than the prevelance of the exposure. This helps us to assess the expected change in the outcome were we to initate a change in the exposure.

### Include the measured exposure with baseline covariates

Controlling for prior exposure enables the interpretation of the effect estimate as a change in the exposure in a manner akin to a randomised trial. We propose that the effect estimate with prior control for the exposure estimates the "incidence exposure" rather than the "prevalence exposure" [@danaei2012]. It is crucial to estimate the incidence exposure because if the effects of an exposure are harmful in the short term such that these effects are not subsequently measured, a failure to adjust for prior exposure will yield the illusion that the exposure is beneficial. Furthermore, this approach aids in controlling for unmeasured confounding. For such a confounder to explain away the observed exposure-outcome association, it would need to do so independently of the prior level of the exposure and outcome.

### State the eligibility criteria for participation

This step is invaluable for assessing whether we are answering the causal question that we have asked.

#### Consider:

-   Generalisability: we cannot evaluate inferences to a target group from the source population if we do not describe the source population
-   Eligibility criteria will help us to ensure whether we have correctly evaluated potential measurement bias/error in our instruments.

For example, the New Zealand Attitudes and Values Study is a National Probability study of New Zealanders. The details provided in the supplementary materials describe how individuals were randomly selected from the country's electoral roll. From these invitations there was typically less than 15% response rate. How might this process of recruitment affect generalisability and transportability of our results?

-   Aside: discuss per protocol effects/ intention to treat effects

### Determine how missing data will be handled

-   As we will consider in the upcoming weeks, loss to follow up and non-response opens sources for bias. We must develop a strategy for handling missing data.

### State a statistical model

The models we have considered in this course are G-computation, Inverse Probability of Treatement Weighting, and Doubly-Robust estimation.

### Reporting

Consider the following ideas about how to report one's model:

-   **Estimator**: Doubly robust where possible.
-   **Propensity Score Reporting:** Detail the process of propensity score derivation, including the model used and any variable transformations.
-   **WeightIt Package Utilisation:** Explicitly mention the use of the 'WeightIt' package in R, including any specific options or parameters used in the propensity score estimation process.
-   **Method Variations:** Report if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as 'ebal', 'energy', and 'ps'.
-   **Continuous Exposures:** Highlight that for continuous exposures, only the 'energy' option was used for propensity score estimation.
-   **Subgroup Estimation:** Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.
-   **Covariate Balance:** Include a Love plot to visually represent covariate balance on the exposure both before and after weighting.
-   **Weighting Algorithm Statistics:** Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit.
-   **Outcome Regression Model:** Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation.
-   **Subgroup Interaction:** Address whether the subgroup was included separately as an interaction in the outcome model, and if the model successfully converged.
-   **Model Coefficients:** Note that the model coefficients should not be interpreted, as they are not meaningful in this context.
-   **Confidence Intervals and Standard Errors:** Describe the methods used to derive confidence intervals and standard errors, noting the use of the 'clarify' package in R for simulation based inference.

### Example of how to report a doubly robust method in your report

The Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:

**Step 1** involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.

**Step 2** focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.

**Step 3** entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.

**Step 4** is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.

**Step 5** involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods [@greifer2023]. This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.

### Inference

Consider the following ideas about what to discuss in one's findings. The order of exposition might be different.

1.  **Summary of results**: What did you find?

2.  **Interpretation of E-values:** Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.

3.  **Causal Effect Interpretation:** What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.

4.  **Comparison of Subgroups:** Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.

5.  **Uncertainty and Confidence Intervals:** Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.

6.  **Generalisability and Transportability:** Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)

7.  **Assumptions and Limitations:** Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.

8.  **Theoretical Relevance**: How are these findings relevant to existing theories.

9.  **Replication and Future Research:** Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.

10. **Real-world Implications:** Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research.

## Part X Estimators

### Conditional estimators

#### Beyond Observed Associations: The Causal Hurdle

The observed association can be misleading because it captures the relationship between treatment $A$ and outcome $Y$ without adjusting for confounding variables $L$. The observed association often diverges from the true causal effect $\delta$, which we can express as:

$$
\delta = f_{\text{causal}}(Y, A | L)
$$

Note:

- $f_{\text{causal}}$ is the causal function capturing the relationship between $Y$ and $A$, conditioned on $L$.
- $L$ are the confounding variables.

One approach to isolate $\delta$ from $f_{\text{observed}}(Y, A)$ is to use techniques like matching, inverse probability weighting (IPW), or instrumental variables. These methods aim to emulate a randomized experiment by adjusting for $L$.

For example, to adjust for confounders in our linear model, we would modify it as:

$$
Y = \beta_0 + \beta_1 A + \beta_2 L + \epsilon
$$

Here, $\beta_2$ represents the vector of coefficients for confounding variables $C$.

In essence, merely relying on $\beta_1$ from the naive OLS regression can result in biased causal inferences. To move from observed associations to causal estimates, we must adjust for confounders and potentially use more advanced statistical techniques.

#### Marginal Structural Models

A marginal structural model (MSM) is a causal model designed to estimate causal effects from observational data by addressing confounding and time-dependent covariates that may be simultaneously confounders and intermediate variables. MSMs use inverse probability weighting (IPW) to create a pseudo-population where the treatment assignment is independent of measured confounders.

Mathematically, consider a treatment $A$ and outcome $Y$. The MSM specifies the counterfactual outcome $Y^a$ under treatment $a$ as:

$$
E[Y^a] = \alpha + \theta a
$$

where $\alpha$ is an intercept, and $\theta$ is the causal effect of interest. 

Inverse probability weights $e$ are calculated based on the conditional probability of receiving the observed treatment given the covariates:

$$
e_i = \frac{1}{P(A=a_i \mid \text{covariates})}
$$

For stabilised weights, a numerator term is added:

$$
e_i = \frac{P(A=a_i)}{P(A=a_i \mid \text{covariates})}
$$

The MSM is then fitted to the weighted pseudo-population to estimate $\theta$, which approximates the causal effect of the treatment in the entire source population.

For example, in our screen time and well-being study, an MSM could help isolate the direct effect of screen time on well-being while controlling for confounding variables like age, socioeconomic status, or previous well-being measures. The inverse probability weights could account for the fact that different individuals have varying propensities to engage in screen time based on these confounders.


#### Survey Weights vs IPTW

Both survey weights and inverse probability of treatment weights (IPTWs) adjust for non-representativeness, but they serve different purposes and arise from different paradigms.

#### **Survey Weights**

Survey weights, commonly denoted as \( W \), correct for unequal probability of selection in the sampling process. These weights aim to make the sample reflective of the source population. In a causal inference context, survey weights are useful to make the estimated average treatment effect (ATE) more generalisable to the source population. Mathematically, 

$$
ATE_{\text{source}} = \sum_{i=1}^N W_i \left( Y_{i1} - Y_{i0} \right)
$$

where $N$ is the number of subjects, $Y_{i1}$ and $Y_{i0}$ are potential outcomes under treatment and control, respectively, for subject $i$.

#### **Inverse Probability of Treatment Weights (IPTWs)**

IPTWs, denoted by $e$, are designed to control for confounding by equating the distribution of observed covariates between treatment and control groups within the sample. The aim is to make the treatment assignment as good as random, or ignorable. IPTWs are calculated as follows:

$$
e_i = \frac{1}{P(A=a_i \mid \text{covariates})}
$$

When stabilised,

$$
e_i = \frac{P(A=a_i)}{P(A=a_i \mid \text{covariates})}
$$

#### **Differences**

1. **Purpose**: Survey weights target the representativeness of the sample concerning the source population, while IPTWs aim to eliminate confounding within the sample.
   
2. **Calculation**: Survey weights often derive from design factors like stratification or clustering. IPTWs are calculated based on observed treatment and covariate distributions.

3. **Use Case**: Survey weights are often useful when generalisability to a broader population is the focus. IPTWs are useful in estimating internally valid causal effects within the sample.

In summary, while both sets of weights serve to adjust for non-representativeness or imbalance, they do so in differing contexts and to achieve different aims. Both can coexist in the same analysis if both generalisability and internal validity are concerns.
### Average Treatment Effects (Difference Scale)

### **G-computation Estimator**

**Step 1** Estimate the outcome model. Fit a model for the outcome $Y$, conditional on the exposure $A$, and the covariates $L$. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, and confounders.

$$ \hat{E}(Y|A,L) = f_Y(A,L; \theta_Y) $$

This equation represents the expected value of the outcome $Y$ given the exposure $A$, and covariates $L$, as modeled by the function $f_Y$ with parameters $\theta_Y$.

**Step 2** Simulate potential outcomes. For each individual, predict their potential outcome under the intervention $A=a$ using the estimated outcome model:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y]$$

We also predict the potential outcome for everyone under the causal contrast, setting the intervention to $A=a'$:

$$  \hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y]$$

In these equations, $Y$ represents the potential outcome, $A$ is the intervention, and $L$ are the covariates.

**Step 3** Calculate the estimated difference:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

This difference $\hat{\delta}$ represents the average causal effect of changing the exposure from level $a'$ to level $a$.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### **Inverse Probability of Treatment Weighting (IPTW) Estimator**

**Step 1** Estimate the propensity score. The propensity score $e(L)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

Here, $f_A(L; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$. Then, we calculate the weights for each individual, denoted as $v$:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$:

$$ \hat{E}(Y|A; V) = f_Y(A; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $\theta_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation.

**Step 3** Simulate potential outcomes. For each individual, simulate their potential outcome under the hypothetical scenario where everyone is exposed to the intervention $A=a$:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a')  = \hat{E}[Y|A=a'; \hat{\theta}_Y,  v_i]$$

The expectation is calculated for each individual $i$, with individual-specific weights $v_i$.

**Step 4** Estimate the average treatment effect as the difference in the predicted outcomes:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The estimated difference $\hat{\delta}$ represents the ATE. We use simulation-based inference methods to compute standard errors and confidence intervals.

We again, use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Doubly Robust Estimation

**Step 1** Estimate the propensity score. The propensity score $e(L)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

Here, $f_A(L; \theta_A)$ is a function (statistical model) estimating the probability of exposure $A = 1$ given covariates $L$. We calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

**Step 2** Fit a weighted outcome model. Using the weights $v$, fit a model for the outcome $Y$, conditional on the exposure $A$.

$$ \hat{E}(Y|A, L; v) = f_Y(A, L ; \theta_Y, v) $$

Here, $f_Y$ is a function (such as a weighted regression model) with parameters $\theta_Y$. The weights $v$ are incorporated into the estimation process.

**Step 3** Simulate potential outcomes under different scenarios for each individual. For instance, simulate the outcome under the hypothetical scenario where everyone is exposed to intervention $A=a$:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y, v_i]$$

and also under the scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y, v_i]$$

**Step 4** Estimate the average causal effect. Compute the estimated expected value of the potential outcomes under each intervention level:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The difference $\delta$ represents the average causal effect of changing the exposure from level $a^{\prime}$ to level $a$.

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Subgroup estimators

### **G-computation for Subgroup Analysis Estimator**

**Step 1** Estimate the outcome model. Fit a model for the outcome $Y$, conditional on the exposure $A$, the covariates $L$, and subgroup indicator $G$. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, confounders, and subgroups.

$$ \hat{E}(Y|A,L,G) = f_Y(A,L,G; \theta_Y) $$

This equation represents the expected value of the outcome $Y$ given the exposure $A$, covariates $L$, and subgroup $G$, as modeled by the function $f_Y$ with parameters $\theta_Y$. This formulation allows for the prediction of the average outcome $Y$ given certain values of $A$, $L$, and $G$.

**Step 2** Simulate potential outcomes. For each individual in each subgroup, predict their potential outcome under the intervention $A=a$ using the estimated outcome model:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y]$$

We also predict the potential outcome for everyone in each subgroup under the causal contrast, setting the intervention for everyone in that group to $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y]$$

In these equations, $Y$ represents the potential outcome, $A$ is the intervention, $L$ are the covariates, $G=g$ represents the subgroup, and $\theta_Y$ are the parameters of the outcome model.

**Step 3** Calculate the estimated difference for each subgroup $g$:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

This difference $\hat{\delta}_g$ represents the average causal effect of changing the exposure from level $a'$ to level $a$ within each subgroup $g$.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 4** Compare differences in causal effects by subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

This difference $\hat{\gamma}$ represents the difference in the average causal effects between the subgroups $g$ and $g'$. It measures the interaction effect of the exposure $A$ and the subgroup $G$ on the outcome $Y$.

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### **Inverse Probability of Treatment Weighting (IPTW) for Subgroup Analysis Estimator**

**Step 1** Estimate the propensity score. The propensity score $e(L, G)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$ and subgroup indicator $G$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L, G) = f_A(L, G; \theta_A)$$

Here, $f_A(L, G; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$ and subgroup $G$. Then, we calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Thus, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

Note that we estimate propensity scores *separately* within strata of the subgroup for whom we are interested in effect modification. $v$ is the weight for each individual in a given subgroup $G$.

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$ and subgroup $G$. This can be represented as:

$$ \hat{E}(Y|A, G; V) = f_Y(A, G ; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation of $θ_Y$, but they are not themselves an additional variable within the model.

Note that in this formulation, unlike doubly-robust estimation, $L$ is not included as a variable in the outcome model, but its effect is accounted for through the weights $V$, which are calculated based on the estimated propensity scores that do include $L$.

**Step 3** Simulate potential outcomes. For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention $A=a$ regardless of their actual exposure level:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,G=g; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',G=g; \hat{\theta}_Y,  v_i]$$

Thus the expectation is calculated for each individual $i$ in each subgroup $g$, with individual-specific weights $v_i$.

**Step 4** Estimate the average causal effect for each subgroup as the difference in the predicted outcomes:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

The estimated difference $\hat{\delta}_g$ represents the average causal effect withing group $g$. We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 5** Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Doubly Robust Estimation for Subgroup Analysis Estimator

Doubly Robust Estimation is a powerful technique that combines the strengths of both the IPTW and G-computation methods. It uses both the propensity score model and the outcome model, which makes it doubly robust: it produces unbiased estimates if either one of the models is correctly specified.

**Step 1** Estimate the propensity score. The propensity score $e(L, G)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$ and subgroup indicator $G$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L, G) = f_A(L, G; \theta_A)$$

Here, $f_A(L, G; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$ and subgroup $G$. Then, we calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Thus, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

Note that we estimate propensity scores *separately* within strata of the subgroup for whom we are interested in effect modification. $v$ is the weight for each individual in a given subgroup $G$.

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$ and subgroup $G$. This can be represented as:

$$ \hat{E}(Y|A, L, G; V) = f_Y(A, L, G ; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation of $θ_Y$, but they are not themselves an additional variable within the model.

Note that in this formulation, unlike propensity score model, estimation, $L$ is included as a variable in the outcome model, Although imbalance in $L$ on $A$ is accounted for by the weights $V$, by including $L$ in the outcome model this method is doubly robust insofar as we will obtain a consistent effect estimate if either the propensity score or the outcome model is correctly specified. This property reduces the strength of the assumption of correct model specification.

**Step 3** For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention $A=a$ regardless of their actual exposure level:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone in each subgroup is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y,  v_i]$$

Thus the expectation is calculated for each individual $i$ in each subgroup $g$, with individual-specific weights $v_i$.

**Step 4** Estimate the average causal effect for each subgroup. Compute the estimated expected value of the potential outcomes under each intervention level for each subgroup:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

The difference $\delta_g$ represents the average causal effect of changing the exposure from level $a^{\prime}$ to level $a$ within each subgroup.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 5** Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

## Inverse Probability of Treatment Weighting (IPTW) Protocolos

We assess balance using **standardised mean differences**, **Mean and Max Difference Adjusted**

### Standardised means difference in the context of Inverse Probability of Treatment Weighting (IPTW)

Standardised means difference is a measure used to compare the difference between two groups.

### Definition:

1.  **Standardised Means Difference (SMD)**: SMD is used to express the size of the intervention effect in each study relative to the variability observed in that study. It is computed as the difference between means divided by a standard deviation of the data. Formula for SMD is: $$
    \text{SMD} = \frac{{\bar{X}_1 - \bar{X}_2}}{{s}}
    $$ where $\bar{X}_1$ and $\bar{X}_2$ are the means of the two groups, and $s$ is the pooled standard deviation.

2.  **Inverse Probability of Treatment Weighting (IPTW)**: IPTW uses propensity scores to create a synthetic sample in which the distribution of measured baseline covariates is independent of treatment assignment. It aims to mimic a randomised experiment by creating a balanced comparison.

3.  **Weighting IPTW with SMD**: Weighting using IPTW can adjust the SMD between the treated and untreated groups. The balance in covariates is often assessed by checking whether the absolute value of the SMD is close to 0.

### Step-by-step:

1.  **Estimate Propensity Score**: Use logistic regression, or other methods, to estimate the propensity score for each subject.

2.  **Calculate IPTW**: The weight for each subject is the inverse of the probability of receiving the treatment that was actually received. For treated subjects: $$
    w = \frac{1}{{\text{propensity score}}}
    $$ For untreated subjects: $$
    w = \frac{1}{{1 - \text{propensity score}}}
    $$

3.  **Compute Standardised Means Difference**: Calculate the SMD for each covariate using the IPTW, comparing the treated and untreated groups.

4.  **Assess Balance**: If the absolute value of the SMD for a covariate is close to 0, the groups are considered balanced for that covariate.

This approach allows for causal inference in observational studies, making the comparison of treated and untreated groups as if randomisation had occurred. It is crucial in causal inference, to minimise bias due to confounding variables.

### Min and Max adjusted average difference in means

When achieving balance using Inverse Probability of Treatment Weighting (IPTW), "Mean.Diff.Adj" and "Max.Diff.Adj" are specific statistics often used to assess the balance of covariates between the treatment and control groups after weighting. Definitions:

1.  **Mean.Diff.Adj**:
    -   Refers to the average difference in means of covariates between the treated and untreated groups after applying IPTW.
    -   Formula: $$
        \text{Mean.Diff.Adj} = \frac{{\sum w_i \cdot (X_{1i} - X_{0i})}}{{\sum w_i}}
        $$ where $w_i$ is the weight for subject $i$, and $X_{1i}$ and $X_{0i}$ are the values of the covariate for the treated and untreated subjects, respectively.
    -   Close to 0 indicates good balance.
2.  **Max.Diff.Adj**:
    -   Refers to the maximum absolute difference in means of covariates between the treated and untreated groups after applying IPTW.
    -   Formula: $$
        \text{Max.Diff.Adj} = \max \left| \frac{{\sum w_i \cdot (X_{1i} - X_{0i})}}{{\sum w_i}} \right|
        $$
    -   Close to 0 indicates good balance, and it focuses on the worst-balanced covariate, which could be a point of concern even if the overall mean difference is small.

The difference between "Mean.Diff.Adj" and "Max.Diff.Adj" in the context of Inverse Probability of Treatment Weighting (IPTW) lies in what they measure regarding the balance of covariates:

1.  **Mean.Diff.Adj**:
    -   Measures the **average** difference in means of covariates between the treated and untreated groups after applying IPTW.
    -   Reflects the overall balance across all covariates.
    -   A value close to 0 indicates good overall balance.
2.  **Max.Diff.Adj**:
    -   Measures the **maximum absolute** difference in means of covariates between the treated and untreated groups after applying IPTW.
    -   Focuses on the worst-balanced covariate, regardless of the overall balance.
    -   A value close to 0 indicates that even the most imbalanced covariate is well-balanced, but a high value could be a concern even if the mean difference is small.

In summary, while "Mean.Diff.Adj" provides a sense of the general balance achieved across all covariates, "Max.Diff.Adj" zeroes in on the single most imbalanced covariate. The former gives a global view, while the latter highlights the potentially problematic area, both crucial for understanding the balance achieved by IPTW.
