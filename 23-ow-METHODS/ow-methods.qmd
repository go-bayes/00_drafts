---
title: "Causal inference in three wave panels: a step-by-step guide"
abstract: | 
  How to estimate causal effects in three wave panel designs
author: 
  - name: Joseph A. Bulbulia
    orcid: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    affiliation: 
      - name: Victoria University of Wellington, New Zealand, School of Psychology, Centre for Applied Cross-Cultural Research
        department: Psychology/Centre for Applied Cross-Cultural Research
        city: Wellington
        country: New Zealand
        url: www.wgtn.ac.nz/cacr
execute:
  warning: false
  eval: true
  echo: false
  include: true
keywords:
  - DAGS
  - Causal Inference
  - Confounding
  - History
  - Psychology
  - Panel
format:
  pdf:
    sanitize: true
    keep-tex: true
    link-citations: true
    colorlinks: true
    documentclass: article
    classoption: [singlecolumn]
    lof: false
    lot: false
    geometry:
      - top=30mm
      - left=20mm
      - heightrounded
    include-in-header:
       - text: |
           \usepackage{cancel}
date: last-modified
csl: camb-a.csl
---

```{r}
#| label: load-libraries
#| echo: false
#| include: true
#| eval: true

# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# for latex graphs
# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


### ALWAYS RESTART R IN A FRESH SESSION ####

# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23-ow-methods"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)

# check path:is this correct?  check so you know you are not overwriting other directors
#push_mods

```

```{r}
#| label: ideas
#| echo: false
#| eval: false

# Notes 
# - introduction on counterfactaul contrasts
# - assumptions for casual inference. 
# - benefits of counterfactual data science
# - limitations of counterfactual data science.
# - add section on multiple imputation
# - note the benefits of outcome-wide approach - dimensions accross a domiain 
# - researchers must explain how the determined their domain
# - note: total effect vs other types of effect. here we discuss interventions 
# - effect modification: 
# - continuous outcomes: continuous exposures 
# - poisson & dispersion: currently e-values not useful. 

```

## Introduction

### Purpose

Here I describe how to calculate causal effects in three-wave panel designs. 

**Part 1** introduces definitions and notations

**Part 2** describes the three-wave panel, and its motiviations. 

**Part 3** develops a the step-by-step guide for conducting causal inference within this design. 

**Part 4** summarises reporting advice

An Appendix describes functions for executing the workflows. 


## **Part 1** Definitions and notation

#### **Treatment or Exposure**

A treatment or exposure, denoted by $A$, represents an intervention or condition in a study. We assume that it can take different levels such that $(A = a) \neq (A = a')$,  which correspond to different states or intensities of the intervention. 

We use the terms "potential outcomes" and "counterfactual outcomes" synonymously.  

In plain terms, the treatment is the "cause."


#### **Potential or Counterfactual Outcomes**

Potential or counterfactual outcomes, denoted by $Y$, represent the values that an outcome would take on if a treatment or exposure were, perhaps contrary to fact, set to a specific level [@ogburn2021].

We  use the terms "potential outcomes" and "counterfactual outcomes" synonymously.  

We denote a potential outcome using the notation $Y(A = a)$ or simply $Y(a)$.

#### **Causal Contrast**

A causal contrast is a function that quantifies a difference, at some scale, in potential outcomes under different treatment levels. 

Formally, a causal contrast is a function of potential outcomes: 

$$f_{\text{causal contrast}}(Y(a), Y(a'))$$

where $Y(a)$ and $Y(a')$ represent the potential outcomes under the specific treatment levels $A = a$ and $A = a'$, respectively.

Where $ATE$ denotes the average treatment effect, a causal contrast on the difference scale may be expressed:

$$\text{Average Treatement Effect}_\text{Difference Scale} = E[Y(a)] - E[Y(a')]$$

 A causal contrast on the ratio scale may be expressed:

$\text{Average Treatement Effect}_\text{Ratio Scale}= \frac{E[Y(1)]}{E[Y(0)]}$$



#### **Causal Estimand**

A causal estimand or simply "estimand" names the causal contrast of interest. 

To state a causal estimand requires stating:

1. The levels of the exposure to be contrasted. 
2. The potential outcomes of interest
3. The scale of the causal contrast
4. The target population for whom the causal contrast applies.



#### **Causal Effect**

We say there is a causal effect on the difference scale when a causal estimand does not equal zero, indicating that the exposure influence the outcome. For example:  

$$E[Y(a)|L] - E[Y(a')|L] \neq 0$$

We say there is a causal effect on the ratio scale when a causal estimand does not equal one. For example:


$$\frac{E[Y(1)|L]}{E[Y(0)|L]}\neq 1$$
where 1 and 0 represent specific levels of a binary exposure, and 
$L$ represents covariates.


#### **Observed Association**

The observed association is the relationship between treatment or exposure and the observed outcome in the sample data, we may generally express:

$$f_{\text{observed}}(Y, A)$$

For example the observed correlation between the exposure $A$ and outcome $Y$ in the data may be expressed as linear relationship using ordinary least squares (OLS) 



<!-- $$ \text{cor}(A, Y) = \frac{\sum_{i=1}^n (A_i - \bar{A})(Y_i - \bar{Y})}{\sqrt{\sum_{i=1}^n (A_i - \bar{A})^2 \sum_{i=1}^n (Y_i - \bar{Y})^2}}$$ -->

<!-- where $A_i$ and $Y_i$  are individual observations of treatment and outcome, respectively, and $\bar{A}$ and $\bar{Y}$ are the means of the treatment and outcome, respectively, over the sample of size $n$. This formula provides a measure of the linear relationship between the treatment or exposure variable $A$ and the observed outcome variable $Y$, accounting for the spread and direction of the relationship in the sample data. -->



$$Y = \beta_0 + \beta_1 A + \epsilon$$

where $Y$ is the outcome variable, $A$ is the treatment, $\beta_0$ is the outcome when A = 0, and $\beta_1$ is the slope when $A = 1$, and $\epsilon$ is the error term the OLS estimates for the slope (\( \beta_1 \)) and intercept (\( \beta_0 \)) are given by:

$$ \hat{\beta}_1 = \frac{\sum_{i=1}^n (A_i - \bar{A})(Y_i - \bar{Y})}{\sum_{i=1}^n (A_i - \bar{A})^2}$$

$$ \hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{A} $$

Here, $\bar{A}$ and $\bar{Y}$ are the means of $A$ and $Y$, respectively. These estimates minimise the sum of squared differences between the observed values of $Y$ and the values predicted by the linear model, hence the term "least squares."



#### **Bias**

We say there is bias when the observed association $ f_{\text{observed}}(Y,A)$ differs from the causal contrast $f_{\text{causal}}(Y(a), Y(a'))$. This difference may arise due to confounding, selection bias, measurement error, or other factors that distort the true causal effect.

These definitions allow for flexibility in describing various forms of causal contrast, while differentiating between the observed association in the data and the underlying causal relationship.

#### **Bias**
We say there is bias when the observed association between $f_{\text{obeserved}}(Y,A)$ differs from the causal association $f_{\text{caual}}(Y,A)$

#### **Confounding Bias** 

We say there is "confounding" when the observed relationship between the treatment and the outcome is influenced by another variable, not just the treatment itself. Confounding introduces bias. 



-   **Confounder**: a confounder is a variable that reduces confounding when it is accounted for in the study.


#### **Covariates**

Covariates, denoted by $L$, are variables that may provide information about other variables that are of interest in a study. Often, they are characteristics or measurements that might affect the outcome but are not the primary focus of investigation. In the context of causal inference, covariates can help in reducing bias by controlling for confounding factors, thereby assisting in a more accurate estimation of the causal effect of the treatment or exposure on the outcome.


#### **Effect Modifier**

An effect modifier, denoted by $G$, is a variable that modifies the magnitude or direction of the effect of a treatment or exposure on an outcome. Unlike a confounder, it does not cause bias in the estimate of the causal effect, but rather it reveals how the effect differs across levels or categories of $G$. Effect modifiers may be of interest for understanding understanding how the effect of the treatment or exposure varies in different subgroups or under varying conditions.

#### **Average Causal Effects in Experiments**

Estimating a causal effect means comparing what actually happened to what would have happened if things had been different.

In an experiment, we place people into groups, give a treatment, and then see what happens. But we can never see what would have happened to a person in a different group. We only see what happens in the group they were placed in.

When we talk about average effects of a treatment, things are different. In a perfect experiment, we can compare the groups because we know the assignment to groups is random. We can work out the average effect of the treatment by comparing what generally happened in the treatment group to what generally happened in the control group.

The random way we place people in groups means that, in theory, anyone in one group could have been in the other. So, we can work out the average effect without having to know exactly what would have happened to each individual in both groups.

#### **Conditional Causal Effects in Experiments**

The effect of a treatment might change based on factors such as age or education.

In an experiment, we can study people who are similar in some way, like being the same age. We compare how the treatment works for them against a control group without the treatment.

This is a conditional causal effect. It tells us how the treatment might work for certain groups of people. It helps us understand who the treatment helps the most.

Randomisation is essential here, too. Because we put people into groups randomly, we can trust that differences in how the groups respond, on average, owe to the treatment, not to other factors. We do not need to guess what would have happened members of a different group had they been assigned to a different condition. Random assignment enables us to compute group-level responses within conditions, bypassing the need to observe what cannot, in reality, ever be observed -- individual-level contrasts.

#### **Estimating Causal Effects outside of Experiments Requires Assumptions**

Experiments are the best method for estimating causal effects. They use randomisation and control to identify causation. However, experiments are not always possible or ethical. In those cases, researchers turn to observational studies. These studies are more complex. They do not have random assignment to treatment conditions, and the conditions may vary widely. Some individuals might not even have a chance to receive one or both levels of the treatment being studied.

Therefore, to estimate causal effects in observational settings, certain assumptions must be met \[citations\]. These assumptions are crucial. Without them, it is risky to draw conclusions about causation outside of experimental settings \[cite\].

The three fundamental assumptions are the exchangeability assumption, the causal consistency assumption, and the positivity assumption. Each one serves a unique role in ensuring that the causal effects identified in observational studies are valid and reliable.

#### **The Exchangeability Assumption**

In observational studies, the lack of randomisation can lead to challenges in identifying causal effects.

Specifically, the assumption requires that, after controlling for measured variables, the potential outcomes under various exposure levels must be independent of the actual exposure level experienced [@hernán2023].

The exchangeability assumption addresses this issue. It requires balance in the treatment conditions, considering factors that might influence the outcome. When the data do have balance across the treatment conditions, we say there is "confounding." The task is removing confounding is one of obtaining balance of the kind that randomisation provides in experimental settings.

In the following sections, we will outline methods for addressing the exchangeability assumption. Because the data do not typically clarify whether counfounding has been fully addressed, we recommend sensitivity analysis. Such analyses describe how much unmeasured confounding would be required to explain away the observed association between the exposure and the outcome.

#### **The Causal Consistency Assumption**

In observational studies, researchers lack control over the treatment, creating complexity in discerning causal effects.

The causal consistency assumption helps navigate this complexity. It mandates that the exposures being compared align with specific, well-defined interventions in the data [@hernán2023].

This means that the exposure or treatment must be consistent across the study, and it should not change over time or vary among subjects in ways that might alter the outcome (see also: @chatton2020).

Consider a multifaceted "treatment" such as weight loss. In real-world weight loss, various means may be employed: dieting, exercise, stress, severe disease, surgical procedures like stomach stapling. Each constitutes a different exposure with unique effects.

In experiments, experimental control allows us to define the exposure precisely, such as weight loss by dieting. By controlling other factors, we can isolate the causal effect of that specific intervention. In this scenario, the causal consistency assumption is satisfied because the intervention does not vary in ways that would affect the result.

In observational studies, ensuring causal consistency becomes more challenging. Studies might include individuals losing weight through various means, with differing motivations, methods, and individual characteristics [@hernan, @tyler]. Without control over these factors, the causal consistency assumption may be violated, complicating the isolation of a specific intervention's effect like dieting.

Though estimating causal effects in heterogeneous treatment settings is complex, it is not incoherent. A mathematical framework, known as causal inference under multiple versions of treatment, shows that unbiased estimation is feasible if all treatment versions meet the exchangeability assumption. Practical challenges do arise, though. Without observing the many versions of treatment, evaluating the exchangeability assumption may become difficult, and the utility of the estimation can be limited. For example, estimating the effect of weight loss through a random assignment to either dieting or heart disease may provide little meaningful insight due to the heterogeneous nature of the treatments.

Unfortunately, the causal consistency assumption typically cannot be verified by inspecting the data. Rather, researchers must rely on a clear understanding of the subject matter, make informed decisions about the definitions of exposures and treatments, and use thorough study design and statistical methods. They must ensure that the exposure or intervention being studied is consistently defined and measured across subjects in the study, without variation that could affect the outcome. This often involves careful consideration of the context, consultation with domain experts, and methodological choices that reflect the underlying science of the phenomenon being studied.

The protocols we describe below are aimed to help researchers obtain sensible inference by focussing their attention these demands for contextual attention informed by expert advice.

#### **The Positivity Assumption**

Positivity is an essential consideration in observational studies. It requires that there is a non-zero probability of receiving every exposure value within all strata of covariates [@hernán2023]. In simpler terms, it means that every subject in the study has some chance of receiving each level of the exposure or treatment. If this assumption is not met, it becomes impossible to make meaningful comparisons between different levels of exposure, as some of the comparisons would be based on groups where the exposure was never applied. Ensuring positivity is vital for the credibility of the causal effect estimation.

Unlike the exchangeability and causal consistency assumptions, we can sometimes verify whether the positivity assumption is satisfied by inspecting the data. We shall describe these methods.

### Causal effects (or Estimands)

**move material to here**

### Causal effect scales

### Scale of effecct

Average causal effects can be inferred by contrasting the expected outcome when a population is exposed to an exposure level, $E[Y(A = a)]$, with the expected outcome under a different exposure level, $E[Y(A=a')]$.

For a binary treatment with levels $A=0$ and $A=1$, the Average Treatment Effect (ATE), on the difference scale, is expressed:

$$ATE_{\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]$$

On the risk ratio scale, the ATE is expressed:

$$ATE_{\text{risk ratio}} = \frac{E[Y(1)|L]}{E[Y(0)|L]}$$

Other effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest. We can also define the Average Treatment Effect on the Treated (ATT) :

$$ATT_{\text{risk difference}} = E[Y(1) - Y(0)|A=1,L]$$

$$ATT_{\text{risk ratio}} = \frac{E[Y(1)|A=1,L]}{E[Y(0)|A=1, L]}$$

Another common estimand is the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the entire population if applied universally to that population. This quantity can be expressed:

$$PATE_{\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)$$

$$PATE_{\text{risk ratio}} = f\left(\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\right)$$

where $f$ is a function that incorporates weights $W$ into the estimation of the expected outcomes. These weights are given from census estimates for the wider population. Note: I will show you how to use weights in future seminars.

We might also be interested in identifying effects specific to certain strata, such as risk differences or risk ratios, as they are modified by baseline indicators. Denote a stratum of interest by $G$. We may then compute:

$$ATE_{G,\text{risk difference}} = E[Y(1) - Y(0)|G, L]$$

$$ATE_{G,\text{risk ratio}} = \frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}$$

#### Considerations

-   In the causal inference literature, the concept we use to make sense of stratum specific comparisons is called "effect modification."
-   By inferring effects within stratums, we may evaluate whether the effects of different exposures or treatments on some well-defined outcome (measured in some well-defined time-period after the exposure) differ depending on group measurement.
-   The logic of effect modification differs slightly from that of interaction.

#### Aside: extensions

For continuous exposures, we must stipulate the level of contrast for the exposure (e.g. weekly versus monthly church attendance):

$$ATE_{A,A'} = E[Y(A) - Y(A')| L]$$

This essentially denotes an average treatment effect comparing the outcome under treatment level $A$ to the outcome under treatment level $A'$.

Likewise:

$$ATE_{A/A'} = \frac{E[Y(A)| L]}{E[Y(A')| L]}$$

This defines the contrast of $A$ and $A'$ on a ratio scale.

#### f. Describe the population(s) for whom the intended study is meant to generalise by distinguishing between source and target populations.

Consider the following concepts:

-   **Source population**: A source population is where we gather our data for a study. We pull our specific sample from this group. It needs to mirror the broader group for our conclusions to be valid and widely applicable.

-   **Target population**: The target population is the larger group we aim to apply our study's results to. It could be defined by location, demographics, or specific conditions. The closer the source matches the target in ways that are relevant to our causal questions, the stronger our causal inferences about the target population will be.

    -   **Generalisability** refers to the ability to apply the causal effects estimated from a sample to the population it was drawn from. In simpler terms, it deals with the extrapolation of causal knowledge from a sample to the broader population. This concept is also called "external validity".

$$\text{Generalisability} = PATE \approx f(ATE_{\text{sample}}, W)$$

-   **Transportability** refers to the ability to extrapolate causal effects learned from a source population to a target population when certain conditions are met. It deals with the transfer of causal knowledge across different settings or populations.

$$\text{Transportability} = ATE_{\text{target}} \approx f(ATE_{\text{source}}, T)$$

where $f$ is a function and $T$ is a function that maps the results from our source population to another population. To achieve transportability, we need information about the source and target populations and an understanding of how the relationships between treatment, outcome, and covariates differ between the populations. Assessing transportability requires scientific knowledge.

## Part 1: Three-Wave Panel Designs

Our goal is to explain how researchers can use three waves of data to satisfy the assumptions needed for causal inference.

Put differently, we aim to demonstrate how, with three waves of data, researchers can emulate the conditions found in a randomised experiment so that they may address causal questions outsider of experiments.

To begin, let us clarify some definitions:

-   **Wave**: a wave is a time interval where measurements are taken. It is placed on a timeline, so there are earlier and later intervals. The length can vary, but the order is specific.

-   **Treatment (or Exposure)**: a treatment refers to an event or condition applied to some individuals but not others. In causal terms, it is what we consider the "cause." Our discussion here will be limited to investigating the effects of one cause.

-   **Outcome**: an outcome is what we study as the effect of the treatment. It is the result we are interested in measuring.

-   **Confounding**: when the observed relationship between the treatment and the outcome may be influenced by another variable, not just the treatment itself, we say there may be confounding.

-   **Confounder**: a confounder is a variable that reduces confounding when it is accounted for in the study.

-   **Panel Design**: a panel design follows the same individuals over time. It enables baseline controls and connects treatments to outcomes.

-   **Baseline**: wave 0, or the baseline, is the interval in which we measure confounders to deal with confounding in a three-wave panel design.

-   **Treatment Wave**: wave 1 is the interval in which we measure the treatment or exposure is measured. Other variables at this wave are generally not included. However, we will explain how to address causal questions in which the effect of a treatment may vary between groups measured at baseline. That is, we will explain how to identify conditional causal effects.

-   **Outcome Wave**: wave 2 is the interval is the interval in which we measure, you guessed it, the outcome. There may be more than one outcome measured.

### Step 1. Defining the exposure: measure it at wave 0 and wave 1

We begin with a well-defined exposure.

Consider the causal effect of attending religious services. The first critical step involves defining the exposure in the context of a hypothetical intervention. What aspect is of interest to us? Is it a comparison of attendance versus non-attendance? Are we distinguishing between weekly and monthly attendees? Perhaps, we are interested in a different facet altogether? Visualising a hypothetical experiment - even when it is not feasible - reveals the need for a precise intervention specification [@hernán2022; @hernán2016a; @bulbulia2022].

The exposure is measured at wave 1 (i.e. +1 interval from baseline, wave 0). When estimating causal effects, the inclusion of exposure at the baseline carries three critical advantages:

a.  **Incidence effect interpretation**: incorporating the baseline exposure allows us to interpret the effect of exposure measured post-baseline as an incidence effect, not a prevalence effect [@vanderweele2020]. This means we can interpret the effect as the change due to a new occurrence (incidence) of the exposure, rather than the overall presence (prevalence) of the exposure. For example, in a study investigating the impact of weekly religious service attendance, including the baseline measure of attendance enables us to understand the effect of starting to attend weekly services (incidence), as opposed to simply being a regular attendee (prevalence).

```{=html}
<!-- -->
```
2.  **Confounding control**: the baseline exposure's inclusion helps to reduce unmeasured confounding arising from time-invariant confounders. These are variables that do not change over time and could confound the association between the exposure and the outcome if not properly accounted for. For instance, personal attributes such as unmeasured childhood religiosity could confound the association between religious service attendance and outcomes if not considered [@vantongeren2020].

3.  **Better evaluation of sample adequacy for rare exposures**: Particularly when the exposure is uncommon, such as switching from no religious service attendance to weekly attendance, measuring the baseline exposure and outcome exposure can help assess adequacy of a sample size. Suppose this switch occurs rarely in the non-religious population, say 1 in 1,000 non-attenders per year. To estimate causal effects while conditioning on a rich set of baseline covariates, we would need a large sample, potentially comprising hundreds of thousands of participants. Ideally researchers would understake investigations prior to data collection to assess feasiblity of causal inference. In this example, it might be more practical to examine changes within the religious population, that is -- assuming changes are more common within this group -- than it would be to investigate conversion events. However, by restricting to only religious people who change in their religious habits, we would then typically estimate a causal effect generalisable to the religious population from which the sample was drawn, rather than one that could be applied to the non-religious population. In any case, including the baseline exposure can help address these issues by providing a reference point for changes within the population studied.

### Step 2. Specify the Outcome(s) measure them at wave 0 and wave 2

After defining the exposure, we need to determine a well-defined outcome (or potentially several outcomes). For instance, we might be interested in understanding the effect of acquiring or losing religious service attendance on the frequency of volunteering (e.g., weekly, monthly, yearly). We have seen that statements like "the causal effects of religious change" are not insightful. We must articulate clearly the phenomenon under study and its timing (e.g., the +1-year effect on weekly volunteering from a shift of 0 to weekly or more religious service attendance).

Measuring the outcome at baseline offers several advantages:

a.  **Temporal Ordering**: controlling for the baseline measure of the outcome helps confirm the temporal order of the cause-effect relationship, thereby guarding against reverse causation.

b.  **Confounding Control**: when we also control for the exposure at baseline, an unmeasured confounder would have to negate the association between the exposure at one wave post-baseline and the outcome at two waves post-baseline, independent of the baseline effect, as show in @fig-dag-1. Note, this figure shows that **reduction of bias is preferable to no reduction if bias**. This is an important practical point: although it may not be possible to eliminate all confounding (the dashed arrows symbolise potential sources of uncontrolled bias), the processes of data collection and analysis can help reduce it. Putting this point more sharply, there is a great danger in allowing automated confounding control strategies to govern an analysis. Again, a minimal adjustment set cannot be insured. Our task is always to reduce confounding in the presence of unmeasured confounders. A strategy must be carefully considered at the design phase in light both of the problem at hand, and the data that might be collected.[^1]

[^1]: Given the typical uncertainty about having accounted for all unmeasured confounding, it is prudent for researchers to conduct sensitivity analyses [@shi2021].

```{tikz}
#| label: fig-dag-1
#| fig-cap: "Causal diagram adapted from Vanderweele et al.'s three-wave panel design. The dotted line indicates a reduction in bias arising from including baseline measures for the exposure and outcome. For an unmeasured confounder U to bias the exposure-outcome association, it would need to do so independently of these outcome and exposure baseline measures. The graph clarifies that by measuring confounders before the exposure and the exposure before the outcome, we reduce the potential for reverse causation, collider stratification, and mediator biases."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
\tikzstyle{cor} = [-, dashed, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {L$_{t0}$ \\A$_{t0}$ \\Y$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (Y) at (6, 0) {Y$_{t2}$};
\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [cor, draw = black, dotted] (A) to (Y);
\draw [-latex, bend left=50, draw =black] (L) to (Y);
\draw [-latex, bend right=50, draw =black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);




\end{tikzpicture}
```

### Step 3. Identify observable common causes of the exposure and the outcome

Next, we should identify all the potential confounders that, when adjusted for, can eliminate any non-causal association between the exposure and outcome. We should group these confounders under standard labels wherever they share the same functional dependencies in the graph. In a three-wave panel design, confounders are recorded during the baseline wave. As illustrated in @fig-dag-mediator-solution, recording confounders before the occurrence of the exposure minimises the potential for mediation bias. For example in @fig-dag-6, the variable $L$ on the graph might denote rich set of indicators such as Age, Gender, Education,Political Orientation, SES,$\dots$ Again, causal diagrams are meant to be human read. We should not include these additional nodes when including a single node will suffice for clarity and thoroughness.

### Step 4. Gather data for proxy variables of unmeasured common causes at the baseline wave

Recall @fig-dag-descendent-solution-2: if any unmeasured confounders influence both the exposure and outcome, but we lack direct measurements, we should make efforts to include proxies for them. Again, even if this strategy cannot eliminate all bias from unmeasured confounding, it will generally reduce bias.

### Step 5. State the target population for whom the causal question applies

We need to define for whom our causal inference applies. For this purpose, it is helpful to distinguish the concepts of source population and target population and between the concepts of generalisability and transportability.

1.  **The source population** is the population from whom our sample is drawn.

2.  **The target population** is the larger population for whom we aim to apply our study's results. The closer the source population matches the target population in structural features relevant to our causal questions, the stronger our causal inferences about the target population will be.

3.  **generalisability**: when the causal effect estimated from a sample applies to the target population beyond the sample population, we say the causal effect estimates are generalisable. This concept is also known as "external validity."

Let $PATE$ denote the population average treatment effect for the target population. Let $ATE_{\text{source}}$ denote the average treatment effect in the source population. Let $W$ denote a set of variables upon which the source and target population structurally differ. We say that results *generalise* if there is a function such that

$$PATE =  f(ATE_{\text{source}}, W)$$

4.  **Transportability**: when causal effects estimates may generalise to different settings and populations from which the source population was sampled, we say effects are transportable. Where $T$ denotes a set of variables upon which the source and the target population structurally differ, we say that results are transportable if there is a function such that

$$ATE_{\text{target}} \approx f(ATE_{\text{source}}, T)$$

This function similarly maps the average treatment effect from the source population to a target population. The function over $T$ might be more complex, as it must handle potential heterogeneity of effects and unobserved sources of bias. To assess transportability, we generally require information about the source and target populations and a specialist understanding. In Section 4, we will return to the concepts of generalisability and transportability as they pertain to sample selection.

### Step 6. Retention is a mission-critical imperative

for reasons we clarify in Part 4, sample retention is a mission-critical imperative because panel attrition opens novel pathways for bias. Researchers must develop protocols for tracking individuals as they change addresses, emails, phone numbers, and names. Moreover, developing and implementing strategies for motivating retention across the entire population of interest (not merely those willing to volunteer for science) is critical for causal human science. These strategies must be developed with specialist knowledge of the population under study and the participation and insights of the people being studied.

## Part 2. The Steps

### STEP 1 Formulate the Research Question

-   **Stating the Question:** Is my question clearly stated? If not, state it.
-   **Relevance of the Question:** Have I explained its importance? If not, explain.
-   **Ethical Considerations** How might this question affect people? How might not investigating this question affect people?
-   **Causality of the Question:** Is my question causal? If not, refine your question.
-   **Subgroup Analysis:** Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.
-   **Understanding the Framework:** Can I explain the potential outcomes framework, individual causal effects, the experimental method to obtain average causal effects, the fundamental assumptions of causal inference, and the estimation of causal effects in observational data? If not, review course materials.

### Data Requirements

-   **Type of Data:** Are my data experimental? If yes, your project may not fit this course.
-   **Time-Series Data:** Are my data time-series? If not, reconsider your causal question.
-   **Data Waves:** Do I have at least three waves of data? If not, beware of confounding control issues.
-   **Data Source:** Are my data from the NZAVS simulated data set? If not, consult with me.

### Defining the Outcome

-   **Outcome Variable:** Is the outcome variable *Y* defined? If not, define it.
-   **Multiple Outcomes:** Are there multiple outcomes? If yes, write them down.
-   **Outcome Relevance:** Can I explain how the outcome variable/s relate to my question? If not, clarify.
-   **Outcome Type:** Is my outcome binary and rare? If yes, consider logistic regression. If my outcome is continuous, consider z-transforming it or categorising it (consult an expert).
-   **Outcome Timing:** Does the outcome appear after the exposure? It should.

### Determining the Exposure

-   **Exposure Variable:** Is the exposure variable *A* defined? If not, define it.
-   **Multiple Exposures:** Are there multiple exposures? If yes, reassess; if only one exposure, proceed.
-   **Exposure Relevance:** Can I explain how the exposure variable relates to my question? If not, clarify.
-   **Positivity:** Can we intervene on the exposure at all levels of the covariates? We should be able to.
-   **Consistency:** Can I interpret what it means to intervene on the exposure? I should be able to.
-   **Exchangeability:** Are different versions of the exposure conditionally exchangeable given measured baseline confounders? They should be.
-   **Exposure Type:** Is the exposure binary or continuous? If continuous, z-transform it or consider categorising it (consult an expert).
-   **Exposure Timing:** Does the exposure appear before the outcome? It should.

### Accounting for Confounders

-   **Baseline Confounders:** Have I defined my baseline confounders *L*? I should have.
-   **Justification:** Can I explain how the baseline confounders could affect both *A* and *Y*? I should be able to.
-   **Timing:** Are the baseline confounders measured before the exposure? They should be.
-   **Inclusion:** Is the baseline measure of the exposure and the baseline outcome included in the set of baseline confounders? They should be.
-   **Sufficiency:** Are the baseline confounders sufficient to ensure balance on the exposure, such that *A* is independent of *Y* given *L*? If not, plan a sensitivity analysis.
-   **Confounder Type:** Are the confounders continuous or binary? If so, consider converting them to z-scores. If they are categorical with three or more levels, do not convert them to z-scores.

### Drawing a Causal Diagram with Unmeasured Confounders

-   **Unmeasured Confounders:** Does previous science suggest the presence of unmeasured confounders? If not, expand your understanding.
-   **Causal Diagram:** Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding? I should have.
-   **M-Bias:** Have I considered the possibility of M-Bias? If not familiar, we'll discuss later.
-   **Measurement Error:** Have I described potential biases from measurement errors? If not, we'll discuss later.
-   **Temporal Order:** Does my DAG have time indicators to ensure correct temporal order? It should.
-   **Time Consistency:** Is my DAG organized so that time follows in a consistent direction? It should.

### Identifying the Estimand

-   **Causal Estimand:** Is my causal estimand one of the following:

$$ATE_{G,(A,A')} = E[Y(1) - Y(0)|G, L]$$

$$ATE_{G,(A/A')} = \frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}$$

If yes, you're on the right track.

### Understanding Source and Target Populations

-   **Populations Identified:** Have I differentiated between my source and target populations? I should have.
-   **Generalisability and Transportability:** Have I considered whether my results generalise to the source population and transport to a different population? I should have.

### Setting Eligibility Criteria

-   **Criteria Stated:** Have I stated the eligibility criteria for the study? I should have.

### Describing Sample Characteristics

-   **Descriptive Statistics:** Have I provided descriptive statistics for demographic information taken at baseline? I should have.
-   **Exposure Change:** Have I demonstrated the magnitudes of change in the exposure from baseline to the exposure interval? I should have.
-   **References:** Have I included references for more information about the sample? I should have.

### Addressing Missing Data

-   **Missing Data Check:** Have I checked for missing data? I should have.
-   **Missing Data Plan:** If there is missing data, have I described how I will address it? I should have.

### Selecting the Model Approach

-   **Approach Decision:** Have I decided on using G-computation, IPTW, or Doubly-Robust Estimation? I should have.
-   **Interaction Inclusion:** Have I included the interaction of the exposure and baseline covariates? I should have.
-   **Large Data Set:** If I have a large data set, should I include the interaction of the exposure, group, and baseline confounders? I should consider it.
-   **Model Specification:** Have I double-checked the model specification? I should.
-   **Outcome Specifics:** If the outcome is rare and binary, have I specified logistic regression? If it's continuous, have I considered converting it to z-scores?
-   **Sensitivity Analysis:** Am I planning a sensitivity analysis using simulation? If yes, describe it (e.g. E-values.)

### d. Highlight unmeasured pre-treatment covariates

Let **U** denoted unmeasured pre-treatment covariates that may potentially bias the statistical association between *A* and *Y* independently of the measured covariates.

### Consider:

-   To affect *Y* and *A*, *U* must occur before *A*.
-   It is useful to draw a causal diagramme to illustrate all potential sources of bias.
-   Causal diagrammes are qualitative tools that require specialist expertise. We cannot typically obtain a causal graph from the data.
-   A causal diagramme should include only as much information as is required to assess confounding. See @fig-dag-outcomewide for an example.
-   Because we cannot ensure the absence of unmeasured confounders in observational settings, it is vital to conduct sensitivity analyses for the results. For sensitivity analyeses, we use E-values, a topic for a latter seminar.

```{tikz}
#| label: fig-dag-outcomewide
#| fig-cap: "Causal graph: three-wave panel design." 
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {t0/L \\t0/A \\t0/Y};
\node [rectangle, draw=white] (A) at (4, 0) {t1/A};
\node [ellipse, draw=white] (Y) at (6, 0) {t2/Y};
\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, draw=red, dotted] (A) to (Y);
\draw [-latex, bend left=50, draw =black] (L) to (Y);
\draw [-latex, bend right=50, draw =black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);


\end{tikzpicture}
```

### Summary Step 1: Consider how much we need to do when asking a causal question!

We discover that asking a causal question is a multifaceted task. It demands careful definition of the outcome, including its timing, the exposure, and covariates. It also requires selecting the appropriate scale for causal contrast, controlling for confounding, and potentially adjusting for sample weights or stratification. Finally, when asking a causal question, we must consider for whom the results apply. Only after following these steps can we then ask: "How may we answer this causal question?"

## STEP 2: ANSWER A CAUSAL QUESTION

#### Obtain longitudinal data

Note that causal inference from observational data turns on the appropriate temporal ordering of the key variables involved in the study.

Recall we have defined.

-   **A**: Our exposure or treatment variable, denoted as **A**. Here we consider the example of 'Church attendance'.

-   **Y**: The outcome variable we are interested in, represented by **Y**, is psychological distress. We operationalise this variable through the 'Kessler-6' distress scale.

-   **L**: The confounding variables, collectively referred to as **L**, represent factors that can independently influence both **A** and **Y**. For example, socio-economic status could be a confounder that impacts both the likelihood of church attendance and the levels of psychological distress.

Given the importance of temporal ordering, we must now define time:

-   **t** $\in$ T: Let $t$ denote within a multiwave panel study with **T** measurement intervals.

Where $t/\text{{exposure}}$ denotes the measurement interval for the exposure. Longitudinal data collection provides us the ability to establish a causal model such that:

$$t_{confounders} < t_{exposure}< t_{outcome}$$

To minimise the posibility of time-varying confounding and obtain the clearest effect estimates, we should acquire the most recent values of $\mathbf{L}$ preceding $A$ and the latest values of $A$ before $Y$.

Note in @fig-dag-outcomewide, We use the prefixes "t0, t1, and t2" to denote temporal ordering. We include in the set of baseline confounders the pre-exposure measurement of *A* and *Y*. This allows for more substantial confounding control. For unmeasured confounder to affect both the exposure and the outcome, it would need to do so independently of the pre-exposure confounders. Additionally, including the baseline exposure gives us an effect estimate for the incidence exposure, rather than the prevelance of the exposure. This helps us to assess the expected change in the outcome were we to initate a change in the exposure.

### Include the measured exposure with baseline covariates

Controlling for prior exposure enables the interpretation of the effect estimate as a change in the exposure in a manner akin to a randomised trial. We propose that the effect estimate with prior control for the exposure estimates the "incidence exposure" rather than the "prevalence exposure" [@danaei2012]. It is crucial to estimate the incidence exposure because if the effects of an exposure are harmful in the short term such that these effects are not subsequently measured, a failure to adjust for prior exposure will yield the illusion that the exposure is beneficial. Furthermore, this approach aids in controlling for unmeasured confounding. For such a confounder to explain away the observed exposure-outcome association, it would need to do so independently of the prior level of the exposure and outcome.

### State the eligibility criteria for participation

This step is invaluable for assessing whether we are answering the causal question that we have asked.

#### Consider:

-   Generalisability: we cannot evaluate inferences to a target group from the source population if we do not describe the source population
-   Eligibility criteria will help us to ensure whether we have correctly evaluated potential measurement bias/error in our instruments.

For example, the New Zealand Attitudes and Values Study is a National Probability study of New Zealanders. The details provided in the supplementary materials describe how individuals were randomly selected from the country's electoral roll. From these invitations there was typically less than 15% response rate. How might this process of recruitment affect generalisability and transportability of our results?

-   Aside: discuss per protocol effects/ intention to treat effects

### Determine how missing data will be handled

-   As we will consider in the upcoming weeks, loss to follow up and non-response opens sources for bias. We must develop a strategy for handling missing data.

### State a statistical model

The models we have considered in this course are G-computation, Inverse Probability of Treatement Weighting, and Doubly-Robust estimation.

### Reporting

Consider the following ideas about how to report one's model:

-   **Estimator**: Doubly robust where possible.
-   **Propensity Score Reporting:** Detail the process of propensity score derivation, including the model used and any variable transformations.
-   **WeightIt Package Utilisation:** Explicitly mention the use of the 'WeightIt' package in R, including any specific options or parameters used in the propensity score estimation process.
-   **Method Variations:** Report if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as 'ebal', 'energy', and 'ps'.
-   **Continuous Exposures:** Highlight that for continuous exposures, only the 'energy' option was used for propensity score estimation.
-   **Subgroup Estimation:** Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.
-   **Covariate Balance:** Include a Love plot to visually represent covariate balance on the exposure both before and after weighting.
-   **Weighting Algorithm Statistics:** Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit.
-   **Outcome Regression Model:** Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation.
-   **Subgroup Interaction:** Address whether the subgroup was included separately as an interaction in the outcome model, and if the model successfully converged.
-   **Model Coefficients:** Note that the model coefficients should not be interpreted, as they are not meaningful in this context.
-   **Confidence Intervals and Standard Errors:** Describe the methods used to derive confidence intervals and standard errors, noting the use of the 'clarify' package in R for simulation based inference.

### Example of how to report a doubly robust method in your report

The Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:

**Step 1** involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.

**Step 2** focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.

**Step 3** entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.

**Step 4** is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.

**Step 5** involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods [@greifer2023]. This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.

### Inference

Consider the following ideas about what to discuss in one's findings. The order of exposition might be different.

1.  **Summary of results**: What did you find?

2.  **Interpretation of E-values:** Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.

3.  **Causal Effect Interpretation:** What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.

4.  **Comparison of Subgroups:** Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.

5.  **Uncertainty and Confidence Intervals:** Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.

6.  **Generalisability and Transportability:** Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)

7.  **Assumptions and Limitations:** Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.

8.  **Theoretical Relevance**: How are these findings relevant to existing theories.

9.  **Replication and Future Research:** Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.

10. **Real-world Implications:** Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research.

## Part X Estimators

### Average Treatment Effects (Difference Scale)

Certainly. If we are moving from a conditional estimator for G-computation to an unconditional estimator, the main difference will be in the removal of the conditioning on the subgroup $G$. Here are the corresponding steps for the unconditional estimator:

### **G-computation Estimator**

**Step 1** Estimate the outcome model. Fit a model for the outcome $Y$, conditional on the exposure $A$, and the covariates $L$. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, and confounders.

$$ \hat{E}(Y|A,L) = f_Y(A,L; \theta_Y) $$

This equation represents the expected value of the outcome $Y$ given the exposure $A$, and covariates $L$, as modeled by the function $f_Y$ with parameters $\theta_Y$.

**Step 2** Simulate potential outcomes. For each individual, predict their potential outcome under the intervention $A=a$ using the estimated outcome model:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y]$$

We also predict the potential outcome for everyone under the causal contrast, setting the intervention to $A=a'$:

$$  \hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y]$$

In these equations, $Y$ represents the potential outcome, $A$ is the intervention, and $L$ are the covariates.

**Step 3** Calculate the estimated difference:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

This difference $\hat{\delta}$ represents the average causal effect of changing the exposure from level $a'$ to level $a$.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### **Inverse Probability of Treatment Weighting (IPTW) Estimator**

**Step 1** Estimate the propensity score. The propensity score $e(L)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

Here, $f_A(L; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$. Then, we calculate the weights for each individual, denoted as $v$:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$:

$$ \hat{E}(Y|A; V) = f_Y(A; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $\theta_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation.

**Step 3** Simulate potential outcomes. For each individual, simulate their potential outcome under the hypothetical scenario where everyone is exposed to the intervention $A=a$:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a')  = \hat{E}[Y|A=a'; \hat{\theta}_Y,  v_i]$$

The expectation is calculated for each individual $i$, with individual-specific weights $v_i$.

**Step 4** Estimate the average treatment effect as the difference in the predicted outcomes:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The estimated difference $\hat{\delta}$ represents the ATE. We use simulation-based inference methods to compute standard errors and confidence intervals.

We again, use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Doubly Robust Estimation

**Step 1** Estimate the propensity score. The propensity score $e(L)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

Here, $f_A(L; \theta_A)$ is a function (statistical model) estimating the probability of exposure $A = 1$ given covariates $L$. We calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

**Step 2** Fit a weighted outcome model. Using the weights $v$, fit a model for the outcome $Y$, conditional on the exposure $A$.

$$ \hat{E}(Y|A, L; v) = f_Y(A, L ; \theta_Y, v) $$

Here, $f_Y$ is a function (such as a weighted regression model) with parameters $\theta_Y$. The weights $v$ are incorporated into the estimation process.

**Step 3** Simulate potential outcomes under different scenarios for each individual. For instance, simulate the outcome under the hypothetical scenario where everyone is exposed to intervention $A=a$:

$$\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y, v_i]$$

and also under the scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y, v_i]$$

**Step 4** Estimate the average causal effect. Compute the estimated expected value of the potential outcomes under each intervention level:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The difference $\delta$ represents the average causal effect of changing the exposure from level $a^{\prime}$ to level $a$.

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Subgroup estimators

### **G-computation for Subgroup Analysis Estimator**

**Step 1** Estimate the outcome model. Fit a model for the outcome $Y$, conditional on the exposure $A$, the covariates $L$, and subgroup indicator $G$. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, confounders, and subgroups.

$$ \hat{E}(Y|A,L,G) = f_Y(A,L,G; \theta_Y) $$

This equation represents the expected value of the outcome $Y$ given the exposure $A$, covariates $L$, and subgroup $G$, as modeled by the function $f_Y$ with parameters $\theta_Y$. This formulation allows for the prediction of the average outcome $Y$ given certain values of $A$, $L$, and $G$.

**Step 2** Simulate potential outcomes. For each individual in each subgroup, predict their potential outcome under the intervention $A=a$ using the estimated outcome model:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y]$$

We also predict the potential outcome for everyone in each subgroup under the causal contrast, setting the intervention for everyone in that group to $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y]$$

In these equations, $Y$ represents the potential outcome, $A$ is the intervention, $L$ are the covariates, $G=g$ represents the subgroup, and $\theta_Y$ are the parameters of the outcome model.

**Step 3** Calculate the estimated difference for each subgroup $g$:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

This difference $\hat{\delta}_g$ represents the average causal effect of changing the exposure from level $a'$ to level $a$ within each subgroup $g$.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 4** Compare differences in causal effects by subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

This difference $\hat{\gamma}$ represents the difference in the average causal effects between the subgroups $g$ and $g'$. It measures the interaction effect of the exposure $A$ and the subgroup $G$ on the outcome $Y$.

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### **Inverse Probability of Treatment Weighting (IPTW) for Subgroup Analysis Estimator**

**Step 1** Estimate the propensity score. The propensity score $e(L, G)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$ and subgroup indicator $G$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L, G) = f_A(L, G; \theta_A)$$

Here, $f_A(L, G; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$ and subgroup $G$. Then, we calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Thus, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

Note that we estimate propensity scores *separately* within strata of the subgroup for whom we are interested in effect modification. $v$ is the weight for each individual in a given subgroup $G$.

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$ and subgroup $G$. This can be represented as:

$$ \hat{E}(Y|A, G; V) = f_Y(A, G ; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation of $θ_Y$, but they are not themselves an additional variable within the model.

Note that in this formulation, unlike doubly-robust estimation, $L$ is not included as a variable in the outcome model, but its effect is accounted for through the weights $V$, which are calculated based on the estimated propensity scores that do include $L$.

**Step 3** Simulate potential outcomes. For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention $A=a$ regardless of their actual exposure level:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,G=g; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',G=g; \hat{\theta}_Y,  v_i]$$

Thus the expectation is calculated for each individual $i$ in each subgroup $g$, with individual-specific weights $v_i$.

**Step 4** Estimate the average causal effect for each subgroup as the difference in the predicted outcomes:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

The estimated difference $\hat{\delta}_g$ represents the average causal effect withing group $g$. We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 5** Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

### Doubly Robust Estimation for Subgroup Analysis Estimator

Doubly Robust Estimation is a powerful technique that combines the strengths of both the IPTW and G-computation methods. It uses both the propensity score model and the outcome model, which makes it doubly robust: it produces unbiased estimates if either one of the models is correctly specified.

**Step 1** Estimate the propensity score. The propensity score $e(L, G)$ is the conditional probability of the exposure $A = 1$, given the covariates $L$ and subgroup indicator $G$. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.

$$e = P(A = 1 | L, G) = f_A(L, G; \theta_A)$$

Here, $f_A(L, G; \theta_A)$ is a function (statistical model) that estimates the probability of the exposure $A = 1$ given covariates $L$ and subgroup $G$. Then, we calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Thus, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

Note that we estimate propensity scores *separately* within strata of the subgroup for whom we are interested in effect modification. $v$ is the weight for each individual in a given subgroup $G$.

**Step 2** Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome $Y$, conditional on the exposure $A$ and subgroup $G$. This can be represented as:

$$ \hat{E}(Y|A, L, G; V) = f_Y(A, L, G ; \theta_Y, V) $$

In this model, $f_Y$ is a function (such as a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting how much each observation contributes to the estimation of $θ_Y$, but they are not themselves an additional variable within the model.

Note that in this formulation, unlike propensity score model, estimation, $L$ is included as a variable in the outcome model, Although imbalance in $L$ on $A$ is accounted for by the weights $V$, by including $L$ in the outcome model this method is doubly robust insofar as we will obtain a consistent effect estimate if either the propensity score or the outcome model is correctly specified. This property reduces the strength of the assumption of correct model specification.

**Step 3** For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention $A=a$ regardless of their actual exposure level:

$$\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y,  v_i]$$

and also under the hypothetical scenario where everyone in each subgroup is exposed to intervention $A=a'$:

$$\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y,  v_i]$$

Thus the expectation is calculated for each individual $i$ in each subgroup $g$, with individual-specific weights $v_i$.

**Step 4** Estimate the average causal effect for each subgroup. Compute the estimated expected value of the potential outcomes under each intervention level for each subgroup:

$$\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]$$

The difference $\delta_g$ represents the average causal effect of changing the exposure from level $a^{\prime}$ to level $a$ within each subgroup.

We use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].

**Step 5** Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:

$$\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}$$

where,

$$\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}$$

We again use simulation-based inference methods to compute standard errors and confidence intervals [@greifer2023].
