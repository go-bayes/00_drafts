% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  singlecolumn]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=20mm,heightrounded]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage[noblocks]{authblk}
\renewcommand*{\Authsep}{, }
\renewcommand*{\Authand}{, }
\renewcommand*{\Authands}{, }
\renewcommand\Affilfont{\small}
\usepackage{cancel}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Causal inference in three wave panels: a step-by-step guide},
  pdfauthor={Joseph A. Bulbulia},
  pdfkeywords={DAGS, Causal
Inference, Confounding, History, Psychology, Panel},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Causal inference in three wave panels: a step-by-step guide}


  \author{Joseph A. Bulbulia}
            \affil{%
                  Victoria University of Wellington, New Zealand, School
                  of Psychology, Centre for Applied Cross-Cultural
                  Research
              }
      
\date{2023-09-06}
\begin{document}
\maketitle
\begin{abstract}
This article offers a guide for addressing causal questions in
psychology using three-wave panel designs. We focus on three-wave panel
studies for the New Zealand Attitudes and Values Study (NZAVS), however
the principles and strategies we describe may generalise. \textbf{Part
1} lays the foundation by introducing key definitions, notation, and
assumptions required for causal inference. \textbf{Part 2} describes the
three-wave panel ``outcome-wide'' design. \textbf{Part 3} provides a
step-by-step giod for conducting three-wave outcome-wide design using
NZAVS data. \textbf{Part 4} explains common estimators and their
options, again focussing on NZAVS designs. \textbf{Part 5} explores more
complex causal questions and approaches required for \(n > 3\) wave
designs. Overall, this article aims to equip pyschological scientists
with the tools and understanding needed for robust causal inferences
using panel data.
\end{abstract}
\subsection{Introduction}\label{introduction}

\subsubsection{Purpose}\label{purpose}

This article describes how to address causal questions in psychology
using panel data. We primarily focus on the simple case of estimating
total effects in three-wave panel designs. A secondary purpose of this
article is to guide applied researchers for the New Zealand Attitudes
and Values Study in developing studies that address causal questions.

\textbf{Part 1} introduces definitions and notation, and outlines how
causal inference works. The purpose of this section is to introduce
readers who are not familiar with causal inference to its conceptual
basis.

\textbf{Part 2} outlines the three-wave panel, and its motivations.
Here, I introduce the concept of an ``outcome-wide study,'' an concept
introduced by Tyler VanderWeele
(\hyperref[ref-vanderweele2017a]{VanderWeele 2017};
\hyperref[ref-vanderweele2020a]{VanderWeele \emph{et al.} 2020a}). I
review important theoretical motivations for outcome-wide studies,
describe pitfalls, and discuss methods for addressing their limitations.
To foreshadow, and outcome-wide study quantifies the total effects of a
single intervention on multiple outcomes. This approach affords more
rapid scientific progress than would be possible were researchers to
focus on single outcomes. This approach also avoids selection bias
arising from cherry-picking outcomes in the service of a publishable
story.

\textbf{Part 3} develops a the step-by-step guide for conducting causal
inference within a three-wave panel design. Here, our focus shifts from
theoretical to applied interests. To make theory concrete, we use the
New Zealand Attitudes and Values Study (NZAVS). The NZAVS is a national
probability study that has been repeatedly measuring individuals since
2009. In 2018-2019 (NZAVS wave 10), the NZAVS conducted a large booster
that enrolled 1.5\% of the adult population of New Zealand. Our focus
here will be on describing causal inference methods as they apply to
NZAVS waves 10-13. Part of the purpose of this guide is to assist NZAVS
researchers in developing causal inferential studies using NZAVS data.
Again, we will focus on outcome-wide approaches.

\textbf{Part 4} describes common estimators, and options. The material
in this section may appear somewhat technical. However, we encourage
readers to worth through the technical details, which have been limited
to the essentials required for understanding the move from stating
causal questions to answering them using time-series data.

\textbf{Part 5} discusses more complex designs where there is scope for
treatment-confounder feedback.

An Appendix describes custom functions written for executing the
workflows in the NZAVS, again with a focus on three-wave panel designs.

\subsection{\texorpdfstring{\textbf{Part 1} Foundational
Concepts}{Part 1 Foundational Concepts}}\label{part-1-foundational-concepts}

\subsubsection{\texorpdfstring{Observed Outcome
(\(Y|A=a\))}{Observed Outcome (Y\textbar A=a)}}\label{observed-outcome-yaa}

A critical aspect of causal inference is the temporal sequence of
events. Specifically, the outcome variable, denoted \(Y\), is observed
after the treatment or exposure, which is symbolised as \(A=a\). This
ordering is imperative; causality implies a forward motion in time, from
cause to effect. Therefore, \(Y\) must be measured post-intervention or
post-exposure to be considered as a potential effect of \(A\).

The nature of the outcome variable can be diverse. In psychological
science, it may be a quantitative measure such as test scores, or a
binary outcome like presence or absence of a mental disorder. We might
be interested in estimating several outcomes simultaneously. Whatever
the outcome, we must ensure that it has been measured after the
occurence of the exposure or treatment.

\subsubsection{\texorpdfstring{Counterfactual Outcome
(\(Y(a)\))}{Counterfactual Outcome (Y(a))}}\label{counterfactual-outcome-ya}

The counterfactual outcome \(Y(a)\) stands for the unobserved outcome
that each unit would have experienced under a specific treatment level
\(a\). This counterfactual serves as the cornerstone for estimating
causal effects, allowing us to consider what would have happened the
treatments differed It is crucial to remember that these are theoretical
constructs; conterfactuals are not observable because \(Y\) can only be
measured after a particular level of treatment \(A=a\) has actually
occurred.

For instance, if an individual receives treatment \(a\), we observe the
outcome \(Y|A=a\). What we cannot observe is how the outcome would have
varied under different treatments, denoted as \(Y(a')\) for
\(a' \neq a\). This predicament, known as the ``fundamental problem of
causal inference,'' will require advanced methods to approximate the
counterfactual outcomes from observations.\footnote{In the literature on
  causal inference, the conventions \(Y(a)\) \(Y_a\) and \(Y^a\) are all
  equivalent, and may be used interchangeably. For consistency, we use
  the notation \(Y(a)\) for counterfactual outcomes throughout this
  article.}

\subsubsection{Measuring Causal Effects}\label{measuring-causal-effects}

In the arena of causal inference, the aim is not merely to detect
associations or patterns but to quantify the effect of an intervention.
The core tool for this is the counterfactual model, which aids in
developing \emph{causal contrasts}. These contrasts are essentially
differences in potential outcomes under different treatment levels. They
serve as the building blocks for quantifying causal effects.

\subsubsection{Individual Level Causal
Contrast}\label{individual-level-causal-contrast}

At the individual level, a causal contrast for a specific unit \(i\) is
defined as \(Y_i(a) - Y_i(a')\). However, this is inherently
unobservable for any individual. The problem stems from the fact that we
can only observe \(Y_i | A_i = a\) or \(Y_i | A_i = a'\) but never both
for the same unit. This limitation is often referred to as the
``fundamental problem of causal inference'' because it restricts our
ability to make conclusive causal claims at the individual level.

\subsubsection{Average (Marginal) Causal
Contrasts}\label{average-marginal-causal-contrasts}

While individual-level contrasts may be unobservable, it is often
possible to estimate average causal contrasts, particularly when certain
assumptions hold. The average or marginal causal contrast is defined as
( E{[}Y(a){]} - E{[}Y(a'){]} ). It provides a summary measure of the
treatment effect across the entire population. When data meet specific
criteria, these aggregate measures can be identified and estimated even
in observational settings.

\subsubsection{Causal Contrasts In
Experiments}\label{causal-contrasts-in-experiments}

In the experimental paradigm, participants are randomly allocated to
treatment groups, and outcomes are observed post-intervention. Although
individual-level contrasts remain unobservable, the randomisation
process allows for the estimation of average causal contrasts. This is
possible because random assignment ensures that, in expectation, each
treatment group is a fair representation of the population. Hence, we
can generalise the average effect of the treatment across groups.

\subsubsection{Causal Contrasts In Observational Studies: Three
Fundamental
Assumptions}\label{causal-contrasts-in-observational-studies-three-fundamental-assumptions}

In observational settings, the aim is to approximate the rigour of
randomised experiments. This involves meeting three crucial assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Causal Consistency}: This principle ensures that the
  treatments being compared correspond to well-defined interventions
  (\hyperref[ref-hernuxe1n2023]{Hernán and Monge 2023}). Causal
  consistency helps resolve the inherent \emph{missing data problems} of
  causal inference. For instance, when causal consistency holds,
  observed outcomes can be linked to counterfactual outcomes as follows:
\end{enumerate}

\[
Y_i^{observed}|A_i = 
\begin{cases} 
Y_i(a^*) & \text{if } A_i = a^* \\
Y_i(a) & \text{if } A_i = a
\end{cases}
\]

For two treatment levels ( A=1 ) and ( A=0 ), the counterfactuals are
then:

\[
Y = A \cdot Y(1) + (1-A) \cdot Y(0)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Exchangeability}: Also known as the ``no unmeasured
  confounding'' condition. It posits that after adjusting for observed
  covariates, potential outcomes are independent of the treatment
  received (\hyperref[ref-hernuxe1n2023]{Hernán and Monge 2023}).
\end{enumerate}

\[
Y(a) \coprod  A|L
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Positivity}: This condition asserts that for every level of
  measured covariates, there is a positive probability of receiving each
  treatment level (\hyperref[ref-hernuxe1n2023]{Hernán and Monge 2023}).
\end{enumerate}

\[
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall l \in L
\]

When these assumptions hold, causal inference in observational data
becomes a more tractable problem, enabling the application of various
estimation techniques to approximate the unobservable counterfactual
outcomes.

\paragraph{Scales of causal contrast}\label{scales-of-causal-contrast}

We cannot generally obtain causal contrasts for individual units. By
definition, treatments are exclusive.

However, when assumptions are satisfied (describe below), we may obtain
average treatment effects.

\[
ATE = f_{\text{causal contrast}}(E[Y_a], E[Y_a'])
\]

For example, an average treatment affect for the exposure \(A = a\) and
\(A=a'\) may be expressed on the difference scale as:

\[
ATE_{A,A'} = E[Y(a)] - E[Y(a')]
\]

This function computes the average effect by subtracting the average of
the expected outcomes under two specific treatment levels \(A\)
and\(A'\). Because the difference of the means is equivalent to the mean
of the differences, this expression is equivalent to:

\[
ATE_{A,A'} = E[Y(a) - Y(a')]
\]

Similarly, a causal contrast between the averages of one treatment and
the average of another treatment can also be expressed on the ratio
scale:

\[
ATE_{A/A'} = \frac{E[Y(a)]}{E[Y(a')]}
\]

Regardless of the scale or type of treatment, specifying the level of
contrast is essential for interpretation.

\paragraph{Causal Effect}\label{causal-effect}

We say there is an average or marginal effect of A on Y on the causal
difference scale if:

\[ {E}[Y(a)] -  {E}[Y(a')] \neq 0\]

We say there is an average or marginal effect of A on Y on the causal
risk ratio scale if:

\[\frac{ {E}[Y(a)]}{ {E}[Y(a')]}\neq 1\]

Unless otherwise specified, we will discuss causal contrasts on the
difference scale:

\[
\delta_{\text{ATE}} = E[Y(a) - Y(a')]
\]

This is the average or ``marginal'' contrast between the outcome under
treatment \(a\) and the outcome under the alternative \(a'\), averaged
over the entire population. This metric provides an aggregate snapshot
of the effect size, ignoring any possible heterogeneities or
subgroup-specific variations in treatment effects.

\paragraph{Introducing Conditional Average Treatment Effect
(CATE)}\label{introducing-conditional-average-treatment-effect-cate}

The effect of treatments are not the same for everyone. What works for
one subgroup might not work for another, or not work in quite the same
way. This brings us to the concept of the Conditional Average Treatment
Effect, or CATE.

We define the CATE as the ATE in subgroup \(G = g\). Call this quantity:
\(\delta_{\text{CATE},g}\). It may be computed:

\[
\delta_{\text{CATE},g} = E[Y(a)|G=g] - E[Y(a')|G=g]
\]

For example, if \(G\) may denote different age groups ---say, young
adults and the elderly. Let \(\delta_{\text{CATE}_{young}}\) denote a
treatment effect specifically on young adults, while
\(\delta_{\text{CATE}_{elderly}}\) would do the same for the
elderly.\footnote{To quantify this contrast, we use statistical methods
  such as simulation-based inference to estimate standard errors and
  confidence intervals (\hyperref[ref-greifer2023]{Greifer \emph{et al.}
  2023}).}

\paragraph{Distinguishing Between ATE and CATE in Group
Comparisons}\label{distinguishing-between-ate-and-cate-in-group-comparisons}

Suppose we wish to understand how treatment effects vary between
different groups, you might want to look into \$ \gamma\_g \$. This term
reflects the \emph{differential} average treatment effect between groups
\(G = g\) and \(G = g'\).

To articulate this notion more clearly, let us redefine \(\gamma_g\) as
follows:

\[
\gamma_g = \delta_{\text{CATE},g} - \delta_{\text{CATE},g'}
\]

This notation allow us to distinguish between the ATE in a subgroup,
\(\delta_{\text{CATE},g}\), from the concept of effect measure
modification \(\gamma_g\).

\paragraph{Example: differential effects of screen-time on well-being
among age
groups}\label{example-differential-effects-of-screen-time-on-well-being-among-age-groups}

To illustrate the application of \(\gamma_g\), consider a psychological
intervention aimed at reducing screen-time to improve well-being. In
this context, let \(G = \text{'adolescents'}\) and
\(G' = \text{'adults'}\). Assume that we estimate
\(\delta_{\text{CATE}, \text{adolescents}} = 10\)-point increase in a
well-being scale and \(\delta_{\text{CATE}, \text{adults}} = 4\)-point
increase.

We can calculate \(\gamma_{\text{adolescents}}\) as:

\[
\gamma_{\text{adolescents}} = \delta_{\text{CATE}, \text{adolescents}} - \delta_{\text{CATE}, \text{adults}} = 10 - 4 = 6
\]

In this example, \(\gamma_{\text{adolescents}}\) indicates that the
intervention is differentially more effective in improving well-being
for adolescents compared to adults by an average of 6 points on the
well-being scale.

This serves as an instance of ``Effect Modification'' (or equivalently
``Effect Measure Modification''), indicating that the treatment effect
of reduced screen-time is not uniformly beneficial across age groups.
The term \(\gamma_g\) becomes a critical metric for assessing this
heterogeneity.

\paragraph{Relating Average Treatment Effect (ATE) to Differential
Effects Across
Groups}\label{relating-average-treatment-effect-ate-to-differential-effects-across-groups}

Consider the quantity \(\delta_{\text{ATE}}\) as it relates to
subgroup-specific treatment effects (\(\delta_{\text{CATE},g}\)) and the
differential treatment effect (\$ \gamma\_g \$).

The ATE represents an average across all subgroups, weighted by their
population sizes. If we denote \$ p\_\{\text{adolescents}\} \$ and \$
p\_\{\text{adults}\}\$ as the proportion of adolescents and adults in
the population, respectively, then:

\[
\delta_{\text{ATE}} = p_{\text{adolescents}} \cdot \delta_{\text{CATE}_{\text{adolescents}}} + p_{\text{adults}} \cdot \delta_{\text{CATE}_{\text{adults}}}
\]

In our example, if adolescents make up 30\% of the sample and adults
make up 70\%, then:

\[
\delta_{\text{ATE}} = 0.3 \cdot 10 + 0.7 \cdot 4 = 3 + 2.8 = 5.8
\]

Here, \(\delta_{\text{ATE}}\) approximates the weighted average of
\(\delta_{\text{CATE}_{\text{adolescents}}}\)
and\(\delta_{\text{CATE}_{\text{adults}}}\). It should be noted that
\(\gamma_{\text{adolescents}} = 6\) underscores how the treatment effect
is differentially stronger for adolescents. This differential effect is
essentially obscured when looking solely at \(\delta_{\text{ATE}}\).

By examining both \(\delta_{\text{ATE}}\) and \(\gamma_g\), we can make
more precise inferences about the heterogeneous effects of interventions
across different subpopulations.

\paragraph{Formal definition of Effect Modification (or Effect Measure
Modification)}\label{formal-definition-of-effect-modification-or-effect-measure-modification}

Effect Modification occurs when the treatment effect varies across
levels of a third variable, often termed the ``modifier'' or ``effect
modifier.'' Formally, it's defined as the interaction between the
treatment variable \(a\) and the modifier \(G\) in their effect on the
outcome \(Y\) .

Mathematically, Effect Measure Modification is said to be present if:

\[ 
E[Y(a) | G=g_1] - E[Y(a') | G=g_1] \neq E[Y(a) | G=g_2] - E[Y(a') | G=g_2]
\]

Or in terms of our average treatment effects within subgroups
(\(\delta_{\text{CATE},g}\)):

\[ 
\delta_{\text{CATE},g_1} \neq \delta_{\text{CATE},g_2}
\]

The term \(\gamma_g\) which we defined as
\(\delta_{\text{CATE},g} - \delta_{\text{CATE},g'}\) would be a non-zero
value when Effect Measure Modification is present.

Effect Measure Modification implies that the treatment does not act
uniformly across different strata of the effect modifier, warranting
subgroup-specific estimates of the treatment effect. Again, this concept
is pivotal for tailoring interventions and identifying whom they benefit
or harm the most.

\subsubsection{Populations}\label{populations}

For whom do we estimate causal effects? A multitude of overlapping
``groups'' demands precise terminology.

\paragraph{Source Population}\label{source-population}

Source population: the origin of our study sample. This population
harbours its own true average treatment effect \(ATE_{\text{source}}\).

\paragraph{Target Population}\label{target-population}

Target population: the is the population fwe actually care about. It
could be defined by location, demographics, or specific conditions
unrelated to the source population. The closer the source matches the
target in ways that are relevant to our causal questions, the stronger
our causal inferences about the target population will be.

\paragraph{\texorpdfstring{\textbf{Generalisability}}{Generalisability}}\label{generalisability}

Results generalise when they are applicable to the broader population
from which the sample is drawn -- the \(PATE\), or is the population
average treatment effect. We can approximate the PATE from the ATE using
survey weights \(W\):

\[
\text{Generalisability} = PATE \approx f_{W}(ATE_{\text{source}}, W)
\]

\paragraph{\texorpdfstring{\textbf{Transportability}}{Transportability}}\label{transportability}

Results are transportable when they apply to a different population than
the one from which the sample was drawn. To express this:

\[
\text{Transportability} = ATE_{\text{target}} \approx f_{T}(ATE_{\text{source}}, T)
\]

Here, \(T\) is a function mapping results from the source to the target
population. Achieving transportability requires both data and scientific
knowledge to understand how relationships between treatment, outcome,
and covariates vary between source and target populations.

\paragraph{National Population}\label{national-population}

The Population Average Treatment Effect \$
PATE\_\{\text{New Zealand}\}\$ is a weighted sum of the CATEs for each
age group, using the proportions of each group within the population as
weights:

\[
PATE_{\text{New Zealand}} = w_{20-30} \times \delta_{\text{CATE}, 20-30} + w_{31-40} \times \delta_{\text{CATE}, 31-40} + w_{41-50} \times \delta_{\text{CATE}, 41-50}
\]

For example, suppose:

\begin{itemize}
\tightlist
\item
  \(\delta_{\text{CATE}, 20-30} = -2\) (screen time decreases well-being
  by 2 units for age 20-30)
\item
  \(\delta_{\text{CATE}, 31-40} = -1\) (screen time decreases well-being
  by 1 unit for age 31-40)
\item
  \(\delta_{\text{CATE}, 41-50} = 0\) (no effect for age 41-50)
\end{itemize}

Suppose the population weights are:

\begin{itemize}
\tightlist
\item
  \(w_{20-30} = 0.4\)
\item
  \(w_{31-40} = 0.3\)
\item
  \(w_{41-50} = 0.3\)
\end{itemize}

The \(PATE_{\text{New Zealand}}\) would be:

\[
PATE_{\text{New Zealand}} = 0.4 \times (-2) + 0.3 \times (-1) + 0.3 \times 0 = -0.8 - 0.3 + 0 = -1.1
\]

So, the \(PATE_{\text{New Zealand}}\) indicates that, on average, screen
time reduces well-being by 1.1 units across the New Zealand population.
This takes into account the age distribution and estimated treatment
effects for each age group.\footnote{Technically we have computed a
  \emph{restricted PATE} because the age groups in New Zealand are wider
  than the 20-50 year old range described here.}

\paragraph{\texorpdfstring{\textbf{Full Data and Observed
Data}}{Full Data and Observed Data}}\label{full-data-and-observed-data}

The full data is the random vector \((Y(1), Y(0), A, L)\) for covariates
\(L\), while the observed data \((Y, A, L)\) is a coarsening of the full
data with \(Y = A \cdot Y(1) + (1-A) \cdot Y(0)\)
(\hyperref[ref-ogburn2021]{Ogburn and Shpitser 2021}).

Absent assumptions, we cannot learn about contrasts from the observed
data, because they are functionals of (partially) unobserved potential
outcomes.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3068}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3068}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2045}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Data Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(Y(1)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(Y(0)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(A\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Full Data & Counterfactual \(Y(1)\) & Counterfactual \(Y(0)\) & Observed
\(A\) \\
Observed Data & Observed \(Y\) if \(A=1\) & Observed \(Y\) if \(A=0\) &
Observed \(A\) \\
\end{longtable}

\subsubsection{\texorpdfstring{\textbf{Confounding}}{Confounding}}\label{confounding}

A condition in which the observed association between the treatment and
the outcome in the data does not reflect a causal association.

\paragraph{\texorpdfstring{\textbf{Confounder}}{Confounder}}\label{confounder}

Any variable that when conditioned upon, perhaps in conjunction with
other confounders, reduces or minimises confounding. In the scientific
investigation of causality, one must often grapple with confounders.
These may be categorised into two distinct types:

\begin{itemize}
\item
  \textbf{Measured Confounder} (\(L\)): A variable that has been
  meticulously documented in the study. The symbol \(L\) is used to
  represent this kind of confounder, and it is a variable that has
  influence on both the treatment and the outcome of interest. By
  incorporating this information into the analysis, researchers can
  diminish or eradicate bias in the causal estimation.
\item
  \textbf{Unmeasured Confounder} (\(U\)): Represented by the symbol
  \(U\), an unmeasured confounder is a variable that is influential on
  both the treatment and the outcome but, regrettably, has not been
  captured in the study's data. The inability to control for \(U\) can
  potentially introduce an erroneous bias in the estimation of the
  causal relationship, a situation that can complicate the understanding
  of true causal effects. This scenario is a subject of considerable
  concern, especially in observational studies where information on all
  confounders might not be attainable.
\end{itemize}

\paragraph{\texorpdfstring{\textbf{Causal
Estimand}}{Causal Estimand}}\label{causal-estimand}

A causal estimand names the causal contrast of interest, specifying the
levels of exposure to be contrasted, potential outcomes of interest, the
scale of the causal contrast, and the target population for whom the
causal contrast applies.

\paragraph{\texorpdfstring{\textbf{Statistical
Estimand}}{Statistical Estimand}}\label{statistical-estimand}

A statistical estimand is a functional of the observed data that
corresponds to the causal estimand of interest. It reduces the causal
question to a statistical one, identifying a quantity in the observed
data that will provide information about the causal estimand.

\paragraph{\texorpdfstring{\textbf{Estimator}}{Estimator}}\label{estimator}

An estimator is a statistical function of the observed data, denoted as
\(\hat{\theta}(Y, A, L)\), that provides an estimate of the statistical
estimand. It translates the observed data into a single value,
approximating the unknown parameter. In the context of causal inference,
an estimator is used to estimate the statistical estimand, thereby
providing information about the corresponding causal estimand.

\paragraph{\texorpdfstring{\textbf{Elicitation}}{Elicitation}}\label{elicitation}

Elicitation refers to the process of gathering expert opinion or
knowledge to inform a model or analysis. We shall see the importance of
elicitation throughout.

\subsubsection{Experiments}\label{experiments}

\subsubsection{\texorpdfstring{\textbf{Average Causal Effects in
Experiments}}{Average Causal Effects in Experiments}}\label{average-causal-effects-in-experiments}

Estimating a causal effect means comparing what actually happened to
what would have happened if things had been different.

In an experiment, we place people into groups, give a treatment, and
then see what happens. But we can never see what would have happened to
a person in a different group. We only see what happens in the group
they were placed in.

When we talk about average effects of a treatment, things are different.
In a perfect experiment, we can compare the groups because we know the
assignment to groups is random. We can work out the average effect of
the treatment by comparing what generally happened in the treatment
group to what generally happened in the control group.

The random way we place people in groups means that, in theory, anyone
in one group could have been in the other. So, we can work out the
average effect without having to know exactly what would have happened
to each individual in both groups.

\paragraph{\texorpdfstring{\textbf{Conditional Causal Effects in
Experiments}}{Conditional Causal Effects in Experiments}}\label{conditional-causal-effects-in-experiments}

The effect of a treatment might change based on factors such as age or
education.

In an experiment, we can study people who are similar in some way, like
being the same age. We compare how the treatment works for them against
a control group without the treatment.

This is a conditional causal effect. It tells us how the treatment might
work for certain groups of people. It helps us understand who the
treatment helps the most.

Randomisation is essential here, too. Because we put people into groups
randomly, we can trust that differences in how the groups respond, on
average, owe to the treatment, not to other factors. We do not need to
guess what would have happened members of a different group had they
been assigned to a different condition. Random assignment enables us to
compute group-level responses within conditions, bypassing the need to
observe what cannot, in reality, ever be observed -- individual-level
contrasts.

\paragraph{\texorpdfstring{\textbf{Estimating Causal Effects outside of
Experiments Requires
Assumptions}}{Estimating Causal Effects outside of Experiments Requires Assumptions}}\label{estimating-causal-effects-outside-of-experiments-requires-assumptions}

Experiments are the best method for estimating causal effects. They use
randomisation and control to identify causation. However, experiments
are not always possible or ethical. In those cases, researchers turn to
observational studies. These studies are more complex. They do not have
random assignment to treatment conditions, and the conditions may vary
widely. Some individuals might not even have a chance to receive one or
both levels of the treatment being studied.

Therefore, to estimate causal effects in observational settings, certain
assumptions must be met \(citations\). These assumptions are crucial.
Without them, it is risky to draw conclusions about causation outside of
experimental settings \(cite\).

The three fundamental assumptions are the exchangeability assumption,
the causal consistency assumption, and the positivity assumption. Each
one serves a unique role in ensuring that the causal effects identified
in observational studies are valid and reliable.

\subsubsection{Three fundamental assumptions of causal
inference}\label{three-fundamental-assumptions-of-causal-inference}

\paragraph{\texorpdfstring{\textbf{The Exchangeability
Assumption}}{The Exchangeability Assumption}}\label{the-exchangeability-assumption}

In observational studies, the lack of randomisation can lead to
challenges in identifying causal effects.

Specifically, the assumption requires that, after controlling for
measured variables, the potential outcomes under various exposure levels
must be independent of the actual exposure level experienced
(\hyperref[ref-hernuxe1n2023]{Hernán and Monge 2023}).

The exchangeability assumption addresses this issue. It requires balance
in the treatment conditions, considering factors that might influence
the outcome. When the data do have balance across the treatment
conditions, we say there is ``confounding.'' The task is removing
confounding is one of obtaining balance of the kind that randomisation
provides in experimental settings.

In the following sections, we will outline methods for addressing the
exchangeability assumption. Because the data do not typically clarify
whether counfounding has been fully addressed, we recommend sensitivity
analysis. Such analyses describe how much unmeasured confounding would
be required to explain away the observed association between the
exposure and the outcome.

\paragraph{\texorpdfstring{\textbf{The Causal Consistency
Assumption}}{The Causal Consistency Assumption}}\label{the-causal-consistency-assumption}

In observational studies, researchers lack control over the treatment,
creating complexity in discerning causal effects.

The causal consistency assumption helps navigate this complexity. It
mandates that the exposures being compared align with specific,
well-defined interventions in the data
(\hyperref[ref-hernuxe1n2023]{Hernán and Monge 2023}).

This means that the exposure or treatment must be consistent across the
study, and it should not change over time or vary among subjects in ways
that might alter the outcome (see also: Chatton \emph{et al.}
(\hyperref[ref-chatton2020]{2020})).

Consider a multifaceted ``treatment'' such as weight loss. In real-world
weight loss, various means may be employed: dieting, exercise, stress,
severe disease, surgical procedures like stomach stapling. Each
constitutes a different exposure with unique effects.

In experiments, experimental control allows us to define the exposure
precisely, such as weight loss by dieting. By controlling other factors,
we can isolate the causal effect of that specific intervention. In this
scenario, the causal consistency assumption is satisfied because the
intervention does not vary in ways that would affect the result.

In observational studies, ensuring causal consistency becomes more
challenging. Studies might include individuals losing weight through
various means, with differing motivations, methods, and individual
characteristics (\hyperref[ref-tyler]{\textbf{tyler?}}). Without control
over these factors, the causal consistency assumption may be violated,
complicating the isolation of a specific intervention's effect like
dieting.

Though estimating causal effects in heterogeneous treatment settings is
complex, it is not incoherent. A mathematical framework, known as causal
inference under multiple versions of treatment, shows that unbiased
estimation is feasible if all treatment versions meet the
exchangeability assumption. Practical challenges do arise, though.
Without observing the many versions of treatment, evaluating the
exchangeability assumption may become difficult, and the utility of the
estimation can be limited. For example, estimating the effect of weight
loss through a random assignment to either dieting or heart disease may
provide little meaningful insight due to the heterogeneous nature of the
treatments.

Unfortunately, the causal consistency assumption typically cannot be
verified by inspecting the data. Rather, researchers must rely on a
clear understanding of the subject matter, make informed decisions about
the definitions of exposures and treatments, and use thorough study
design and statistical methods. They must ensure that the exposure or
intervention being studied is consistently defined and measured across
subjects in the study, without variation that could affect the outcome.
This often involves careful consideration of the context, consultation
with domain experts, and methodological choices that reflect the
underlying science of the phenomenon being studied.

The protocols we describe below are aimed to help researchers obtain
sensible inference by focussing their attention these demands for
contextual attention informed by expert advice.

\paragraph{\texorpdfstring{\textbf{The Positivity
Assumption}}{The Positivity Assumption}}\label{the-positivity-assumption}

There is a non-zero probability of receiving every exposure value within
all strata of covariates (\hyperref[ref-hernuxe1n2023]{Hernán and Monge
2023}).

In simpler terms, it means that every subject in the study has some
chance of receiving each level of the exposure or treatment.

If this assumption is not met, it becomes impossible to make meaningful
comparisons between different levels of exposure, as some of the
comparisons would be based on groups where the exposure was never
applied.

Unlike the exchangeability and causal consistency assumptions, we can
sometimes verify whether the positivity assumption is satisfied by
inspecting the data.

\paragraph{\texorpdfstring{\textbf{Identification
Strategy}}{Identification Strategy}}\label{identification-strategy}

An identification strategy refers to the set of assumptions and
methodologies employed to ensure that a causal estimand (recall -- a
quantity representing a causal effect) can be determined uniquely from
the observed data. It is the process through which researchers make a
bridge from the statistical estimand, derived from the observed data, to
the causal estimand that represents the actual causal effect of
interest. Identifiability relies on assumptions such as exchangeability,
positivity, and consistent measurement. The validity of these
assumptions enables a unique mapping of the causal estimand from the
statistical estimand, facilitating causal inference from observational
data.

\paragraph{Considerations}\label{considerations}

\begin{itemize}
\tightlist
\item
  In the causal inference literature, the concept we use to make sense
  of stratum specific comparisons is called ``effect modification.''
\item
  By inferring effects within strata, we may evaluate whether the
  effects of different exposures or treatments on some well-defined
  outcome (measured in some well-defined time-period after the exposure)
  differ depending on group measurement.
\item
  The logic of effect modification differs slightly from that of
  interaction.
\end{itemize}

\subsection{Part 2: Three-Wave Panel
Designs}\label{part-2-three-wave-panel-designs}

Our goal is to explain how researchers can use three waves of data to
satisfy the assumptions needed for causal inference.

Put differently, we aim to demonstrate how, with three waves of data,
researchers can emulate the conditions found in a randomised experiment
so that they may address causal questions out of experiments.

To begin, some definitions:

\begin{itemize}
\item
  \textbf{Wave}: a wave is a time interval where measurements are taken.
  It is placed on a timeline, so there are earlier and later intervals.
  The length can vary, but the order is specific.
\item
  \textbf{Treatment (or Exposure)}: a treatment refers to an event or
  condition applied to some individuals but not others. In causal terms,
  it is what we consider the ``cause.'' Our discussion here will be
  limited to investigating the effects of one cause.
\item
  \textbf{Outcome}: an outcome is what we study as the effect of the
  treatment. It is the result we are interested in measuring.
\item
  \textbf{Confounding}: when the observed relationship between the
  treatment and the outcome may be influenced by another variable, not
  just the treatment itself, we say there may be confounding.
\item
  \textbf{Confounder}: a confounder is a variable that reduces
  confounding when it is accounted for in the study.
\item
  \textbf{Panel Design}: a panel design follows the same individuals
  over time. It enables baseline controls and connects treatments to
  outcomes.
\item
  \textbf{Baseline}: wave 0, or the baseline, is the interval in which
  we measure confounders to deal with confounding in a three-wave panel
  design.
\item
  \textbf{Treatment Wave}: wave 1 is the interval in which we measure
  the treatment or exposure is measured. Other variables at this wave
  are generally not included. However, we will explain how to address
  causal questions in which the effect of a treatment may vary between
  groups measured at baseline. That is, we will explain how to identify
  conditional causal effects.
\item
  \textbf{Outcome Wave}: wave 2 is the interval is the interval in which
  we measure, you guessed it, the outcome. There may be more than one
  outcome measured.
\end{itemize}

\subsubsection{Step 1. Defining the exposure: measure it at wave 0 and
wave
1}\label{step-1.-defining-the-exposure-measure-it-at-wave-0-and-wave-1}

We begin with a well-defined exposure.

Consider the causal effect of attending religious services. The first
critical step involves defining the exposure in the context of a
hypothetical intervention. What aspect is of interest to us? Is it a
comparison of attendance versus non-attendance? Are we distinguishing
between weekly and monthly attendees? Perhaps, we are interested in a
different facet altogether? Visualising a hypothetical experiment - even
when it is not feasible - reveals the need for a precise intervention
specification (\hyperref[ref-bulbulia2022]{Bulbulia 2022};
\hyperref[ref-hernuxe1n2016a]{Hernán \emph{et al.} 2016};
\hyperref[ref-hernuxe1n2022]{Hernán \emph{et al.} 2022}).

The exposure is measured at wave 1 (i.e.~+1 interval from baseline, wave
0). When estimating causal effects, the inclusion of exposure at the
baseline carries three critical advantages:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \textbf{Incidence effect interpretation}: incorporating the baseline
  exposure allows us to interpret the effect of exposure measured
  post-baseline as an incidence effect, not a prevalence effect
  (\hyperref[ref-vanderweele2020]{VanderWeele \emph{et al.} 2020b}).
  This means we can interpret the effect as the change due to a new
  occurrence (incidence) of the exposure, rather than the overall
  presence (prevalence) of the exposure. For example, in a study
  investigating the impact of weekly religious service attendance,
  including the baseline measure of attendance enables us to understand
  the effect of starting to attend weekly services (incidence), as
  opposed to simply being a regular attendee (prevalence).
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Confounding control}: the baseline exposure's inclusion helps
  to reduce unmeasured confounding arising from time-invariant
  confounders. These are variables that do not change over time and
  could confound the association between the exposure and the outcome if
  not properly accounted for. For instance, personal attributes such as
  unmeasured childhood religiosity could confound the association
  between religious service attendance and outcomes if not considered
  (\hyperref[ref-vantongeren2020]{Van Tongeren \emph{et al.} 2020}).
\item
  \textbf{Better evaluation of sample adequacy for rare exposures}:
  Particularly when the exposure is uncommon, such as switching from no
  religious service attendance to weekly attendance, measuring the
  baseline exposure and outcome exposure can help assess adequacy of a
  sample size. Suppose this switch occurs rarely in the non-religious
  population, say 1 in 1,000 non-attenders per year. To estimate causal
  effects while conditioning on a rich set of baseline covariates, we
  would need a large sample, potentially comprising hundreds of
  thousands of participants. Ideally researchers would understake
  investigations prior to data collection to assess feasiblity of causal
  inference. In this example, it might be more practical to examine
  changes within the religious population, that is -- assuming changes
  are more common within this group -- than it would be to investigate
  conversion events. However, by restricting to only religious people
  who change in their religious habits, we would then typically estimate
  a causal effect generalisable to the religious population from which
  the sample was drawn, rather than one that could be applied to the
  non-religious population. In any case, including the baseline exposure
  can help address these issues by providing a reference point for
  changes within the population studied.
\end{enumerate}

\subsubsection{Step 2. Specify the Outcome(s) measure them at wave 0 and
wave
2}\label{step-2.-specify-the-outcomes-measure-them-at-wave-0-and-wave-2}

After defining the exposure, we need to determine a well-defined outcome
(or potentially several outcomes). For instance, we might be interested
in understanding the effect of acquiring or losing religious service
attendance on the frequency of volunteering (e.g., weekly, monthly,
yearly). We have seen that statements like ``the causal effects of
religious change'' are not insightful. We must articulate clearly the
phenomenon under study and its timing (e.g., the +1-year effect on
weekly volunteering from a shift of 0 to weekly or more religious
service attendance).

Measuring the outcome at baseline offers several advantages:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \textbf{Temporal Ordering}: controlling for the baseline measure of
  the outcome helps confirm the temporal order of the cause-effect
  relationship, thereby guarding against reverse causation.
\item
  \textbf{Confounding Control}: when we also control for the exposure at
  baseline, an unmeasured confounder would have to negate the
  association between the exposure at one wave post-baseline and the
  outcome at two waves post-baseline, independent of the baseline
  effect, as show in Figure~\ref{fig-dag-1}. Note, this figure shows
  that \textbf{reduction of bias is preferable to no reduction if bias}.
  This is an important practical point: although it may not be possible
  to eliminate all confounding (the dashed arrows symbolise potential
  sources of uncontrolled bias), the processes of data collection and
  analysis can help reduce it. Putting this point more sharply, there is
  a great danger in allowing automated confounding control strategies to
  govern an analysis. Again, a minimal adjustment set cannot be insured.
  Our task is always to reduce confounding in the presence of unmeasured
  confounders. A strategy must be carefully considered at the design
  phase in light both of the problem at hand, and the data that might be
  collected.\footnote{Given the typical uncertainty about having
    accounted for all unmeasured confounding, it is prudent for
    researchers to conduct sensitivity analyses
    (\hyperref[ref-shi2021]{Shi \emph{et al.} 2021}).}
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{ow-methods_files/figure-pdf/fig-dag-1-1.pdf}

}

\caption{\label{fig-dag-1}Causal diagram adapted from Vanderweele et
al.'s three-wave panel design. The dotted line indicates a reduction in
bias arising from including baseline measures for the exposure and
outcome. For an unmeasured confounder U to bias the exposure-outcome
association, it would need to do so independently of these outcome and
exposure baseline measures. The graph clarifies that by measuring
confounders before the exposure and the exposure before the outcome, we
reduce the potential for reverse causation, collider stratification, and
mediator biases.}

\end{figure}

\subsubsection{Step 3. Identify observable common causes of the exposure
and the
outcome}\label{step-3.-identify-observable-common-causes-of-the-exposure-and-the-outcome}

Next, we should identify all the potential confounders that, when
adjusted for, can eliminate any non-causal association between the
exposure and outcome. We should group these confounders under standard
labels wherever they share the same functional dependencies in the
graph. In a three-wave panel design, confounders are recorded during the
baseline wave. As illustrated in \textbf{?@fig-dag-mediator-solution},
recording confounders before the occurrence of the exposure minimises
the potential for mediation bias. For example in \textbf{?@fig-dag-6},
the variable \(L\) on the graph might denote rich set of indicators such
as Age, Gender, Education,Political Orientation, SES,\(\dots\) Again,
causal diagrams are meant to be human read. We should not include these
additional nodes when including a single node will suffice for clarity
and thoroughness.

\subsubsection{Step 4. Gather data for proxy variables of unmeasured
common causes at the baseline
wave}\label{step-4.-gather-data-for-proxy-variables-of-unmeasured-common-causes-at-the-baseline-wave}

Recall \textbf{?@fig-dag-descendent-solution-2}: if any unmeasured
confounders influence both the exposure and outcome, but we lack direct
measurements, we should make efforts to include proxies for them. Again,
even if this strategy cannot eliminate all bias from unmeasured
confounding, it will generally reduce bias.

\subsubsection{Step 5. State the target population for whom the causal
question
applies}\label{step-5.-state-the-target-population-for-whom-the-causal-question-applies}

We need to define for whom our causal inference applies. For this
purpose, it is helpful to distinguish the concepts of source population
and target population and between the concepts of generalisability and
transportability.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{The source population} is the population from whom our sample
  is drawn.
\item
  \textbf{The target population} is the larger population for whom we
  aim to apply our study's results. The closer the source population
  matches the target population in structural features relevant to our
  causal questions, the stronger our causal inferences about the target
  population will be.
\item
  \textbf{generalisability}: when the causal effect estimated from a
  sample applies to the target population beyond the sample population,
  we say the causal effect estimates are generalisable. This concept is
  also known as ``external validity.''
\end{enumerate}

Let \(PATE\) denote the population average treatment effect for the
target population. Let \(ATE_{\text{source}}\) denote the average
treatment effect in the source population. Let \(W\) denote a set of
variables upon which the source and target population structurally
differ. We say that results \emph{generalise} if there is a function
such that

\[PATE =  f(ATE_{\text{source}}, W)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Transportability}: when causal effects estimates may
  generalise to different settings and populations from which the source
  population was sampled, we say effects are transportable. Where \(T\)
  denotes a set of variables upon which the source and the target
  population structurally differ, we say that results are transportable
  if there is a function such that
\end{enumerate}

\[ATE_{\text{target}} \approx f(ATE_{\text{source}}, T)\]

This function similarly maps the average treatment effect from the
source population to a target population. The function over \(T\) might
be more complex, as it must handle potential heterogeneity of effects
and unobserved sources of bias. To assess transportability, we generally
require information about the source and target populations and a
specialist understanding. In Section 4, we will return to the concepts
of generalisability and transportability as they pertain to sample
selection.

\subsubsection{Step 6. Retention is a mission-critical
imperative}\label{step-6.-retention-is-a-mission-critical-imperative}

for reasons we clarify in Part 4, sample retention is a mission-critical
imperative because panel attrition opens novel pathways for bias.
Researchers must develop protocols for tracking individuals as they
change addresses, emails, phone numbers, and names. Moreover, developing
and implementing strategies for motivating retention across the entire
population of interest (not merely those willing to volunteer for
science) is critical for causal human science. These strategies must be
developed with specialist knowledge of the population under study and
the participation and insights of the people being studied.

\subsection{Part 2. The Steps}\label{part-2.-the-steps}

\subsubsection{STEP 1 Formulate the Research
Question}\label{step-1-formulate-the-research-question}

\begin{itemize}
\tightlist
\item
  \textbf{Stating the Question:} Is my question clearly stated? If not,
  state it.
\item
  \textbf{Relevance of the Question:} Have I explained its importance?
  If not, explain.
\item
  \textbf{Ethical Considerations} How might this question affect people?
  How might not investigating this question affect people?
\item
  \textbf{Causality of the Question:} Is my question causal? If not,
  refine your question.
\item
  \textbf{Subgroup Analysis:} Does my question involve a subgroup (e.g.,
  cultural group)? If not, develop a subgroup analysis question.
\item
  \textbf{Understanding the Framework:} Can I explain the potential
  outcomes framework, individual causal effects, the experimental method
  to obtain average causal effects, the fundamental assumptions of
  causal inference, and the estimation of causal effects in
  observational data? If not, review course materials.
\end{itemize}

\subsubsection{Data Requirements}\label{data-requirements}

\begin{itemize}
\tightlist
\item
  \textbf{Type of Data:} Are my data experimental? If yes, your project
  may not fit this course.
\item
  \textbf{Time-Series Data:} Are my data time-series? If not, reconsider
  your causal question.
\item
  \textbf{Data Waves:} Do I have at least three waves of data? If not,
  beware of confounding control issues.
\item
  \textbf{Data Source:} Are my data from the NZAVS simulated data set?
  If not, consult with me.
\end{itemize}

\subsubsection{Defining the Outcome}\label{defining-the-outcome}

\begin{itemize}
\tightlist
\item
  \textbf{Outcome Variable:} Is the outcome variable \emph{Y} defined?
  If not, define it.
\item
  \textbf{Multiple Outcomes:} Are there multiple outcomes? If yes, write
  them down.
\item
  \textbf{Outcome Relevance:} Can I explain how the outcome variable/s
  relate to my question? If not, clarify.
\item
  \textbf{Outcome Type:} Is my outcome binary and rare? If yes, consider
  logistic regression. If my outcome is continuous, consider
  z-transforming it or categorising it (consult an expert).
\item
  \textbf{Outcome Timing:} Does the outcome appear after the exposure?
  It should.
\end{itemize}

\subsubsection{Determining the Exposure}\label{determining-the-exposure}

\begin{itemize}
\tightlist
\item
  \textbf{Exposure Variable:} Is the exposure variable \emph{A} defined?
  If not, define it.
\item
  \textbf{Multiple Exposures:} Are there multiple exposures? If yes,
  reassess; if only one exposure, proceed.
\item
  \textbf{Exposure Relevance:} Can I explain how the exposure variable
  relates to my question? If not, clarify.
\item
  \textbf{Positivity:} Can we intervene on the exposure at all levels of
  the covariates? We should be able to.
\item
  \textbf{Consistency:} Can I interpret what it means to intervene on
  the exposure? I should be able to.
\item
  \textbf{Exchangeability:} Are different versions of the exposure
  conditionally exchangeable given measured baseline confounders? They
  should be.
\item
  \textbf{Exposure Type:} Is the exposure binary or continuous? If
  continuous, z-transform it or consider categorising it (consult an
  expert).
\item
  \textbf{Exposure Timing:} Does the exposure appear before the outcome?
  It should.
\end{itemize}

\subsubsection{Accounting for
Confounders}\label{accounting-for-confounders}

\begin{itemize}
\tightlist
\item
  \textbf{Baseline Confounders:} Have I defined my baseline confounders
  \emph{L}? I should have.
\item
  \textbf{Justification:} Can I explain how the baseline confounders
  could affect both \emph{A} and \emph{Y}? I should be able to.
\item
  \textbf{Timing:} Are the baseline confounders measured before the
  exposure? They should be.
\item
  \textbf{Inclusion:} Is the baseline measure of the exposure and the
  baseline outcome included in the set of baseline confounders? They
  should be.
\item
  \textbf{Sufficiency:} Are the baseline confounders sufficient to
  ensure balance on the exposure, such that \emph{A} is independent of
  \emph{Y} given \emph{L}? If not, plan a sensitivity analysis.
\item
  \textbf{Confounder Type:} Are the confounders continuous or binary? If
  so, consider converting them to z-scores. If they are categorical with
  three or more levels, do not convert them to z-scores.
\end{itemize}

\subsubsection{Drawing a Causal Diagram with Unmeasured
Confounders}\label{drawing-a-causal-diagram-with-unmeasured-confounders}

\begin{itemize}
\tightlist
\item
  \textbf{Unmeasured Confounders:} Does previous science suggest the
  presence of unmeasured confounders? If not, expand your understanding.
\item
  \textbf{Causal Diagram:} Have I drawn a causal diagram (DAG) to
  highlight both measured and unmeasured sources of confounding? I
  should have.
\item
  \textbf{M-Bias:} Have I considered the possibility of M-Bias? If not
  familiar, we'll discuss later.
\item
  \textbf{Measurement Error:} Have I described potential biases from
  measurement errors? If not, we'll discuss later.
\item
  \textbf{Temporal Order:} Does my DAG have time indicators to ensure
  correct temporal order? It should.
\item
  \textbf{Time Consistency:} Is my DAG organized so that time follows in
  a consistent direction? It should.
\end{itemize}

\subsubsection{Identifying the Estimand}\label{identifying-the-estimand}

\begin{itemize}
\tightlist
\item
  \textbf{Causal Estimand:} Is my causal estimand one of the following:
\end{itemize}

\[ATE_{G,(A,A')} = E[Y(1) - Y(0)|G, L]\]

\[ATE_{G,(A/A')} = \frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}\]

If yes, you're on the right track.

\subsubsection{Understanding Source and Target
Populations}\label{understanding-source-and-target-populations}

\begin{itemize}
\tightlist
\item
  \textbf{Populations Identified:} Have I differentiated between my
  source and target populations? I should have.
\item
  \textbf{Generalisability and Transportability:} Have I considered
  whether my results generalise to the source population and transport
  to a different population? I should have.
\end{itemize}

\subsubsection{Setting Eligibility
Criteria}\label{setting-eligibility-criteria}

\begin{itemize}
\tightlist
\item
  \textbf{Criteria Stated:} Have I stated the eligibility criteria for
  the study? I should have.
\end{itemize}

\subsubsection{Describing Sample
Characteristics}\label{describing-sample-characteristics}

\begin{itemize}
\tightlist
\item
  \textbf{Descriptive Statistics:} Have I provided descriptive
  statistics for demographic information taken at baseline? I should
  have.
\item
  \textbf{Exposure Change:} Have I demonstrated the magnitudes of change
  in the exposure from baseline to the exposure interval? I should have.
\item
  \textbf{References:} Have I included references for more information
  about the sample? I should have.
\end{itemize}

\subsubsection{Addressing Missing Data}\label{addressing-missing-data}

\begin{itemize}
\tightlist
\item
  \textbf{Missing Data Check:} Have I checked for missing data? I should
  have.
\item
  \textbf{Missing Data Plan:} If there is missing data, have I described
  how I will address it? I should have.
\end{itemize}

\subsubsection{Selecting the Model
Approach}\label{selecting-the-model-approach}

\begin{itemize}
\tightlist
\item
  \textbf{Approach Decision:} Have I decided on using G-computation,
  IPTW, or Doubly-Robust Estimation? I should have.
\item
  \textbf{Interaction Inclusion:} Have I included the interaction of the
  exposure and baseline covariates? I should have.
\item
  \textbf{Large Data Set:} If I have a large data set, should I include
  the interaction of the exposure, group, and baseline confounders? I
  should consider it.
\item
  \textbf{Model Specification:} Have I double-checked the model
  specification? I should.
\item
  \textbf{Outcome Specifics:} If the outcome is rare and binary, have I
  specified logistic regression? If it's continuous, have I considered
  converting it to z-scores?
\item
  \textbf{Sensitivity Analysis:} Am I planning a sensitivity analysis
  using simulation? If yes, describe it (e.g.~E-values.)
\end{itemize}

\subsubsection{d.~Highlight unmeasured pre-treatment
covariates}\label{d.-highlight-unmeasured-pre-treatment-covariates}

Let \textbf{U} denoted unmeasured pre-treatment covariates that may
potentially bias the statistical association between \emph{A} and
\emph{Y} independently of the measured covariates.

\subsubsection{Consider:}\label{consider}

\begin{itemize}
\tightlist
\item
  To affect \emph{Y} and \emph{A}, \emph{U} must occur before \emph{A}.
\item
  It is useful to draw a causal diagramme to illustrate all potential
  sources of bias.
\item
  Causal diagrammes are qualitative tools that require specialist
  expertise. We cannot typically obtain a causal graph from the data.
\item
  A causal diagramme should include only as much information as is
  required to assess confounding. See Figure~\ref{fig-dag-outcomewide}
  for an example.
\item
  Because we cannot ensure the absence of unmeasured confounders in
  observational settings, it is vital to conduct sensitivity analyses
  for the results. For sensitivity analyeses, we use E-values, a topic
  for a latter seminar.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{ow-methods_files/figure-pdf/fig-dag-outcomewide-1.pdf}

}

\caption{\label{fig-dag-outcomewide}Causal graph: three-wave panel
design.}

\end{figure}

\subsubsection{Summary Step 1: Consider how much we need to do when
asking a causal
question!}\label{summary-step-1-consider-how-much-we-need-to-do-when-asking-a-causal-question}

We discover that asking a causal question is a multifaceted task. It
demands careful definition of the outcome, including its timing, the
exposure, and covariates. It also requires selecting the appropriate
scale for causal contrast, controlling for confounding, and potentially
adjusting for sample weights or stratification. Finally, when asking a
causal question, we must consider for whom the results apply. Only after
following these steps can we then ask: ``How may we answer this causal
question?''

\subsection{STEP 2: ANSWER A CAUSAL
QUESTION}\label{step-2-answer-a-causal-question}

\paragraph{Obtain longitudinal data}\label{obtain-longitudinal-data}

Note that causal inference from observational data turns on the
appropriate temporal ordering of the key variables involved in the
study.

Recall we have defined.

\begin{itemize}
\item
  \textbf{A}: Our exposure or treatment variable, denoted as \textbf{A}.
  Here we consider the example of `Church attendance'.
\item
  \textbf{Y}: The outcome variable we are interested in, represented by
  \textbf{Y}, is psychological distress. We operationalise this variable
  through the `Kessler-6' distress scale.
\item
  \textbf{L}: The confounding variables, collectively referred to as
  \textbf{L}, represent factors that can independently influence both
  \textbf{A} and \textbf{Y}. For example, socio-economic status could be
  a confounder that impacts both the likelihood of church attendance and
  the levels of psychological distress.
\end{itemize}

Given the importance of temporal ordering, we must now define time:

\begin{itemize}
\tightlist
\item
  \textbf{t} \(\in\) T: Let \(t\) denote within a multiwave panel study
  with \textbf{T} measurement intervals.
\end{itemize}

Where \(t/\text{{exposure}}\) denotes the measurement interval for the
exposure. Longitudinal data collection provides us the ability to
establish a causal model such that:

\[t_{confounders} < t_{exposure}< t_{outcome}\]

To minimise the posibility of time-varying confounding and obtain the
clearest effect estimates, we should acquire the most recent values of
\(\mathbf{L}\) preceding \(A\) and the latest values of \(A\) before
\(Y\).

Note in Figure~\ref{fig-dag-outcomewide}, We use the prefixes ``t0, t1,
and t2'' to denote temporal ordering. We include in the set of baseline
confounders the pre-exposure measurement of \emph{A} and \emph{Y}. This
allows for more substantial confounding control. For unmeasured
confounder to affect both the exposure and the outcome, it would need to
do so independently of the pre-exposure confounders. Additionally,
including the baseline exposure gives us an effect estimate for the
incidence exposure, rather than the prevelance of the exposure. This
helps us to assess the expected change in the outcome were we to initate
a change in the exposure.

\subsubsection{Include the measured exposure with baseline
covariates}\label{include-the-measured-exposure-with-baseline-covariates}

Controlling for prior exposure enables the interpretation of the effect
estimate as a change in the exposure in a manner akin to a randomised
trial. We propose that the effect estimate with prior control for the
exposure estimates the ``incidence exposure'' rather than the
``prevalence exposure'' (\hyperref[ref-danaei2012]{Danaei \emph{et al.}
2012}). It is crucial to estimate the incidence exposure because if the
effects of an exposure are harmful in the short term such that these
effects are not subsequently measured, a failure to adjust for prior
exposure will yield the illusion that the exposure is beneficial.
Furthermore, this approach aids in controlling for unmeasured
confounding. For such a confounder to explain away the observed
exposure-outcome association, it would need to do so independently of
the prior level of the exposure and outcome.

\subsubsection{State the eligibility criteria for
participation}\label{state-the-eligibility-criteria-for-participation}

This step is invaluable for assessing whether we are answering the
causal question that we have asked.

\paragraph{Consider:}\label{consider-1}

\begin{itemize}
\tightlist
\item
  Generalisability: we cannot evaluate inferences to a target group from
  the source population if we do not describe the source population
\item
  Eligibility criteria will help us to ensure whether we have correctly
  evaluated potential measurement bias/error in our instruments.
\end{itemize}

For example, the New Zealand Attitudes and Values Study is a National
Probability study of New Zealanders. The details provided in the
supplementary materials describe how individuals were randomly selected
from the country's electoral roll. From these invitations there was
typically less than 15\% response rate. How might this process of
recruitment affect generalisability and transportability of our results?

\begin{itemize}
\tightlist
\item
  Aside: discuss per protocol effects/ intention to treat effects
\end{itemize}

\subsubsection{Determine how missing data will be
handled}\label{determine-how-missing-data-will-be-handled}

\begin{itemize}
\tightlist
\item
  As we will consider in the upcoming weeks, loss to follow up and
  non-response opens sources for bias. We must develop a strategy for
  handling missing data.
\end{itemize}

\subsubsection{State a statistical
model}\label{state-a-statistical-model}

The models we have considered in this course are G-computation, Inverse
Probability of Treatement Weighting, and Doubly-Robust estimation.

\subsubsection{Reporting}\label{reporting}

Consider the following ideas about how to report one's model:

\begin{itemize}
\tightlist
\item
  \textbf{Estimator}: Doubly robust where possible.
\item
  \textbf{Propensity Score Reporting:} Detail the process of propensity
  score derivation, including the model used and any variable
  transformations.
\item
  \textbf{WeightIt Package Utilisation:} Explicitly mention the use of
  the `WeightIt' package in R, including any specific options or
  parameters used in the propensity score estimation process.
\item
  \textbf{Method Variations:} Report if different methods were used to
  obtain propensity scores, and the reasons behind the choice of methods
  such as `ebal', `energy', and `ps'.
\item
  \textbf{Continuous Exposures:} Highlight that for continuous
  exposures, only the `energy' option was used for propensity score
  estimation.
\item
  \textbf{Subgroup Estimation:} Confirm that the propensity scores for
  subgroups were estimated separately, and discuss how the weights were
  subsequently combined with the original data.
\item
  \textbf{Covariate Balance:} Include a Love plot to visually represent
  covariate balance on the exposure both before and after weighting.
\item
  \textbf{Weighting Algorithm Statistics:} Report the statistics for the
  weighting algorithms as provided by the WeightIt package, including
  any measures of balance or fit.
\item
  \textbf{Outcome Regression Model:} Clearly report the type of
  regression model used to estimate outcome model coefficients (e.g.,
  linear regression, Poisson, binomial), and mention if the exposure was
  interacted with the baseline covariates. Do not report model
  coefficients as these have no interpretation.
\item
  \textbf{Subgroup Interaction:} Address whether the subgroup was
  included separately as an interaction in the outcome model, and if the
  model successfully converged.
\item
  \textbf{Model Coefficients:} Note that the model coefficients should
  not be interpreted, as they are not meaningful in this context.
\item
  \textbf{Confidence Intervals and Standard Errors:} Describe the
  methods used to derive confidence intervals and standard errors,
  noting the use of the `clarify' package in R for simulation based
  inference.
\end{itemize}

\subsubsection{Example of how to report a doubly robust method in your
report}\label{example-of-how-to-report-a-doubly-robust-method-in-your-report}

The Doubly Robust Estimation method for Subgroup Analysis Estimator is a
sophisticated tool combining features of both IPTW and G-computation
methods, providing unbiased estimates if either the propensity score or
outcome model is correctly specified. The process involves five main
steps:

\textbf{Step 1} involves the estimation of the propensity score, a
measure of the conditional probability of exposure given the covariates
and the subgroup indicator. This score is calculated using statistical
models such as logistic regression, with the model choice depending on
the nature of the data and exposure. Weights for each individual are
then calculated using this propensity score. These weights depend on the
exposure status and are computed differently for exposed and unexposed
individuals. The estimation of propensity scores is performed separately
within each subgroup stratum.

\textbf{Step 2} focuses on fitting a weighted outcome model, making use
of the previously calculated weights from the propensity scores. This
model estimates the outcome conditional on exposure, covariates, and
subgroup, integrating the weights into the estimation process. Unlike in
propensity score model estimation, covariates are included as variables
in the outcome model. This inclusion makes the method doubly robust -
providing a consistent effect estimate if either the propensity score or
the outcome model is correctly specified, thereby reducing the
assumption of correct model specification.

\textbf{Step 3} entails the simulation of potential outcomes for each
individual in each subgroup. These hypothetical scenarios assume
universal exposure to the intervention within each subgroup, regardless
of actual exposure levels. The expectation of potential outcomes is
calculated for each individual in each subgroup, using
individual-specific weights. These scenarios are performed for both the
current and alternative interventions.

\textbf{Step 4} is the estimation of the average causal effect for each
subgroup, achieved by comparing the computed expected values of
potential outcomes under each intervention level. The difference
represents the average causal effect of changing the exposure within
each subgroup.

\textbf{Step 5} involves comparing differences in causal effects across
groups by calculating the differences in the estimated causal effects
between different subgroups. Confidence intervals and standard errors
for these calculations are determined using simulation-based inference
methods (\hyperref[ref-greifer2023]{Greifer \emph{et al.} 2023}). This
step allows for a comprehensive comparison of the impact of different
interventions across various subgroups, while encorporating uncertainty.

\subsubsection{Inference}\label{inference}

Consider the following ideas about what to discuss in one's findings.
The order of exposition might be different.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Summary of results}: What did you find?
\item
  \textbf{Interpretation of E-values:} Interpret the E-values used for
  sensitivity analysis. State what they represent in terms of the
  robustness of the findings to potential unmeasured confounding.
\item
  \textbf{Causal Effect Interpretation:} What is the interest of the
  effect, if any, if an effect was observed? Interpret the average
  causal effect of changing the exposure level within each subgroup, and
  discuss its relevance to the research question.
\item
  \textbf{Comparison of Subgroups:} Discuss how differences in causal
  effect estimates between different subgroups, if observed, or if not
  observed, contribute to the overall findings of the study.
\item
  \textbf{Uncertainty and Confidence Intervals:} Consider the
  uncertainty around the estimated causal effects, and interpret the
  confidence intervals to understand the precision of the estimates.
\item
  \textbf{Generalisability and Transportability:} Reflect on the
  generalizability of the study results to other contexts or
  populations. Discuss any factors that might influence the
  transportability of the causal effects found in the study. (Again see
  lecture 9.)
\item
  \textbf{Assumptions and Limitations:} Reflect on the assumptions made
  during the study and identify any limitations in the methodology that
  could affect the interpretation of results. State that the
  implications of different intervention levels on potential outcomes
  are not analysed.
\item
  \textbf{Theoretical Relevance}: How are these findings relevant to
  existing theories.
\item
  \textbf{Replication and Future Research:} Consider how the study could
  be replicated or expanded upon in future research, and how the
  findings contribute to the existing body of knowledge in the field.
\item
  \textbf{Real-world Implications:} Discuss the real-world implications
  of the findings, and how they could be applied in policy, practice, or
  further research.
\end{enumerate}

\subsection{Part X Estimators}\label{part-x-estimators}

\subsubsection{Conditional estimators}\label{conditional-estimators}

\paragraph{Beyond Observed Associations: The Causal
Hurdle}\label{beyond-observed-associations-the-causal-hurdle}

The observed association can be misleading because it captures the
relationship between treatment \(A\) and outcome \(Y\) without adjusting
for confounding variables \(L\). The observed association often diverges
from the true causal effect \(\delta\), which we can express as:

\[
\delta = f_{\text{causal}}(Y, A | L)
\]

Note:

\begin{itemize}
\tightlist
\item
  \(f_{\text{causal}}\) is the causal function capturing the
  relationship between \(Y\) and \(A\), conditioned on \(L\).
\item
  \(L\) are the confounding variables.
\end{itemize}

One approach to isolate \(\delta\) from \(f_{\text{observed}}(Y, A)\) is
to use techniques like matching, inverse probability weighting (IPW), or
instrumental variables. These methods aim to emulate a randomized
experiment by adjusting for \(L\).

For example, to adjust for confounders in our linear model, we would
modify it as:

\[
Y = \beta_0 + \beta_1 A + \beta_2 L + \epsilon
\]

Here, \(\beta_2\) represents the vector of coefficients for confounding
variables \(C\).

In essence, merely relying on \(\beta_1\) from the naive OLS regression
can result in biased causal inferences. To move from observed
associations to causal estimates, we must adjust for confounders and
potentially use more advanced statistical techniques.

\paragraph{Marginal Structural Models}\label{marginal-structural-models}

A marginal structural model (MSM) is a causal model designed to estimate
causal effects from observational data by addressing confounding and
time-dependent covariates that may be simultaneously confounders and
intermediate variables. MSMs use inverse probability weighting (IPW) to
create a pseudo-population where the treatment assignment is independent
of measured confounders.

Mathematically, consider a treatment \(A\) and outcome \(Y\). The MSM
specifies the counterfactual outcome \(Y^a\) under treatment \(a\) as:

\[
E[Y^a] = \alpha + \theta a
\]

where \(\alpha\) is an intercept, and \(\theta\) is the causal effect of
interest.

Inverse probability weights \(e\) are calculated based on the
conditional probability of receiving the observed treatment given the
covariates:

\[
e_i = \frac{1}{P(A=a_i \mid \text{covariates})}
\]

For stabilised weights, a numerator term is added:

\[
e_i = \frac{P(A=a_i)}{P(A=a_i \mid \text{covariates})}
\]

The MSM is then fitted to the weighted pseudo-population to estimate
\(\theta\), which approximates the causal effect of the treatment in the
entire source population.

For example, in our screen time and well-being study, an MSM could help
isolate the direct effect of screen time on well-being while controlling
for confounding variables like age, socioeconomic status, or previous
well-being measures. The inverse probability weights could account for
the fact that different individuals have varying propensities to engage
in screen time based on these confounders.

\paragraph{Survey Weights vs IPTW}\label{survey-weights-vs-iptw}

Both survey weights and inverse probability of treatment weights (IPTWs)
adjust for non-representativeness, but they serve different purposes and
arise from different paradigms.

\paragraph{\texorpdfstring{\textbf{Survey
Weights}}{Survey Weights}}\label{survey-weights}

Survey weights, commonly denoted as ( W ), correct for unequal
probability of selection in the sampling process. These weights aim to
make the sample reflective of the source population. In a causal
inference context, survey weights are useful to make the estimated
average treatment effect (ATE) more generalisable to the source
population. Mathematically,

\[
ATE_{\text{source}} = \sum_{i=1}^N W_i \left( Y_{i1} - Y_{i0} \right)
\]

where \(N\) is the number of subjects, \(Y_{i1}\) and \(Y_{i0}\) are
potential outcomes under treatment and control, respectively, for
subject \(i\).

\paragraph{\texorpdfstring{\textbf{Inverse Probability of Treatment
Weights
(IPTWs)}}{Inverse Probability of Treatment Weights (IPTWs)}}\label{inverse-probability-of-treatment-weights-iptws}

IPTWs, denoted by \(e\), are designed to control for confounding by
equating the distribution of observed covariates between treatment and
control groups within the sample. The aim is to make the treatment
assignment as good as random, or ignorable. IPTWs are calculated as
follows:

\[
e_i = \frac{1}{P(A=a_i \mid \text{covariates})}
\]

When stabilised,

\[
e_i = \frac{P(A=a_i)}{P(A=a_i \mid \text{covariates})}
\]

\paragraph{\texorpdfstring{\textbf{Differences}}{Differences}}\label{differences}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Purpose}: Survey weights target the representativeness of the
  sample concerning the source population, while IPTWs aim to eliminate
  confounding within the sample.
\item
  \textbf{Calculation}: Survey weights often derive from design factors
  like stratification or clustering. IPTWs are calculated based on
  observed treatment and covariate distributions.
\item
  \textbf{Use Case}: Survey weights are often useful when
  generalisability to a broader population is the focus. IPTWs are
  useful in estimating internally valid causal effects within the
  sample.
\end{enumerate}

In summary, while both sets of weights serve to adjust for
non-representativeness or imbalance, they do so in differing contexts
and to achieve different aims. Both can coexist in the same analysis if
both generalisability and internal validity are concerns. \#\#\# Average
Treatment Effects (Difference Scale)

\subsubsection{\texorpdfstring{\textbf{G-computation
Estimator}}{G-computation Estimator}}\label{g-computation-estimator}

\textbf{Step 1} Estimate the outcome model. Fit a model for the outcome
\(Y\), conditional on the exposure \(A\), and the covariates \(L\). This
model can be a linear regression, logistic regression, or another
statistical model. The goal is to capture the relationship between the
outcome, exposure, and confounders.

\[ \hat{E}(Y|A,L) = f_Y(A,L; \theta_Y) \]

This equation represents the expected value of the outcome \(Y\) given
the exposure \(A\), and covariates \(L\), as modeled by the function
\(f_Y\) with parameters \(\theta_Y\).

\textbf{Step 2} Simulate potential outcomes. For each individual,
predict their potential outcome under the intervention \(A=a\) using the
estimated outcome model:

\[\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y]\]

We also predict the potential outcome for everyone under the causal
contrast, setting the intervention to \(A=a'\):

\[  \hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y]\]

In these equations, \(Y\) represents the potential outcome, \(A\) is the
intervention, and \(L\) are the covariates.

\textbf{Step 3} Calculate the estimated difference:

\[\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]\]

This difference \(\hat{\delta}\) represents the average causal effect of
changing the exposure from level \(a'\) to level \(a\).

We use simulation-based inference methods to compute standard errors and
confidence intervals (\hyperref[ref-greifer2023]{Greifer \emph{et al.}
2023}).

\subsubsection{\texorpdfstring{\textbf{Inverse Probability of Treatment
Weighting (IPTW)
Estimator}}{Inverse Probability of Treatment Weighting (IPTW) Estimator}}\label{inverse-probability-of-treatment-weighting-iptw-estimator}

\textbf{Step 1} Estimate the propensity score. The propensity score
\(e(L)\) is the conditional probability of the exposure \(A = 1\), given
the covariates \(L\). This can be modeled using logistic regression or
other suitable methods, depending on the nature of the data and the
exposure.

\[e = P(A = 1 | L) = f_A(L; \theta_A)\]

Here, \(f_A(L; \theta_A)\) is a function (statistical model) that
estimates the probability of the exposure \(A = 1\) given covariates
\(L\). Then, we calculate the weights for each individual, denoted as
\(v\):

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

\textbf{Step 2} Fit a weighted outcome model. Using the weights
calculated from the estimated propensity scores, fit a model for the
outcome \(Y\), conditional on the exposure \(A\):

\[ \hat{E}(Y|A; V) = f_Y(A; \theta_Y, V) \]

In this model, \(f_Y\) is a function (such as a weighted regression
model) with parameters \(\theta_Y\). The weights \(V\) are incorporated
into the estimation process, affecting how much each observation
contributes to the estimation.

\textbf{Step 3} Simulate potential outcomes. For each individual,
simulate their potential outcome under the hypothetical scenario where
everyone is exposed to the intervention \(A=a\):

\[\hat{E}(Y|A=a)  = \hat{E}[Y|A=a; \hat{\theta}_Y,  v_i]\]

and also under the hypothetical scenario where everyone is exposed to
intervention \(A=a'\):

\[\hat{E}(Y|A=a')  = \hat{E}[Y|A=a'; \hat{\theta}_Y,  v_i]\]

The expectation is calculated for each individual \(i\), with
individual-specific weights \(v_i\).

\textbf{Step 4} Estimate the average treatment effect as the difference
in the predicted outcomes:

\[\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]\]

The estimated difference \(\hat{\delta}\) represents the ATE. We use
simulation-based inference methods to compute standard errors and
confidence intervals.

We again, use simulation-based inference methods to compute standard
errors and confidence intervals (\hyperref[ref-greifer2023]{Greifer
\emph{et al.} 2023}).

\subsubsection{Doubly Robust Estimation}\label{doubly-robust-estimation}

\textbf{Step 1} Estimate the propensity score. The propensity score
\(e(L)\) is the conditional probability of the exposure \(A = 1\), given
the covariates \(L\).

\[e = P(A = 1 | L) = f_A(L; \theta_A)\]

Here, \(f_A(L; \theta_A)\) is a function (statistical model) estimating
the probability of exposure \(A = 1\) given covariates \(L\). We
calculate the weights for each individual, denoted as \(v\), using the
estimated propensity score:

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

\textbf{Step 2} Fit a weighted outcome model. Using the weights \(v\),
fit a model for the outcome \(Y\), conditional on the exposure \(A\).

\[ \hat{E}(Y|A, L; v) = f_Y(A, L ; \theta_Y, v) \]

Here, \(f_Y\) is a function (such as a weighted regression model) with
parameters \(\theta_Y\). The weights \(v\) are incorporated into the
estimation process.

\textbf{Step 3} Simulate potential outcomes under different scenarios
for each individual. For instance, simulate the outcome under the
hypothetical scenario where everyone is exposed to intervention \(A=a\):

\[\hat{E}(Y|A=a)  = \hat{E}[Y|A=a,L; \hat{\theta}_Y, v_i]\]

and also under the scenario where everyone is exposed to intervention
\(A=a'\):

\[\hat{E}(Y|A=a')  = \hat{E}[Y|A=a',L; \hat{\theta}_Y, v_i]\]

\textbf{Step 4} Estimate the average causal effect. Compute the
estimated expected value of the potential outcomes under each
intervention level:

\[\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]\]

The difference \(\delta\) represents the average causal effect of
changing the exposure from level \(a^{\prime}\) to level \(a\).

We again use simulation-based inference methods to compute standard
errors and confidence intervals (\hyperref[ref-greifer2023]{Greifer
\emph{et al.} 2023}).

\subsubsection{Subgroup estimators}\label{subgroup-estimators}

\subsubsection{\texorpdfstring{\textbf{G-computation for Subgroup
Analysis
Estimator}}{G-computation for Subgroup Analysis Estimator}}\label{g-computation-for-subgroup-analysis-estimator}

\textbf{Step 1} Estimate the outcome model. Fit a model for the outcome
\(Y\), conditional on the exposure \(A\), the covariates \(L\), and
subgroup indicator \(G\). This model can be a linear regression,
logistic regression, or another statistical model. The goal is to
capture the relationship between the outcome, exposure, confounders, and
subgroups.

\[ \hat{E}(Y|A,L,G) = f_Y(A,L,G; \theta_Y) \]

This equation represents the expected value of the outcome \(Y\) given
the exposure \(A\), covariates \(L\), and subgroup \(G\), as modeled by
the function \(f_Y\) with parameters \(\theta_Y\). This formulation
allows for the prediction of the average outcome \(Y\) given certain
values of \(A\), \(L\), and \(G\).

\textbf{Step 2} Simulate potential outcomes. For each individual in each
subgroup, predict their potential outcome under the intervention \(A=a\)
using the estimated outcome model:

\[\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y]\]

We also predict the potential outcome for everyone in each subgroup
under the causal contrast, setting the intervention for everyone in that
group to \(A=a'\):

\[\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y]\]

In these equations, \(Y\) represents the potential outcome, \(A\) is the
intervention, \(L\) are the covariates, \(G=g\) represents the subgroup,
and \(\theta_Y\) are the parameters of the outcome model.

\textbf{Step 3} Calculate the estimated difference for each subgroup
\(g\):

\[\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]\]

This difference \(\hat{\delta}_g\) represents the average causal effect
of changing the exposure from level \(a'\) to level \(a\) within each
subgroup \(g\).

We use simulation-based inference methods to compute standard errors and
confidence intervals (\hyperref[ref-greifer2023]{Greifer \emph{et al.}
2023}).

\textbf{Step 4} Compare differences in causal effects by subgroups:

\[\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}\]

where,

\[\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}\]

This difference \(\hat{\gamma}\) represents the difference in the
average causal effects between the subgroups \(g\) and \(g'\). It
measures the interaction effect of the exposure \(A\) and the subgroup
\(G\) on the outcome \(Y\).

We again use simulation-based inference methods to compute standard
errors and confidence intervals (\hyperref[ref-greifer2023]{Greifer
\emph{et al.} 2023}).

\subsubsection{\texorpdfstring{\textbf{Inverse Probability of Treatment
Weighting (IPTW) for Subgroup Analysis
Estimator}}{Inverse Probability of Treatment Weighting (IPTW) for Subgroup Analysis Estimator}}\label{inverse-probability-of-treatment-weighting-iptw-for-subgroup-analysis-estimator}

\textbf{Step 1} Estimate the propensity score. The propensity score
\(e(L, G)\) is the conditional probability of the exposure \(A = 1\),
given the covariates \(L\) and subgroup indicator \(G\). This can be
modeled using logistic regression or other suitable methods, depending
on the nature of the data and the exposure.

\[e = P(A = 1 | L, G) = f_A(L, G; \theta_A)\]

Here, \(f_A(L, G; \theta_A)\) is a function (statistical model) that
estimates the probability of the exposure \(A = 1\) given covariates
\(L\) and subgroup \(G\). Then, we calculate the weights for each
individual, denoted as \(v\), using the estimated propensity score:

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

Thus, \(v\) depends on \(A\), and is calculated as the inverse of the
propensity score for exposed individuals and as the inverse of \(1-e\)
for unexposed individuals.

Note that we estimate propensity scores \emph{separately} within strata
of the subgroup for whom we are interested in effect modification. \(v\)
is the weight for each individual in a given subgroup \(G\).

\textbf{Step 2} Fit a weighted outcome model. Using the weights
calculated from the estimated propensity scores, fit a model for the
outcome \(Y\), conditional on the exposure \(A\) and subgroup \(G\).
This can be represented as:

\[ \hat{E}(Y|A, G; V) = f_Y(A, G ; \theta_Y, V) \]

In this model, \(f_Y\) is a function (such as a weighted regression
model) with parameters \(θ_Y\). The weights \(V\) are incorporated into
the estimation process, affecting how much each observation contributes
to the estimation of \(θ_Y\), but they are not themselves an additional
variable within the model.

Note that in this formulation, unlike doubly-robust estimation, \(L\) is
not included as a variable in the outcome model, but its effect is
accounted for through the weights \(V\), which are calculated based on
the estimated propensity scores that do include \(L\).

\textbf{Step 3} Simulate potential outcomes. For each individual in each
subgroup, simulate their potential outcome under the hypothetical
scenario where everyone in the subgroup is exposed to the intervention
\(A=a\) regardless of their actual exposure level:

\[\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,G=g; \hat{\theta}_Y,  v_i]\]

and also under the hypothetical scenario where everyone is exposed to
intervention \(A=a'\):

\[\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',G=g; \hat{\theta}_Y,  v_i]\]

Thus the expectation is calculated for each individual \(i\) in each
subgroup \(g\), with individual-specific weights \(v_i\).

\textbf{Step 4} Estimate the average causal effect for each subgroup as
the difference in the predicted outcomes:

\[\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]\]

The estimated difference \(\hat{\delta}_g\) represents the average
causal effect withing group \(g\). We use simulation-based inference
methods to compute standard errors and confidence intervals
(\hyperref[ref-greifer2023]{Greifer \emph{et al.} 2023}).

\textbf{Step 5} Compare differences in causal effects by groups. Compute
the differences in the estimated causal effects between different
subgroups:

\[\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}\]

where,

\[\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}\]

We again use simulation-based inference methods to compute standard
errors and confidence intervals (\hyperref[ref-greifer2023]{Greifer
\emph{et al.} 2023}).

\subsubsection{Doubly Robust Estimation for Subgroup Analysis
Estimator}\label{doubly-robust-estimation-for-subgroup-analysis-estimator}

Doubly Robust Estimation is a powerful technique that combines the
strengths of both the IPTW and G-computation methods. It uses both the
propensity score model and the outcome model, which makes it doubly
robust: it produces unbiased estimates if either one of the models is
correctly specified.

\textbf{Step 1} Estimate the propensity score. The propensity score
\(e(L, G)\) is the conditional probability of the exposure \(A = 1\),
given the covariates \(L\) and subgroup indicator \(G\). This can be
modeled using logistic regression or other suitable methods, depending
on the nature of the data and the exposure.

\[e = P(A = 1 | L, G) = f_A(L, G; \theta_A)\]

Here, \(f_A(L, G; \theta_A)\) is a function (statistical model) that
estimates the probability of the exposure \(A = 1\) given covariates
\(L\) and subgroup \(G\). Then, we calculate the weights for each
individual, denoted as \(v\), using the estimated propensity score:

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

Thus, \(v\) depends on \(A\), and is calculated as the inverse of the
propensity score for exposed individuals and as the inverse of \(1-e\)
for unexposed individuals.

Note that we estimate propensity scores \emph{separately} within strata
of the subgroup for whom we are interested in effect modification. \(v\)
is the weight for each individual in a given subgroup \(G\).

\textbf{Step 2} Fit a weighted outcome model. Using the weights
calculated from the estimated propensity scores, fit a model for the
outcome \(Y\), conditional on the exposure \(A\) and subgroup \(G\).
This can be represented as:

\[ \hat{E}(Y|A, L, G; V) = f_Y(A, L, G ; \theta_Y, V) \]

In this model, \(f_Y\) is a function (such as a weighted regression
model) with parameters \(θ_Y\). The weights \(V\) are incorporated into
the estimation process, affecting how much each observation contributes
to the estimation of \(θ_Y\), but they are not themselves an additional
variable within the model.

Note that in this formulation, unlike propensity score model,
estimation, \(L\) is included as a variable in the outcome model,
Although imbalance in \(L\) on \(A\) is accounted for by the weights
\(V\), by including \(L\) in the outcome model this method is doubly
robust insofar as we will obtain a consistent effect estimate if either
the propensity score or the outcome model is correctly specified. This
property reduces the strength of the assumption of correct model
specification.

\textbf{Step 3} For each individual in each subgroup, simulate their
potential outcome under the hypothetical scenario where everyone in the
subgroup is exposed to the intervention \(A=a\) regardless of their
actual exposure level:

\[\hat{E}(Y|A=a, G=g)  = \hat{E}[Y|A=a,L,G=g; \hat{\theta}_Y,  v_i]\]

and also under the hypothetical scenario where everyone in each subgroup
is exposed to intervention \(A=a'\):

\[\hat{E}(Y|A=a', G=g)  = \hat{E}[Y|A=a',L,G=g; \hat{\theta}_Y,  v_i]\]

Thus the expectation is calculated for each individual \(i\) in each
subgroup \(g\), with individual-specific weights \(v_i\).

\textbf{Step 4} Estimate the average causal effect for each subgroup.
Compute the estimated expected value of the potential outcomes under
each intervention level for each subgroup:

\[\hat{\delta}_g = \hat{E}[Y(a)|G=g] - \hat{E}[Y(a')|G=g]\]

The difference \(\delta_g\) represents the average causal effect of
changing the exposure from level \(a^{\prime}\) to level \(a\) within
each subgroup.

We use simulation-based inference methods to compute standard errors and
confidence intervals (\hyperref[ref-greifer2023]{Greifer \emph{et al.}
2023}).

\textbf{Step 5} Compare differences in causal effects by groups. Compute
the differences in the estimated causal effects between different
subgroups:

\[\hat{\gamma} = \hat{\delta}_g - \hat{\delta}_{g'}\]

where,

\[\hat{\gamma} = \overbrace{\big( \hat{E}[Y(a)|G=g] - \hat{E}[Y(a^{\prime})|G=g] \big)}^{\hat{\delta_g}} - \overbrace{\big(\hat{E}[Y(a^{\prime})|G=g^{\prime}]- \hat{E}[Y(a)|G=g^{\prime}]\big)}^{\hat{\delta_{g^{\prime}}}}\]

We again use simulation-based inference methods to compute standard
errors and confidence intervals (\hyperref[ref-greifer2023]{Greifer
\emph{et al.} 2023}).

\subsection{Inverse Probability of Treatment Weighting (IPTW)
Protocolos}\label{inverse-probability-of-treatment-weighting-iptw-protocolos}

We assess balance using \textbf{standardised mean differences},
\textbf{Mean and Max Difference Adjusted}

\subsubsection{Standardised means difference in the context of Inverse
Probability of Treatment Weighting
(IPTW)}\label{standardised-means-difference-in-the-context-of-inverse-probability-of-treatment-weighting-iptw}

Standardised means difference is a measure used to compare the
difference between two groups.

\subsubsection{Definition:}\label{definition}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Standardised Means Difference (SMD)}: SMD is used to express
  the size of the intervention effect in each study relative to the
  variability observed in that study. It is computed as the difference
  between means divided by a standard deviation of the data. Formula for
  SMD is: \[
  \text{SMD} = \frac{{\bar{X}_1 - \bar{X}_2}}{{s}}
  \] where \(\bar{X}_1\) and \(\bar{X}_2\) are the means of the two
  groups, and \(s\) is the pooled standard deviation.
\item
  \textbf{Inverse Probability of Treatment Weighting (IPTW)}: IPTW uses
  propensity scores to create a synthetic sample in which the
  distribution of measured baseline covariates is independent of
  treatment assignment. It aims to mimic a randomised experiment by
  creating a balanced comparison.
\item
  \textbf{Weighting IPTW with SMD}: Weighting using IPTW can adjust the
  SMD between the treated and untreated groups. The balance in
  covariates is often assessed by checking whether the absolute value of
  the SMD is close to 0.
\end{enumerate}

\subsubsection{Step-by-step:}\label{step-by-step}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Estimate Propensity Score}: Use logistic regression, or other
  methods, to estimate the propensity score for each subject.
\item
  \textbf{Calculate IPTW}: The weight for each subject is the inverse of
  the probability of receiving the treatment that was actually received.
  For treated subjects: \[
  w = \frac{1}{{\text{propensity score}}}
  \] For untreated subjects: \[
  w = \frac{1}{{1 - \text{propensity score}}}
  \]
\item
  \textbf{Compute Standardised Means Difference}: Calculate the SMD for
  each covariate using the IPTW, comparing the treated and untreated
  groups.
\item
  \textbf{Assess Balance}: If the absolute value of the SMD for a
  covariate is close to 0, the groups are considered balanced for that
  covariate.
\end{enumerate}

This approach allows for causal inference in observational studies,
making the comparison of treated and untreated groups as if
randomisation had occurred. It is crucial in causal inference, to
minimise bias due to confounding variables.

\subsubsection{Min and Max adjusted average difference in
means}\label{min-and-max-adjusted-average-difference-in-means}

When achieving balance using Inverse Probability of Treatment Weighting
(IPTW), ``Mean.Diff.Adj'' and ``Max.Diff.Adj'' are specific statistics
often used to assess the balance of covariates between the treatment and
control groups after weighting. Definitions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Mean.Diff.Adj}:

  \begin{itemize}
  \tightlist
  \item
    Refers to the average difference in means of covariates between the
    treated and untreated groups after applying IPTW.
  \item
    Formula: \[
    \text{Mean.Diff.Adj} = \frac{{\sum w_i \cdot (X_{1i} - X_{0i})}}{{\sum w_i}}
    \] where \(w_i\) is the weight for subject \(i\), and \(X_{1i}\) and
    \(X_{0i}\) are the values of the covariate for the treated and
    untreated subjects, respectively.
  \item
    Close to 0 indicates good balance.
  \end{itemize}
\item
  \textbf{Max.Diff.Adj}:

  \begin{itemize}
  \tightlist
  \item
    Refers to the maximum absolute difference in means of covariates
    between the treated and untreated groups after applying IPTW.
  \item
    Formula: \[
    \text{Max.Diff.Adj} = \max \left| \frac{{\sum w_i \cdot (X_{1i} - X_{0i})}}{{\sum w_i}} \right|
    \]
  \item
    Close to 0 indicates good balance, and it focuses on the
    worst-balanced covariate, which could be a point of concern even if
    the overall mean difference is small.
  \end{itemize}
\end{enumerate}

The difference between ``Mean.Diff.Adj'' and ``Max.Diff.Adj'' in the
context of Inverse Probability of Treatment Weighting (IPTW) lies in
what they measure regarding the balance of covariates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Mean.Diff.Adj}:

  \begin{itemize}
  \tightlist
  \item
    Measures the \textbf{average} difference in means of covariates
    between the treated and untreated groups after applying IPTW.
  \item
    Reflects the overall balance across all covariates.
  \item
    A value close to 0 indicates good overall balance.
  \end{itemize}
\item
  \textbf{Max.Diff.Adj}:

  \begin{itemize}
  \tightlist
  \item
    Measures the \textbf{maximum absolute} difference in means of
    covariates between the treated and untreated groups after applying
    IPTW.
  \item
    Focuses on the worst-balanced covariate, regardless of the overall
    balance.
  \item
    A value close to 0 indicates that even the most imbalanced covariate
    is well-balanced, but a high value could be a concern even if the
    mean difference is small.
  \end{itemize}
\end{enumerate}

In summary, while ``Mean.Diff.Adj'' provides a sense of the general
balance achieved across all covariates, ``Max.Diff.Adj'' zeroes in on
the single most imbalanced covariate. The former gives a global view,
while the latter highlights the potentially problematic area, both
crucial for understanding the balance achieved by IPTW.

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-bulbulia2022}{}}%
Bulbulia, JA (2022) A workflow for causal inference in cross-cultural
psychology. \emph{Religion, Brain \& Behavior}, \textbf{0}(0), 1--16.
doi:\href{https://doi.org/10.1080/2153599X.2022.2070245}{10.1080/2153599X.2022.2070245}.

\leavevmode\vadjust pre{\hypertarget{ref-chatton2020}{}}%
Chatton, A, Le Borgne, F, Leyrat, C, \ldots{} Foucher, Y (2020)
G-computation, propensity score-based methods, and targeted maximum
likelihood estimator for causal inference with different covariates
sets: a comparative simulation study. \emph{Scientific Reports},
\textbf{10}(1), 9219.
doi:\href{https://doi.org/10.1038/s41598-020-65917-x}{10.1038/s41598-020-65917-x}.

\leavevmode\vadjust pre{\hypertarget{ref-danaei2012}{}}%
Danaei, G, Tavakkoli, M, and Hernán, MA (2012) Bias in observational
studies of prevalent users: lessons for comparative effectiveness
research from a meta-analysis of statins. \emph{American Journal of
Epidemiology}, \textbf{175}(4), 250--262.
doi:\href{https://doi.org/10.1093/aje/kwr301}{10.1093/aje/kwr301}.

\leavevmode\vadjust pre{\hypertarget{ref-greifer2023}{}}%
Greifer, N, Worthington, S, Iacus, S, and King, G (2023) \emph{Clarify:
Simulation-based inference for regression models}. Retrieved from
\url{https://iqss.github.io/clarify/}

\leavevmode\vadjust pre{\hypertarget{ref-hernuxe1n2023}{}}%
Hernán, MA, and Monge, S (2023) Selection bias due to conditioning on a
collider. \emph{BMJ}, \textbf{381}, p1135.
doi:\href{https://doi.org/10.1136/bmj.p1135}{10.1136/bmj.p1135}.

\leavevmode\vadjust pre{\hypertarget{ref-hernuxe1n2016a}{}}%
Hernán, MA, Sauer, BC, Hernández-Díaz, S, Platt, R, and Shrier, I (2016)
Specifying a target trial prevents immortal time bias and other
self-inflicted injuries in observational analyses. \emph{Journal of
Clinical Epidemiology}, \textbf{79}, 7075.

\leavevmode\vadjust pre{\hypertarget{ref-hernuxe1n2022}{}}%
Hernán, MA, Wang, W, and Leaf, DE (2022) Target trial emulation: A
framework for causal inference from observational data. \emph{JAMA},
\textbf{328}(24), 2446--2447.
doi:\href{https://doi.org/10.1001/jama.2022.21383}{10.1001/jama.2022.21383}.

\leavevmode\vadjust pre{\hypertarget{ref-ogburn2021}{}}%
Ogburn, EL, and Shpitser, I (2021) Causal modelling: The two cultures.
\emph{Observational Studies}, \textbf{7}(1), 179--183.
doi:\href{https://doi.org/10.1353/obs.2021.0006}{10.1353/obs.2021.0006}.

\leavevmode\vadjust pre{\hypertarget{ref-shi2021}{}}%
Shi, B, Choirat, C, Coull, BA, VanderWeele, TJ, and Valeri, L (2021)
CMAverse: A suite of functions for reproducible causal mediation
analyses. \emph{Epidemiology}, \textbf{32}(5), e20e22.

\leavevmode\vadjust pre{\hypertarget{ref-vantongeren2020}{}}%
Van Tongeren, DR, DeWall, CN, Chen, Z, Sibley, CG, and Bulbulia, J
(2020) Religious residue: Cross-cultural evidence that religious
psychology and behavior persist following deidentification.
\emph{Journal of Personality and Social Psychology}.

\leavevmode\vadjust pre{\hypertarget{ref-vanderweele2017a}{}}%
VanderWeele, TJ (2017) Outcome-wide epidemiology. \emph{Epidemiology
(Cambridge, Mass.)}, \textbf{28}(3), 399--402.
doi:\href{https://doi.org/10.1097/EDE.0000000000000641}{10.1097/EDE.0000000000000641}.

\leavevmode\vadjust pre{\hypertarget{ref-vanderweele2020}{}}%
VanderWeele, TJ, Mathur, MB, and Chen, Y (2020b) Outcome-wide
longitudinal designs for causal inference: A new template for empirical
studies. \emph{Statistical Science}, \textbf{35}(3), 437466.

\leavevmode\vadjust pre{\hypertarget{ref-vanderweele2020a}{}}%
VanderWeele, TJ, Mathur, MB, and Chen, Y (2020a) Outcome-wide
longitudinal designs for causal inference: A new template for empirical
studies. \emph{Statistical Science}, \textbf{35}(3), 437466.

\end{CSLReferences}



\end{document}
