---
title: "Trust Sceince Environment"
subtitle: ""
abstract: |
  Counterfactual Prediction
author: 
  - name: Joseph A. Bulbulia
    affiliation: Victoria University of Wellington, New Zealand
    orcid_id: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: yes
  - name: Don E Davis
    affiliation: Georgia State University
    orcid_id: 0000-0003-3169-6576 
  - name: Ken Rice
    affiliation: Georgia State University 
  - name: Geoffrey Troughton
    affiliation: Victoria University of Wellington
  - name: Chris G. Sibley
    affiliation: School of Psychology, University of Auckland
    orcid_id: 0000-0002-4064-8800
execute:
  warning: false
  eval: false
keywords:
  - measurement
date: last-modified
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-libraries
#| echo: false
#| include: true
#| eval: true

# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# for latex graphs
# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


### ALWAYS RESTART R IN A FRESH SESSION ####

# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23-ow-env-science"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)



# check path:is this correct?  check so you know you are not overwriting other directors
push_mods


# for information on LMPT go to 
#https://github.com/nt-williams/lmtp
#devtools::install_github("nt-williams/lmtp@devel")

# for modified treatment policies
library("lmtp")
push_mods
```


```{r}
#| label: clean data
#| echo: false
#| include: false
#| eval: false

# note that religion church NA we impute zero to those who are not religious in the "religion_church2" variable

# check here
# table(is.na( dat$religion_church)) 
# table(is.na( dat$religion_church2)) 

# Note: read this: # create dataframes, one for each level of the factor.  This allows valid multiple imputation see: 
# https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-023-01843-6


# select variables and emulate a target trial according to eligibility criteria
# you may need to select different confounders. note that the more you include, the less efficient the estimates,
# particularly if the confounder is only associated with the exposure.  On the other hand, better to err on the side of caution 

#"science_trust",# #"I have a high degree of confidence in the scientific community./  Our society places too much emphasis on science.(n) (SD)


## assess correlation
# cor(dat$science_trust01, dat$science_trust02r,  method = "pearson", use = "complete.obs")
# #[1] 0.5033631. # not convincing
# 
# cor(dat$science_trust01, dat$science_trust02r,  method = "spearman", use = "complete.obs")
# # [1] 0.5694429
# 
# cor(dat$science_trust01, dat$science_trust02r,  method = "kendall", use = "complete.obs")
# # [1] 0.4913033
df <- dat |>
  arrange(id, wave) |>
  mutate(urban = factor(
    ifelse(
      rural_gch2018 == "Medium Urban Accessibility" |
        # Define urban condition
        rural_gch2018 == "High Urban Accessibility",
      "urban",
      # Label 'urban' if condition is met
      "rural"  # Label 'rural' if condition is not met
    )
  )) |>
  mutate(covid19_timeline = as.factor(covid19_timeline)) |> 
  dplyr::rename(sample_weights = w_gend_age_euro) |>
  select("id", 
         "wave",
         "sample_weights",
         "year_measured", 
         "male", 
         "born_nz",
         "covid19_timeline",
         "urban",
         "religion_identification",
         "science_trust01",
         "pol_orient",
         "age",
         "partner",
         "parent",
         "eth_cat",
         "nzsei13",
         "covid19_timeline",
         "env_climate_chg_real",
         "env_climate_chg_cause", # "Climate change is caused by humans"
         "env_climate_chg_concern", #"I am deeply concerned about climate change."
         "env_sat_nz_environment") |>
  arrange(id, wave) %>%
  dplyr::filter((wave == 2019 & year_measured  == 1) |
                  (wave == 2020  &
                     year_measured  == 1) |
                  (wave == 2021 )) |>  # Eligibility criteria  Observed in 2018/2019 & Outcomes in 2020 or 2021
  group_by(id) |>
  dplyr::mutate(k_19 =  ifelse(wave == 2019 &
                                 !is.na(science_trust01), 1, 0)) |>   # creating an indicator for the first wave. Inclusion criteria
  dplyr::mutate(h_19 = mean(k_19, na.rm = TRUE)) |>   # Hack
  dplyr::mutate(k_20 =  ifelse(wave == 2020 &
                                 year_measured == 1 &
                                 !is.na(science_trust01), #  Inclusion criteria
                               1,
                               0)) |>   # creating an indicator for the first wave; note that we allow people t
  dplyr::mutate(h_20 = mean(k_20, na.rm = TRUE)) |>  # Hack
  dplyr::filter(h_19 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_20 > 0) |>  # hack to enable repeat of baseline
    mutate(
    not_censored = ifelse(lead(year_measured) == 1, 1, 0),
    # not_censored = ifelse(lead(year_measured)== -1, 0, not_censored,
    # not_censored = ifelse(lead(year_measured) == 0, 0, not_censored,
    not_censored = ifelse(is.na(not_censored) &
                            year_measured == 1, 1, not_censored),
    not_censored = ifelse(is.na(not_censored), 0, not_censored)

  ) |>
  ungroup() |> 
  arrange(id, wave) |> 
  droplevels() |> 
  select(-h_19,-k_20,-h_20,-k_19) |> 
  data.frame()

colnames(df)
# 
# margot_wide <- function(.data, baseline_vars, exposure_var, outcome_vars) {
#   require(tidyverse)
#   # Add the 'time' column to the data
#   data_with_time <- .data %>%
#     mutate(time = as.numeric(wave) - 1) %>%
#     arrange(id, time)
# 
#   # Filter the data based on the time condition
#   data_filtered <- data_with_time %>%
#     filter(time >= 0)
# 
#   # Create the wide data frame
#   wide_data <- data_filtered %>%
#     pivot_wider(
#       id_cols = id,
#       names_from = time,
#       values_from = -c(id, time),
#       names_glue = "t{time}_{.value}",
#       names_prefix = "t"
#     )
# 
#   # Define a custom function to filter columns based on conditions
#   custom_col_filter <- function(col_name) {
#     if (startsWith(col_name, "t0_")) {
#       return(col_name %in% c(
#         paste0("t0_", baseline_vars),
#         paste0("t0_", exposure_var),
#         paste0("t0_", outcome_vars)
#       ))
#     } else if (startsWith(col_name, "t1_")) {
#       return(col_name %in% paste0("t1_", exposure_var))
#     } else if (grepl("^t[2-9][0-9]*_", col_name)) {
#       return(col_name %in% paste0("t2_", outcome_vars))
#     } else {
#       return(FALSE)
#     }
#   }
# 
#   # Apply the custom function to select the desired columns
#   wide_data_filtered <- wide_data %>%
#     dplyr::select(id, which(sapply(colnames(wide_data), custom_col_filter))) %>%
#     dplyr::relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#     arrange(id)
# 
#   # Extract unique time values from column names
#   time_values <- gsub("^t([0-9]+)_.+$", "\\1", colnames(wide_data_filtered))
#   time_values <- time_values[grepl("^[0-9]+$", time_values)]
#   time_values <- unique(as.numeric(time_values))
#   time_values <- time_values[order(time_values)]
# 
#   # Relocate columns iteratively
#   for (i in 2:(length(time_values) - 1)) {
#     wide_data_filtered <- wide_data_filtered %>%
#       dplyr::relocate(starts_with(paste0("t", time_values[i + 1], "_")), .after = starts_with(paste0("t", time_values[i], "_")))
#   }
#   # Reorder t0_ columns
#   t0_column_order <- c(paste0("t0_", baseline_vars), paste0("t0_", exposure_var), paste0("t0_", outcome_vars))
#   wide_data_ordered <- wide_data_filtered %>%
#     select(id, all_of(t0_column_order), everything())
# 
#   return(data.frame(wide_data_ordered)) # Ensure output is a data.frame
# }
# 

# Define your baseline, exposure, and outcome variables without any prefix
baseline_vars <- c(
  "male",
  "born_nz",
  "covid19_timeline",
  "urban",
  "partner",
  "parent",
  "eth_cat",
  "nzsei13",
  "pol_orient",
  "sample_weights"
)



exposure_var <- c("science_trust01","not_censored")

outcome_vars <- c("env_climate_chg_real", "env_climate_chg_cause","env_climate_chg_concern", "env_sat_nz_environment")

# Call your function
df_wide <- margot_wide(df, baseline_vars = baseline_vars, exposure_var = exposure_var, outcome_vars = outcome_vars)
df_wide_censored <- 
  df_wide |> 
  relocate("t0_not_censored", .before = starts_with("t1_"))  %>%
  relocate("t1_not_censored", .before = starts_with("t2_"))
  # select(-"t0_not_censored") 

head( df_wide_censored ) 


n_unique(df_wide_censored$id) # 31782
# missing values not permitted for lmpt
# df_clean <- df_wide_censored %>%
#   filter(!rowSums(is.na(select(
#     ., starts_with("t0_") )))) |>
#   dplyr::mutate(across(where(is.numeric) &
#                         !t0_not_censored &  !t1_not_censored & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) |>
#   select(where(is.factor), t0_not_censored,  t1_not_censored, t0_sample_weights, ends_with("_z")) |>
#   relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#   relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
#   relocate("t0_not_censored", .before = starts_with("t1_"))  %>%
#   relocate("t1_not_censored", .before = starts_with("t2_")) |>
#   mutate(t0_sample_weights = as.numeric(t0_sample_weights)) |>
#   data.frame()

df_clean <- df_wide_censored %>%
  mutate(t2_na_flag = rowSums(is.na(select(., starts_with("t2_")))) > 0) %>%
  mutate(t1_not_censored = ifelse(t2_na_flag, 0, t1_not_censored)) %>%
 # select(-t2_na_flag) %>%
  filter(!rowSums(is.na(select(., starts_with("t0_"))))) |> 
  dplyr::mutate(across(where(is.numeric) &
                        !t0_not_censored & !t1_not_censored & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) |>
  select(where(is.factor), t0_not_censored, t1_not_censored, t0_sample_weights, ends_with("_z")) |>
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate("t0_not_censored", .before = starts_with("t1_"))  %>%
  relocate("t1_not_censored", .before = starts_with("t2_")) |> 
  mutate(t0_sample_weights = as.numeric(t0_sample_weights)) |> 
  data.frame()

# df_clean <- df_wide_censored %>%
#   mutate(t1_not_censored = ifelse(rowSums(is.na(select(., starts_with("t2_")))) > 0, 0, t1_not_censored)) %>%
#   filter(!rowSums(is.na(select(., starts_with("t0_"))))) %>%
#   dplyr::mutate(across(where(is.numeric) &
#                         !t0_not_censored &  !t1_not_censored & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
#   select(where(is.factor), t0_not_censored,  t1_not_censored, t0_sample_weights, ends_with("_z")) %>%
#   relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#   relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
#   relocate("t0_not_censored", .before = starts_with("t1_"))  %>%
#   relocate("t1_not_censored", .before = starts_with("t2_")) %>%
#   mutate(t0_sample_weights = as.numeric(t0_sample_weights)) %>%
#   data.frame()


# Check the output
n_unique(df_clean$id) # 29946

table(df_clean$t1_not_censored)

# Continue on with the other steps


head(df_clean)

names_base <- df_clean |> select( starts_with("t0"), - t0_sample_weights,-t0_not_censored )|> colnames()

names_base

n_unique(df_clean$id) # 30420
head(df_clean)

# check: 
df_clean$t2_env_climate_chg_cause_z

#vis_miss(df_clean_2)

outcome_vars
# attempt model
A <- c( "t1_science_trust01_z")
C <- c( "t1_not_censored")

#L <- list(c("L1"), c("L2")) 
W <- c(paste(names_base, collapse = ", "))

print(W) 

#baseline confounders
#L <- as.list(names_base)
min(df_clean$t1_science_trust01_z, na.rm=TRUE)
# shift function -- what if everyone increased by .5 standard deviation, except those above 2 


f <- function(data, trt){
  ifelse( data[[trt]] < 0,  data[[trt]] + 1,  data[[trt]] )
}

#f <- function(data, trt) data[[trt]] + 0.25

# Create a vector indicating what algorithms should be R. # used in the SuperLearner 
sl_lib <- c("SL.glmnet", "SL.ranger", "SL.earth") 
# "SL.earth" refers to a wrapper for the 'earth' function from the 'earth' R package in the SuperLearner library. This function implements Multivariate Adaptive Regression Splines (MARS), a non-parametric regression method that extends linear models by allowing for interactions and non-linear relationships between variables.

# MARS models can handle high-dimensional data well and can be a useful tool for capturing complex patterns in the data. They work by fitting piecewise linear models to the data, which allows for flexible and potentially non-linear relationships between predictors and the outcome.


sl_lib2<- c("SL.glmnet", "SL.xgboost", "SL.randomForest") # faster

vis_miss(df_clean)
dev.off()

head(sim_cens)
# save model
push_mods
here_save(df_clean,"df_clean")

# BONUS: progressr progress bars!
progressr::handlers(global = TRUE)

# recomend tmle for single time point
# recommend sdr for multiple time points
m_env_climate_chg_real <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_real_z",  
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")


here_save(m_env_climate_chg_real, "m_env_climate_chg_real")
m_env_climate_chg_real

m_env_climate_chg_cause <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_cause_z",  
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")

here_save(m_env_climate_chg_cause, "m_env_climate_chg_cause")
m_env_climate_chg_cause <- here_read("m_env_climate_chg_cause")

m_env_climate_chg_cause

m_env_climate_chg_concern <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_concern_z",
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")


here_save(m_env_climate_chg_concern, "m_env_climate_chg_concern")
m_env_climate_chg_concern <- here_read( "m_env_climate_chg_concern")



m_env_sat_nz_environment <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_sat_nz_environment_z",
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")
m_env_sat_nz_environment
str(m_env_sat_nz_environment)
summarize_results( m_env_sat_nz_environment, est_trt = 0, ci_level = 0.95,
                              ci_type = c("marginal") ) 

m_env_sat_nz_environment <- here_read( "m_env_sat_nz_environment")

#### My code
format_tab_tmle <- function(tmtp_output, scale = c("RD", "RR"), new_name = "character_string") {
  
  scale <- match.arg(scale)
  
  require(dplyr)
  
  tab_tmle <- cbind.data.frame(
    tmtp_output$theta,
    tmtp_output$standard_error,
    tmtp_output$low,
    tmtp_output$high
  )
  
  if (scale == "RD") {
    colnames(tab_tmle) <- c("E[Y(1)]-E[Y(0)]", "standard_error", "2.5 %", "97.5 %")
  } else if (scale == "RR") {
    colnames(tab_tmle) <- c("E[Y(1)]/E[Y(0)]", "standard_error", "2.5 %", "97.5 %")
  }
  
  tab_tmle_round <- tab_tmle |> 
    dplyr::mutate(across(where(is.numeric), round, digits = 4))
  
  rownames(tab_tmle_round)[1] <- paste0(new_name)
  
  return(tab_tmle_round)
}
tab_tmle_round


result_m_env_sat_nz_environment <- format_tab_tmle(m_env_sat_nz_environment, scale = "RD", new_name = "satisfied environment")

result_m_env_sat_nz_environment

result_m_env_climate_chg_concern <- format_tab_tmle(m_env_climate_chg_concern, scale = "RD", new_name = "climate change concern")

result_m_env_climate_chg_concern

result_m_env_climate_chg_cause <- format_tab_tmle(m_env_climate_chg_cause, scale = "RD", new_name = "climate change human")

result_m_env_climate_chg_cause

result_m_env_climate_chg_real <-  format_tab_tmle(m_env_climate_chg_real, scale = "RD", new_name = "climate change real")

str(result_m_env_climate_chg_real)
test_group_tab
test_group_tab <- rbind(result_m_env_climate_chg_real,result_m_env_climate_chg_cause,result_m_env_climate_chg_concern,result_m_env_sat_nz_environment)

grouped_outcomes <- group_tab_2( test_group_tab, type = "RD" ) 
grouped_outcomes
margot_plot(
  grouped_outcomes,
  type = "RD",
  title = "Modified Treatment Policy",
  subtitle = "If one is below average trust in science, intervene to add + 1 SD trust in science.",
  xlab = "x",
  ylab = "y",
  x_offset =  -.2,
  x_lim_lo = -.2,
  x_lim_hi = .2
)
    

```


