---
title: "Trust Sceince Environment"
subtitle: ""
abstract: |
  Counterfactual Prediction
author: 
  - name: Joseph A. Bulbulia
    affiliation: Victoria University of Wellington, New Zealand
    orcid_id: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: yes
  - name: Don E Davis
    affiliation: Georgia State University
    orcid_id: 0000-0003-3169-6576 
  - name: Ken Rice
    affiliation: Georgia State University 
  - name: Geoffrey Troughton
    affiliation: Victoria University of Wellington
  - name: Chris G. Sibley
    affiliation: School of Psychology, University of Auckland
    orcid_id: 0000-0002-4064-8800
execute:
  warning: false
  eval: false
keywords:
  - measurement
date: last-modified
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-libraries
#| echo: false
#| include: true
#| eval: true

# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# for latex graphs
# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


### ALWAYS RESTART R IN A FRESH SESSION ####

# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs_refactor/nzavs_data_23"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23-ow-env-science"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)



# check path:is this correct?  check so you know you are not overwriting other directors
push_mods


# for information on LMPT go to 
#https://github.com/nt-williams/lmtp
#devtools::install_github("nt-williams/lmtp@devel")

# for modified treatment policies
library("lmtp")
push_mods

# set exposure here
nzavs_exposure <-
  "trust_science_our_society_places_too_much_emphasis_reversed"

# define exposure
A <-
  "t1_trust_science_our_society_places_too_much_emphasis_reversed_z"

# define shift function (if any one is average make them average, otherwise leave alone)
f <- function(data, trt) {
  ifelse(data[[trt]] <= 0, 0,  data[[trt]])
}

# set number of folds for ML here. use a minimum of 5 and a max of 10
SL_folds = 5

#this will allow you to track progress
progressr::handlers(global = TRUE)

# set seed for reproducing results
set.seed(0112358)

# set cores for estimation
library(future)
plan(multisession)
n_cores <- parallel::detectCores()

# super learner libraries
sl_lib <- c("SL.glmnet",
            "SL.ranger",
            "SL.xgboost")

#Improve speed (if needed)

# sl_lib_args <- list(
#   SL.glmnet = list(nalpha = 5, nlambda = 20),
#   SL.ranger = list(num.threads = 4),
#   SL.xgboost = list(nthread = 4,
#                     nrounds = 50,
#                     early_stopping_rounds = 10,
#                     max_depth = 6,
#                     colsample_bytree = 0.8,
#                     subsample = 0.8,
#                     eta = 0.01,
#                     tree_method = 'hist')
# )

# superlearner libraries
library(SuperLearner)
library(ranger)
library(xgboost)
library(glmnet)

# boost spped
SL.xgboost = list(tree_method = 'gpu_hist')


# check options
listWrappers()



```


```{r}
#| label: clean data
#| echo: false
#| include: false
#| eval: false

# note that religion church NA we impute zero to those who are not religious in the "religion_church2" variable

# check here
# table(is.na( dat$religion_church)) 
# table(is.na( dat$religion_church2)) 

# Note: read this: # create dataframes, one for each level of the factor.  This allows valid multiple imputation see:# https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-023-01843-6


# select variables and emulate a target trial according to eligibility criteria
# you may need to select different confounders. note that the more you include, the less efficient the estimates,
# particularly if the confounder is only associated with the exposure.  On the other hand, better to err on the side of caution

#"science_trust",# #"I have a high degree of confidence in the scientific community./  Our society places too much emphasis on science.(n) (SD)


## assess correlation
# cor(dat$science_trust01, dat$science_trust02r,  method = "pearson", use = "complete.obs")
# #[1] 0.5033631. # not convincing
#
# cor(dat$science_trust01, dat$science_trust02r,  method = "spearman", use = "complete.obs")
# # [1] 0.5694429
# cor(dat$science_trust01, dat$science_trust02r,  method = "kendall", use = "complete.obs")
# # [1] 0.4913033
dat_long <- dat |>
  arrange(id, wave) |>
  # mutate(urban = factor(
  #   ifelse(
  #     rural_gch2018 == "Medium Urban Accessibility" |
  #       # Define urban condition
  #       rural_gch2018 == "High Urban Accessibility",
  #     "urban",
  #     # Label 'urban' if condition is met
  #     "rural"  # Label 'rural' if condition is not met
  #   )
  # )) |>
  rename(
    trust_science_high_confidence_scientific_community = science_trust01,
    trust_science_our_society_places_too_much_emphasis_reversed =
      science_trust02r
  ) |>
  mutate(covid19_timeline = as.factor(covid19_timeline)) |>
  dplyr::rename(sample_weights = w_gend_age_euro) |>
  arrange(id, wave) |>
  rowwise(wave) |>
  mutate(power_no_control_composite = mean(c(
    power_self_nocontrol, power_others_control
  ), na.rm = TRUE)) |>
  mutate(kessler_latent_depression =  mean(
    c(kessler_depressed, kessler_hopeless, kessler_worthless),
    na.rm = TRUE
  )) |>
  mutate(kessler_latent_anxiety  = mean(c(
    kessler_effort, kessler_nervous, kessler_restless
  ), na.rm = TRUE)) |>
  ungroup() |>
  mutate(religion_church_round = round(ifelse(religion_church >= 8, 8, religion_church), 0)) |>
  mutate(male = as.numeric(male)) |>
  mutate(total_siblings_factor = ordered(round(
    ifelse(total_siblings > 7, 7, total_siblings), 0
  ))) |>
  
  mutate(
    eth_cat = as.integer(eth_cat),
    urban = as.numeric(urban),
    education_level_coarsen = as.integer(education_level_coarsen)
  ) |>
  dplyr::mutate(
    friends_money = ifelse(friends_money < 0, 0, friends_money),
    # someone gave neg number
    household_inc_log = log(household_inc + 1),
    hours_children_log = log(hours_children + 1),
    hours_work_log = log(hours_work + 1),
    hours_housework_log = log(hours_housework + 1),
    hours_exercise_log = log(hours_exercise + 1)
  ) |>
  select(
    "wave",
    "year_measured",
    "id",
    # "edu",
    "sample_origin_names_combined",
    # Sample origin names combined
    #"alert_level_combined_lead",  not needed because all receive all levels by the point the outcome is measured
    # covid alert levels -> 2019-2020
    "education_level_coarsen",
    # Ordinal-Rank 0-10 NZREG codes (with overseas school quals coded as Level 3, and all other ancillary categories coded as missing)  Combined highschool levels See:https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf
    "male",
    # 0 = female, 0.5 = neither female nor male, 1 = male.
    "age",
    "born_nz",
    "hlth_disability",
    # value label 0    No 1   Yes
    "eth_cat",
    #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed",
    # Are you currently employed? (this includes self-employment or casual work)
    # "gen_cohort",
    "household_inc_log",
    # Please estimate your total household income (before tax) for the last year.
    "nz_dep2018",
    # see nzavs materials
    "nzsei13",
    # see nzavs materials
    "partner",
    # 0 = no, 1 = yes
    "parent",
    # 0 = no, 1 = yes
    "political_conservative",
    #Please rate how politically liberal versus conservative you see yourself as being.
    "pol_wing",
    # Please rate how politically left-wing versus right-wing you see yourself as being.
    "urban",
    # see NZAVS,
    "have_siblings",
    #Do you have siblings?
    "total_siblings",
    "total_siblings_factor",
    # sum siblings
    "number_sisters_older",
    
    #How many older sisters do you have?
    "number_sisters_younger",
    #	How many younger sisters do you have?
    "number_brothers_older",
    #	How many older brothers do you have?
    "number_brothers_younger",
    #	How many older brothers do you have?
    "children_num",
    # How many children have you given birth to, fathered, or adopted?
    "hours_children_log",
    #Hours - Looking after children
    "hours_work_log",
    #Hours - Working in paid employment
    "hours_housework_log",
    # Hours - Housework/cooking
    "hours_exercise_log",
    "agreeableness",
    # Mini-IPIP6 Agreeableness (also modelled as empathy facet)
    # Sympathize with others' feelings.
    # Am not interested in other people's problems.
    # Feel others' emotions.
    # Am not really interested in others.
    "conscientiousness",
    # see mini ipip6
    # Get chores done right away.
    # Like order.
    # Make a mess of things.
    # Often forget to put things back in their proper place.
    "extraversion",
    # Mini-IPIP6 Extraversion
    # Am the life of the party.
    # Don't talk a lot.
    # Keep in the background.
    # Talk to a lot of different people at parties.
    "honesty_humility",
    # see mini ipip6
    # Would like to be seen driving around in a very expensive car.
    # Would get a lot of pleasure from owning expensive luxury goods.
    # Feel entitled to more of everything.
    # Deserve more things in life.
    "openness",
    # see mini ipip6
    # Have a vivid imagination.
    # Have difficulty understanding abstract ideas.
    # Do not have a good imagination.
    # Am not interested in abstract ideas.
    "neuroticism",
    # see mini ipip6
    # Have frequent mood swings.
    # Am relaxed most of the time.
    # Get upset easily.
    # Seldom feel blue.
    "modesty",
    # see mini ipip6
    # I want people to know that I am an important person of high status,
    # I am an ordinary person who is no better than others.
    # I wouldn’t want people to treat me as though I were superior to them.
    # I think that I am entitled to more respect than the average person is
    # "sdo",
    # "rwa",
    # "brk_relationship",
    # "began_relationship",
    "religion_religious",
    # Do you identify with a religion and/or spiritual group?
    # "religion_religious_not",  # reverse this indicator
    "religion_identification_level",
    #How important is your religion to how you see yourself?"
    "religion_prayer",
    # How many times did you pray in the last week?
    "religion_scripture",
    # How many times did you read religious scripture in the last week?
    "religion_church",
    # How many times did you attend a church or place of worship in the last month?
    "religion_believe_spirit",
    #Do you believe in some form of spirit or lifeforce?
    "religion_believe_spirit",
    #inverse believe in god
    "religion_believe_god",
    #Do you believe in a God
    "religion_believe_god_not",
    #inverse believe in god
    "religion_spiritual_identification",
    #w8,w10,w12-13 "I identify as a spiritual person."
    "religion_perceive_religious_discrim",
    #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
    # "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers
    "sample_weights",
    # sample_weights.
    # Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "gratitude",
    ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of peopl
    "modesty",
    # see above
    "env_climate_chg_real",
    "env_climate_chg_cause",
    # "Climate change is caused by humans"
    "env_climate_chg_concern",
    #"I am deeply concerned about climate change."
    "env_sat_nz_environment",
    "alert_level_combined",
    "sample_origin",
  ) |>
  
  arrange(id, wave) %>%
  dplyr::filter((wave == 2019 & year_measured  == 1) |
                  (wave == 2020  &
                     year_measured  == 1) |
                  (wave == 2021)) |>  # Eligibility criteria  Observed in 2018/2019 & Outcomes in 2020 or 2021
  group_by(id) |>
  ## MAKE SURE YOU HAVE ELIGIBILITY CRITERIA
  dplyr::mutate(meets_criteria_baseline = ifelse(year_measured == 1 &
                                                   !is.na(!!sym(nzavs_exposure)), 1, 0)) |>  # using R lang
  dplyr::mutate(sample_origin = sample_origin_names_combined) |>  #shorter name
  dplyr::mutate(k_19 =  ifelse(wave == 2019 &
                                 meets_criteria_baseline == 1, 1, 0)) |>   # creating an indicator for the first wave. Inclusion criteria
  dplyr::mutate(h_19 = mean(k_19, na.rm = TRUE)) |>   # Hack
  dplyr::mutate(k_20 =  ifelse(wave == 2020 &
                                 ymeets_criteria_baseline == 1, #  Inclusion criteria
                               1,
                               0)) |>   # creating an indicator for the first wave; note that we allow people
  dplyr::mutate(h_20 = mean(k_20, na.rm = TRUE)) |>  # Hack
  dplyr::filter(h_19 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_20 > 0) |>  # hack to enable repeat of baseline
  ungroup() |>
  arrange(id, wave) |>
  droplevels() |>
  mutate(
    not_lost = ifelse(lead(year_measured) == 1, 1, 0),
    # not_lost = ifelse(lead(year_measured)== -1, 0, not_lost,
    # not_lost = ifelse(lead(year_measured) == 0, 0, not_lost,
    not_lost = ifelse(is.na(not_lost) &
                        year_measured == 1, 1, not_lost),
    not_lost = ifelse(is.na(not_lost), 0, not_lost)
    
  ) |>
  select(-h_19, -k_20, -h_20, -k_19) |>
  data.frame()

colnames(dat_long)
# 
# margot_wide <- function(.data, baseline_vars, exposure_var, outcome_vars) {
#   require(tidyverse)
#   # Add the 'time' column to the data
#   data_with_time <- .data %>%
#     mutate(time = as.numeric(wave) - 1) %>%
#     arrange(id, time)
# 
#   # Filter the data based on the time condition
#   data_filtered <- data_with_time %>%
#     filter(time >= 0)
# 
#   # Create the wide data frame
#   wide_data <- data_filtered %>%
#     pivot_wider(
#       id_cols = id,
#       names_from = time,
#       values_from = -c(id, time),
#       names_glue = "t{time}_{.value}",
#       names_prefix = "t"
#     )
# 
#   # Define a custom function to filter columns based on conditions
#   custom_col_filter <- function(col_name) {
#     if (startsWith(col_name, "t0_")) {
#       return(col_name %in% c(
#         paste0("t0_", baseline_vars),
#         paste0("t0_", exposure_var),
#         paste0("t0_", outcome_vars)
#       ))
#     } else if (startsWith(col_name, "t1_")) {
#       return(col_name %in% paste0("t1_", exposure_var))
#     } else if (grepl("^t[2-9][0-9]*_", col_name)) {
#       return(col_name %in% paste0("t2_", outcome_vars))
#     } else {
#       return(FALSE)
#     }
#   }
# 
#   # Apply the custom function to select the desired columns
#   wide_data_filtered <- wide_data %>%
#     dplyr::select(id, which(sapply(colnames(wide_data), custom_col_filter))) %>%
#     dplyr::relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#     arrange(id)
# 
#   # Extract unique time values from column names
#   time_values <- gsub("^t([0-9]+)_.+$", "\\1", colnames(wide_data_filtered))
#   time_values <- time_values[grepl("^[0-9]+$", time_values)]
#   time_values <- unique(as.numeric(time_values))
#   time_values <- time_values[order(time_values)]
# 
#   # Relocate columns iteratively
#   for (i in 2:(length(time_values) - 1)) {
#     wide_data_filtered <- wide_data_filtered %>%
#       dplyr::relocate(starts_with(paste0("t", time_values[i + 1], "_")), .after = starts_with(paste0("t", time_values[i], "_")))
#   }
#   # Reorder t0_ columns
#   t0_column_order <- c(paste0("t0_", baseline_vars), paste0("t0_", exposure_var), paste0("t0_", outcome_vars))
#   wide_data_ordered <- wide_data_filtered %>%
#     select(id, all_of(t0_column_order), everything())
# 
#   return(data.frame(wide_data_ordered)) # Ensure output is a data.frame
# }
# 

# Define your baseline, exposure, and outcome variables without any prefix
baseline_vars <- c(
  "male",
  "born_nz",
  "covid19_timeline",
  "urban",
  "partner",
  "parent",
  "eth_cat",
  "nzsei13",
  "pol_orient",
  "sample_weights"
)



exposure_var <- c("science_trust01","not_lost")

outcome_vars <- c("env_climate_chg_real", "env_climate_chg_cause","env_climate_chg_concern", "env_sat_nz_environment")

# Call your function
df_wide <- margot_wide(df, baseline_vars = baseline_vars, exposure_var = exposure_var, outcome_vars = outcome_vars)
df_wide_censored <- 
  df_wide |> 
  relocate("t0_not_lost", .before = starts_with("t1_"))  %>%
  relocate("t1_not_lost", .before = starts_with("t2_"))
  # select(-"t0_not_lost") 

head( df_wide_censored ) 


n_unique(df_wide_censored$id) # 31782
# missing values not permitted for lmpt
# df_clean <- df_wide_censored %>%
#   filter(!rowSums(is.na(select(
#     ., starts_with("t0_") )))) |>
#   dplyr::mutate(across(where(is.numeric) &
#                         !t0_not_lost &  !t1_not_lost & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) |>
#   select(where(is.factor), t0_not_lost,  t1_not_lost, t0_sample_weights, ends_with("_z")) |>
#   relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#   relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
#   relocate("t0_not_lost", .before = starts_with("t1_"))  %>%
#   relocate("t1_not_lost", .before = starts_with("t2_")) |>
#   mutate(t0_sample_weights = as.numeric(t0_sample_weights)) |>
#   data.frame()

df_clean <- df_wide_censored %>%
  mutate(t2_na_flag = rowSums(is.na(select(., starts_with("t2_")))) > 0) %>%
  mutate(t1_not_lost = ifelse(t2_na_flag, 0, t1_not_lost)) %>%
 # select(-t2_na_flag) %>%
  filter(!rowSums(is.na(select(., starts_with("t0_"))))) |> 
  dplyr::mutate(across(where(is.numeric) &
                        !t0_not_lost & !t1_not_lost & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) |>
  select(where(is.factor), t0_not_lost, t1_not_lost, t0_sample_weights, ends_with("_z")) |>
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate("t0_not_lost", .before = starts_with("t1_"))  %>%
  relocate("t1_not_lost", .before = starts_with("t2_")) |> 
  mutate(t0_sample_weights = as.numeric(t0_sample_weights)) |> 
  data.frame()

# df_clean <- df_wide_censored %>%
#   mutate(t1_not_lost = ifelse(rowSums(is.na(select(., starts_with("t2_")))) > 0, 0, t1_not_lost)) %>%
#   filter(!rowSums(is.na(select(., starts_with("t0_"))))) %>%
#   dplyr::mutate(across(where(is.numeric) &
#                         !t0_not_lost &  !t1_not_lost & !t0_sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
#   select(where(is.factor), t0_not_lost,  t1_not_lost, t0_sample_weights, ends_with("_z")) %>%
#   relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#   relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
#   relocate("t0_not_lost", .before = starts_with("t1_"))  %>%
#   relocate("t1_not_lost", .before = starts_with("t2_")) %>%
#   mutate(t0_sample_weights = as.numeric(t0_sample_weights)) %>%
#   data.frame()


# Check the output
n_unique(df_clean$id) # 29946

table(df_clean$t1_not_lost)

# Continue on with the other steps


head(df_clean)

names_base <- df_clean |> select( starts_with("t0"), - t0_sample_weights,-t0_not_lost )|> colnames()

names_base

n_unique(df_clean$id) # 30420
head(df_clean)

# check: 
df_clean$t2_env_climate_chg_cause_z

#vis_miss(df_clean_2)

outcome_vars
# attempt model
A <- c( "t1_science_trust01_z")
C <- c( "t1_not_lost")

#L <- list(c("L1"), c("L2")) 
W <- c(paste(names_base, collapse = ", "))

print(W) 

#baseline confounders
#L <- as.list(names_base)
min(df_clean$t1_science_trust01_z, na.rm=TRUE)
# shift function -- what if everyone increased by .5 standard deviation, except those above 2 


f <- function(data, trt){
  ifelse( data[[trt]] < 0,  data[[trt]] + 1,  data[[trt]] )
}

#f <- function(data, trt) data[[trt]] + 0.25

# Create a vector indicating what algorithms should be R. # used in the SuperLearner 
sl_lib <- c("SL.glmnet", "SL.ranger", "SL.earth") 
# "SL.earth" refers to a wrapper for the 'earth' function from the 'earth' R package in the SuperLearner library. This function implements Multivariate Adaptive Regression Splines (MARS), a non-parametric regression method that extends linear models by allowing for interactions and non-linear relationships between variables.

# MARS models can handle high-dimensional data well and can be a useful tool for capturing complex patterns in the data. They work by fitting piecewise linear models to the data, which allows for flexible and potentially non-linear relationships between predictors and the outcome.


sl_lib2<- c("SL.glmnet", "SL.xgboost", "SL.randomForest") # faster

vis_miss(df_clean)
dev.off()

head(sim_cens)
# save model
push_mods
here_save(df_clean,"df_clean")

# BONUS: progressr progress bars!
progressr::handlers(global = TRUE)

# recomend tmle for single time point
# recommend sdr for multiple time points
m_env_climate_chg_real <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_real_z",  
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")


here_save(m_env_climate_chg_real, "m_env_climate_chg_real")
m_env_climate_chg_real

m_env_climate_chg_cause <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_cause_z",  
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")

here_save(m_env_climate_chg_cause, "m_env_climate_chg_cause")
m_env_climate_chg_cause <- here_read("m_env_climate_chg_cause")

m_env_climate_chg_cause

m_env_climate_chg_concern <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_climate_chg_concern_z",
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")


here_save(m_env_climate_chg_concern, "m_env_climate_chg_concern")
m_env_climate_chg_concern <- here_read( "m_env_climate_chg_concern")



m_env_sat_nz_environment <- lmtp_tmle(data = df_clean, 
                                   trt = A, 
                                   baseline = names_base,
                                   outcome = "t2_env_sat_nz_environment_z",
                                   cens = C,
                                   shift = f, 
                                   mtp = TRUE, 
                                   folds = 5, # ideally use ten
                                   #.trim = 0.999,
                                  # time_vary = NULL,
                                   outcome_type = "continuous",
                                 #  id = "id",
                                   weights = df_clean$t0_sample_weights,
                                   learners_trt = "SL.glmnet",
                                   learners_outcome = "SL.glmnet")
m_env_sat_nz_environment
str(m_env_sat_nz_environment)
summarize_results( m_env_sat_nz_environment, est_trt = 0, ci_level = 0.95,
                              ci_type = c("marginal") ) 

m_env_sat_nz_environment <- here_read( "m_env_sat_nz_environment")

#### My code
format_tab_tmle <- function(tmtp_output, scale = c("RD", "RR"), new_name = "character_string") {
  
  scale <- match.arg(scale)
  
  require(dplyr)
  
  tab_tmle <- cbind.data.frame(
    tmtp_output$theta,
    tmtp_output$standard_error,
    tmtp_output$low,
    tmtp_output$high
  )
  
  if (scale == "RD") {
    colnames(tab_tmle) <- c("E[Y(1)]-E[Y(0)]", "standard_error", "2.5 %", "97.5 %")
  } else if (scale == "RR") {
    colnames(tab_tmle) <- c("E[Y(1)]/E[Y(0)]", "standard_error", "2.5 %", "97.5 %")
  }
  
  tab_tmle_round <- tab_tmle |> 
    dplyr::mutate(across(where(is.numeric), round, digits = 4))
  
  rownames(tab_tmle_round)[1] <- paste0(new_name)
  
  return(tab_tmle_round)
}
tab_tmle_round


result_m_env_sat_nz_environment <- format_tab_tmle(m_env_sat_nz_environment, scale = "RD", new_name = "satisfied environment")

result_m_env_sat_nz_environment

result_m_env_climate_chg_concern <- format_tab_tmle(m_env_climate_chg_concern, scale = "RD", new_name = "climate change concern")

result_m_env_climate_chg_concern

result_m_env_climate_chg_cause <- format_tab_tmle(m_env_climate_chg_cause, scale = "RD", new_name = "climate change human")

result_m_env_climate_chg_cause

result_m_env_climate_chg_real <-  format_tab_tmle(m_env_climate_chg_real, scale = "RD", new_name = "climate change real")

str(result_m_env_climate_chg_real)
test_group_tab
test_group_tab <- rbind(result_m_env_climate_chg_real,result_m_env_climate_chg_cause,result_m_env_climate_chg_concern,result_m_env_sat_nz_environment)

grouped_outcomes <- group_tab_2( test_group_tab, type = "RD" ) 
grouped_outcomes
margot_plot(
  grouped_outcomes,
  type = "RD",
  title = "Modified Treatment Policy",
  subtitle = "If one is below average trust in science, intervene to add + 1 SD trust in science.",
  xlab = "x",
  ylab = "y",
  x_offset =  -.2,
  x_lim_lo = -.2,
  x_lim_hi = .2
)
    

```


