---
title: "Causal effects of religious affiation on multi-dimensional well-being"
subtitle: "An outcome-wide study"
abstract: |
  Religious change itself.
  
author: 
  - name: Joseph A. Bulbulia
    affiliation: Victoria University of Wellington, New Zealand
    orcid_id: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: yes
  - name: Don E Davis
    affiliation: Georgia State University
    orcid_id: 0000-0003-3169-6576 
  - name: Ken Rice
    affiliation: Georgia State University 
  - name: Geoffrey Troughton
    affiliation: Victoria University of Wellington
  - name: Daryl Van Tongeren
    affiliation: Hope College
  - name: Chris G. Sibley
    affiliation: School of Psychology, University of Auckland
    orcid_id: 0000-0002-4064-8800
keywords:
  - Author order TBA.
execute:
  warning: false
  eval: false
  echo: false
  include: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: true

# for html use the following in the headign 
# format:
#   pdf:
#   html:
#     html-math-method:
#       method: mathjax

# format: latex
# keep-md: true

# for latex graphs
# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")

### ALWAYS RESTART R IN A FRESH SESSION ####
# regularly update tinytex: quarto update tinytex

# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# experimental functions (more functions)
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23-outcomewide-religious-affiliation"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)


# check path:is this correct?  check so you know you are not overwriting other directors
push_mods


```

```{r}
#| label: clean-data
#| echo: false
#| include: false
#| eval: false

# note that religion church NA we impute zero to those who are not religious in the "religion_church2" variable

# check here
# table(is.na( dat$religion_church)) 
# table(is.na( dat$religion_church2)) 

# Note: read this: # create dataframes, one for each level of the factor.  This allows valid multiple imputation see: 
# https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-023-01843-6


# select variables and emulate a target trial according to eligibility criteria
# you may need to select different confounders. note that the more you include, the less efficient the estimates,
# particularly if the confounder is only associated with the exposure.  On the other hand, better to err on the side of caution 

# select variables and emulate a target trial according to eligibility criteria
# you may need to select different confounders. note that the more you include, the less efficient the estimates,
# particularly if the confounder is only associated with the exposure.  On the other hand, better to err on the side of caution 0

dat_long <- dat |>
  arrange(id, wave) |>
 dplyr::filter(id != 9630) %>% # problematic reports no income but works full time and owns home.
  mutate(urban = factor(
    ifelse(
      rural_gch2018 == "Medium Urban Accessibility" |
        # Define urban condition
        rural_gch2018 == "High Urban Accessibility",
      "urban",
      # Label 'urban' if condition is met
      "rural"  # Label 'rural' if condition is not met
    )
  )) |>
  # select variables
  # mutate(across(where(is.double), as.numeric)) |>
  mutate(male = as.numeric(male) - 1) |>
  rename(religion_religious = religious) |>  # religious yes/no
  mutate(religion_church_binary = ifelse(religion_church > 0, 1, 0)) |>
  mutate(religion_church_binary2 = ifelse(religion_church2 > 0, 1, 0)) |>
  mutate(religion_religious = as.integer(as.numeric(as.character(religion_religious)))) |> 
  mutate(religion_religious_not = abs(religion_religious - 1)) |> 
  mutate(religion_believe_spirit = as.integer(as.numeric(as.character(religion_believe_spirit))) - 1) |> 
 # mutate(religion_believe_spirit_not = abs(religion_believe_spirit - 1)) |> # see target trial for use of this variable
  mutate(religion_believe_god = as.integer(as.numeric(as.character(religion_believe_god))) - 1) |> 
  mutate(religion_believe_god_not = abs(religion_believe_god - 1)) |> 
  dplyr::select(
    "wave",
    "year_measured",
    "id",
    # "edu",
    "sample_origin_names_combined",
    # Sample origin names combined
    #"alert_level_combined_lead",  not needed because all receive all levels by the point the outcome is measured
    # covid alert levels -> 2019-2020
    "education_level_coarsen",
    # Ordinal-Rank 0-10 NZREG codes (with overseas school quals coded as Level 3, and all other ancillary categories coded as missing)  Combined highschool levels See:https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf
    "male",
    # 0 = female, 0.5 = neither female nor male, 1 = male.
    "age",
    "born_nz",
    "hlth_disability",
    # value label 0    No 1   Yes
    "eth_cat",
    #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed",
    # Are you currently employed? (this includes self-employment or casual work)
    # "gen_cohort",
    "household_inc",
    # Please estimate your total household income (before tax) for the last year.
    "nz_dep2018",
    # see nzavs materials
    "nzsei13",
    # see nzavs materials
    "partner",
    # 0 = no, 1 = yes
    "parent",
    # 0 = no, 1 = yes
    "pol_orient",
    #Please rate how politically liberal versus conservative you see yourself as being.
    "pol_wing",
    # Please rate how politically left-wing versus right-wing you see yourself as being.
    "urban",
    # see NZAVS,
    "have_siblings", #Do you have siblings?
    "total_siblings",# sum siblings
    "number_sisters_older", #How many older sisters do you have?   
    "number_sisters_younger", #	How many younger sisters do you have? 
    "number_brothers_older",#	How many older brothers do you have?
    "number_brothers_younger", #	How many older brothers do you have?
    "children_num", # How many children have you given birth to, fathered, or adopted?
    "hours_children", #Hours - Looking after children
    "hours_work",#Hours - Working in paid employment
    "hours_housework", # Hours - Housework/cooking
    "agreeableness",
    # Mini-IPIP6 Agreeableness (also modelled as empathy facet)
    # Sympathize with others' feelings.
    # Am not interested in other people's problems.
    # Feel others' emotions.
    # Am not really interested in others.
    "conscientiousness",
    # see mini ipip6
    # Get chores done right away.
    # Like order.
    # Make a mess of things.
    # Often forget to put things back in their proper place.
    "extraversion",
    # Mini-IPIP6 Extraversion
    # Am the life of the party.
    # Don't talk a lot.
    # Keep in the background.
    # Talk to a lot of different people at parties.
    "honesty_humility",
    # see mini ipip6
    # Would like to be seen driving around in a very expensive car.
    # Would get a lot of pleasure from owning expensive luxury goods.
    # Feel entitled to more of everything.
    # Deserve more things in life.
    "openness",
    # see mini ipip6
    # Have a vivid imagination.
    # Have difficulty understanding abstract ideas.
    # Do not have a good imagination.
    # Am not interested in abstract ideas.
    "neuroticism",
    # see mini ipip6
    # Have frequent mood swings.
    # Am relaxed most of the time.
    # Get upset easily.
    # Seldom feel blue.
    "modesty",
    # see mini ipip6
    # I want people to know that I am an important person of high status,
    # I am an ordinary person who is no better than others.
    # I wouldn’t want people to treat me as though I were superior to them.
    # I think that I am entitled to more respect than the average person is
    # "sdo",
    # "rwa",
    # "brk_relationship",
    # "began_relationship",
    "religion_religious",
    # Do you identify with a religion and/or spiritual group?
   # "religion_religious_not",  # reverse this indicator
    "religion_identification_level",
    #How important is your religion to how you see yourself?"
    "religion_church_binary",
    "religion_church_binary2",
    "religion_prayer",
    # How many times did you pray in the last week?
    "religion_scripture",
    # How many times did you read religious scripture in the last week?
    "religion_church2",
    # How many times did you attend a church or place of worship in the last month?
    "religion_believe_spirit",
    #Do you believe in some form of spirit or lifeforce?
    "religion_believe_spirit",  #inverse believe in god
    "religion_believe_god",
    #Do you believe in a God
    "religion_believe_god_not",  #inverse believe in god
    "religion_spiritual_identification",
    #w8,w10,w12-13 "I identify as a spiritual person."
    "religion_perceive_religious_discrim",
    #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
    # "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers
    "w_gend_age_euro",
    # sample_weights.
    # Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "gratitude",
    ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of peopl
    "modesty",
    # see above
    "vengeful_rumin",
    "charity_donate",
    #How much money have you donated to charity in the last year?
    "hours_charity",
    #,#Hours spent in activities/Hours spent … voluntary/charitable work
    "warm_asians",
    "warm_chinese",
    #"warm_disabled" ,  missing at time 0
    # begins w9
    "warm_immigrants",
    "warm_indians",
    "warm_elderly",
    # warm_lgbtq starts w12
    "warm_maori",
    "warm_mental_illness",
    "warm_muslims",
    "warm_nz_euro",
    "warm_overweight",
    "warm_pacific",
    "warm_refugees",
    "religion_perceive_religious_discrim",
    # "issue_same_sex_marriage", not in range
     "support", # three items as below
    # "support_help",
    # # 'There are people I can depend on to help me if I really need it.
    # "support_turnto",
    # # There is no one I can turn to for guidance in times of stress.
    # "support_rnoguidance",
    #There is no one I can turn to for guidance in times of stress.
    "family_time",
    "friends_time",
    "community_time",
    "family_money",
    "friends_money",
    "community_money",
     #Please estimate how much help you have received from the following sources in the last week?
    # Received help and support - hours
    # family
    # friends
    # others in my community
    # Received help and support - money
    # family
    # friends
    # others in my community
    # outcomewide, 
     "religion_religious",
    # Do you identify with a religion and/or spiritual group?
    "religion_identification_level",
    #How important is your religion to how you see yourself?"
    "religion_church_binary",
    "religion_church_binary2",
    "religion_prayer",
    # How many times did you pray in the last week?
    "religion_scripture",
    # How many times did you read religious scripture in the last week?
    "religion_church2",
    # How many times did you attend a church or place of worship in the last month?
    "religion_believe_spirit",
    #Do you believe in some form of spirit or lifeforce?
    "religion_believe_god",
    #Do you believe in a God
    "religion_spiritual_identification",
    #w8,w10,w12-13 "I identify as a spiritual person."
    "religion_perceive_religious_discrim",
    #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
    # "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers
    # sample_weights
    "alcohol_frequency",
    #"How often do you have a drink containing alcohol?"
    "alcohol_intensity",
    # How many drinks containing alcohol do you have on a typical day when drinking?
    "hlth_bmi",
    # " What is your height? (metres)\nWhat is your weight? (kg)\nKg
    "hours_exercise",
    # Hours spent … exercising/physical activity
    # "sfhealth",
    "sfhealth_your_health",
    # "In general, would you say your health is...
    "sfhealth_get_sick_easier",
    #\nI seem to get sick a little easier than other people.
    "sfhealth_expect_worse_health",
    #\nI expect my health to get worse." ****
    "hlth_sleep_hours",
    #During the past month, on average, how many hours of actual sleep did you get per night?
    "smoker",
    #Do you currently smoke?
    "hlth_fatigue",
    #During the last 30 days, how often did.... you feel exhausted?
    "rumination",
    # During the last 30 days, how often did.... you have negative thoughts that repeated over and over?
    "kessler_depressed",
    #During the last 30 days, how often did.... you feel so depressed that nothing could cheer you up?
    "kessler_effort",
    #During the last 30 days, how often did.... you feel that everything was an effort?
    "kessler_hopeless",
    # During the last 30 days, how often did.... you feel hopeless?
    "kessler_nervous",
    #During the last 30 days, how often did.... you feel nervous?
    "kessler_restless",
    #During the last 30 days, how often did.... you feel restless or fidgety?
    "kessler_worthless",
    # During the last 30 days, how often did.... you feel worthless?
    "sexual_satisfaction",
    #  How satisfied are you with your sex life?
    "bodysat",
    ## Am satisfied with the appearance, size and shape of my body.
    "vengeful_rumin",
    # Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "perfectionism",
    # # Doing my best never seems to be enough./# My performance rarely measures up to my standards.
    # I am hardly ever satisfied with my performance.
    "power_self_nocontrol",
    # I do not have enough power or control over\nimportant parts of my life.
    "power_others_control",
    # Other people have too much power or control over\nimportant parts of my life
    "self_esteem",
    "selfesteem_satself",
    #  On the whole am satisfied with myself.
    "selfesteem_postiveself",
    # Take a positive attitude toward myself
    "selfesteem_rfailure",
    # Am inclined to feel that I am a failure.
  #  "self_control",
    "self_control_have_lots",
    #In general, I have a lot of self-control.
    "self_control_wish_more_r",
    #I wish I had more self-discipline.(r)
    "emotion_regulation_out_control",
    # When I feel negative emotions, my emotions feel out of control. w10 - w13
    "emotion_regulation_hide_neg_emotions",
    # When I feel negative emotions, I suppress or hide my emotions. w10 - w13
    "emotion_regulation_change_thinking_to_calm",
    # When I feel negative emotions, I change the way I think to help me stay calm. w10 - w13
    # "emp_work_life_balance",# I have a good balance between work and other important things in my life. # not measured at baseline
   # "respect_self",  #If they knew me, most NZers would respect what I have accomplished in life. Missing at T12
    "gratitude",
    ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of people.
    "pwi_health",
    #Your health.
    "pwi_relationships",
    #Your personal relationships.
    "pwi_security",
    #Your future security.
    "pwi_standardliving",
    #Your standard of living.
    "lifesat",
    "lifesat_satlife",
    # I am satisfied with my life.
    "lifesat_ideal",
    # In most ways my life is close to ideal.
    "meaning_purpose",
    # My life has a clear sense of purpose.
    "meaning_sense",
    # I have a good sense of what makes my life meaningful.
    "permeability_individual",
    #I believe I am capable, as an individual\nof improving my status in society.
    "impermeability_group",
    #The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change.
    "neighbourhood_community",
    #I feel a sense of community with others in my local neighbourhood.
    "support",
    "support_help",
    # 'There are people I can depend on to help me if I really need it.
    "support_turnto",
    # There is no one I can turn to for guidance in times of stress.
    "support_rnoguidance",
    #There is no one I can turn to for guidance in times of stress.
    "belong",
    "belong_accept",
    #Know that people in my life accept and value me.
    "belong_routsider",
    # Feel like an outsider.
    "belong_beliefs",
    # Know that people around me share my attitudes and beliefs.
    "charity_donate",
    #How much money have you donated to charity in the last year?
    "hours_charity",#,#Hours spent in activities/Hours spent … voluntary/charitable work
    # "nwi", # The economic situation in New Zealand./# The social conditions in New Zealand. # Business in New Zealand.
    "emp_job_sat", # How satisfied are you with your current job? #Eisenbarth, H., Hart, C. M., Zubielevitch, E., Keilor, T., Wilson, M. S., Bulbulia, J. A., Sibley, C. G., & Sedikides, C. (in press). Aspects of psychopathic personality relate to lower subjective and objective professional success. Personality and Individual Differences, 186, 111340.
    "emp_job_secure",  #only for employed people
    "emp_job_valued"
  )|> 
  dplyr::rename(sample_weights = w_gend_age_euro) |>
  dplyr::mutate(meets_criteria_baseline = ifelse(year_measured == 1, 1, 0) )|> 
  dplyr::mutate(sample_origin = sample_origin_names_combined) |>  #shorter name
  arrange(id) |>
  filter((wave == 2018 & year_measured == 1) |
           (wave == 2019 & year_measured == 1) |
           (wave == 2020)) %>%
  group_by(id) |> 
  mutate(k_18 = ifelse(wave == 2018 & ! is.na(religion_religious) &  meets_criteria_baseline == 1, 1, 0)) %>% # selection criteria
  mutate(h_18 = mean(k_18, na.rm = TRUE)) %>%
  mutate(k_19 = ifelse(wave == 2019 & !is.na(religion_religious), 1,0)) %>% # selection criteria
  mutate(h_19 = mean(k_19, na.rm = TRUE)) %>%
  dplyr::filter(h_18 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_19 > 0) |>  # hack to enable repeat of baseline
  ungroup() %>%
  mutate(# for outcomewide cooperation studies
    friends_money = ifelse(friends_money < 0, 0, friends_money),
    household_inc_log = log(household_inc + 1),
    hours_children_log = log(hours_children + 1),
    hours_work_log = log(hours_work + 1),
    hours_housework_log = log(hours_housework + 1)
  ) |> 
  ungroup() |> 
  droplevels() |> 
  select(-c("h_19", "k_19", "h_18", "k_18", "meets_criteria_baseline")) %>%
  as.data.frame()

# check unique n
n_unique(dat_long$id) # 34742 # sample size

# checks
table(dat_long$wave, dat_long$religion_religious)


# examples of bad correlations
#summary(lm(meaning_purpose ~ religion_religious, data = dat_19))
#summary(lm(meaning_sense ~ religion_religious, data = dat_19))

# Other people have too much power or control over\nimportant parts of my life
```

```{r}
#| label: prepare-data
# prepare on basis of positivity chack
dat_long_t  <- dat_long %>%
  # mutate(
  #   hours_work_coarsen = cut(
  #     hours_work,
  #     breaks = c( 10, 30, 41, Inf),
  #     labels = c("[10_30)", "[30_41)", "[41_up]"),
  #     include.lowest = TRUE,
  #     right = FALSE,
  #     ordered = TRUE
  #   )
  # )  |> 
  droplevels() |> 
  arrange(id, wave) |> 
  data.frame()

# check n again
n_unique(dat_long_t$id)

# double check path
push_mods

# only look at vars at baseline
dat_18 <- dat_long_t |> 
  dplyr::filter(wave == 2018)

# save data for table
saveRDS(dat_18, here::here(push_mods, "dat_18"))


# better for imputation - make factors numeric. the mice package likes this
# rename to work with workflow
dat_long_t <- dat_long_t |>
  mutate(
    religion_religious =  as.factor(religion_religious),
    # needed for imputation
    eth_cat = as.integer(eth_cat),
    urban = as.numeric(urban),
    education_level_coarsen = as.integer(education_level_coarsen)
  )

# save
saveRDS(dat_long_t, here::here(push_mods, "dat_long_t"))

str(dat_long_t$religion_religious)
n_unique(dat_long$id)
# read if needed
#dat_long_t <- readRDS(here::here(push_mods, "dat_long_t"))
```

```{r}
#|label: data-wrangling-for-imputatons

# Create wide data frame
# baseline_vars = c(
#     "male",
#     "age",
#     "education_level_coarsen", # factors
#     "eth_cat", #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
#     "employed", # Are you currently employed? (this includes self-employment or casual work) not needed
#     #"gen_cohort", #age
#     "nz_dep2018",
#     "nzsei13",
#     "total_siblings",# added: needed because we are dealing with family giving/receiving
#     "born_nz",  # added
#     "hlth_disability",  # added
#     "partner",
#     "parent",  # newly changed - have information in child number
#     "pol_orient", #Please rate how politically liberal versus conservative you see yourself as being.
#     "pol_wing", # Please rate how politically left-wing versus right-wing you see yourself as being.
#     "sample_origin",    # Sample origin names combined
#     "urban",
#    # "emp_job_sat",
#     # "children_num",
#    # "household_inc_log", # measured with error
#   #  "hours_children_log", #
#   #  "hours_work_log", #
#   #  "hours_housework_log",
#     "agreeableness",
#     "conscientiousness",
#     "extraversion",
#     "honesty_humility",
#     "openness",
#     "neuroticism",
#     "modesty",
#     "sample_weights"
# )
baseline_vars = c(
    "male",
    "age",
    "education_level_coarsen", # factors
    "eth_cat", #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
   # "employed", # Are you currently employed? (this includes self-employment or casual work) # we have work hours
    #"gen_cohort", #age
    "nz_dep2018",
    "nzsei13",
    "total_siblings",# added: needed because we are dealing with family giving/receiving
    "born_nz",  # added 
    "hlth_disability",  # added 
    "household_inc_log", # added: measured with error but OK for imputations
    "partner",
   # "parent",  # newly changed - have information in child number
    "pol_orient", #Please rate how politically liberal versus conservative you see yourself as being.
    "pol_wing", # Please rate how politically left-wing versus right-wing you see yourself as being.
    "sample_origin",    # Sample origin names combined
    "urban",
    "children_num",
    "household_inc_log", # new from previous study. needed because we are dealing with family giving/receiving
    "hours_children_log", # new
    "hours_work_log", # new
    "hours_housework_log", #new
    "agreeableness", 
    "conscientiousness",
    "extraversion",
    "honesty_humility",
    "openness",
    "neuroticism",
    "modesty", # I want people to know that I am an important person of high status, I am an ordinary person who is no better than others. , I wouldn’t want people to treat me as though I were superior to them. I think that I am entitled to more respect than the average person is.
  #  "religion_religious", # Do you identify with a religion and/or spiritual group?
    #"religion_identification_level", #How important is your religion to how you see yourself?"  # note this is not a great measure of virtue, virtue is a mean between extremes.
    "sample_weights" # will make binary after imputation
)





# check
baseline_vars

# set exposure variable, can be both the continuous and the coarsened, if needed
exposure_var = c("religion_religious") # we could construct this after imputation. # "perfectionism_high" to be replace by "perfectionism_coarsen" - do the data wrangling after imputation.


# outcome_vars_health = c(
#     "alcohol_frequency",
#     "alcohol_intensity",
#     "hlth_bmi",
#     "hours_exercise",
#     "sfhealth_your_health",# "In general, would you say your health is...
#     "sfhealth_get_sick_easier",#\nI seem to get sick a little easier than other people.
#     "sfhealth_expect_worse_health",
#     "hlth_sleep_hours",
#     "smoker"
#   )




outcome_vars_health = c(
    "alcohol_frequency",
    "alcohol_intensity",
    "hlth_bmi",
    "hours_exercise",
    "sfhealth_your_health",# "In general, would you say your health is...
    "sfhealth_get_sick_easier",#\nI seem to get sick a little easier than other people.
    "sfhealth_expect_worse_health",
    "hlth_sleep_hours",
    "smoker"
  )


outcome_vars_embodied = c(
    "hlth_fatigue",
    "rumination",
    "kessler_depressed",
    "kessler_effort",
    "kessler_hopeless",
    "kessler_nervous",
    "kessler_restless",
    "kessler_worthless"
  )

outcome_vars_practical = c(
 #   "nzsei13", # objective job success
    "bodysat", ## Am satisfied with the appearance, size and shape of my body.
    "vengeful_rumin",# Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "perfectionism",  # # Doing my best never seems to be enough./# My performance rarely measures up to my standards.
# I am hardly ever satisfied with my performance.
    "power_self_nocontrol",# I do not have enough power or control over\nimportant parts of my life.
    "power_others_control", # Other people have too much power or control over\nimportant parts of my life
    "selfesteem_satself", #  On the whole am satisfied with myself.
    "selfesteem_postiveself",# Take a positive attitude toward myself
    "selfesteem_rfailure", # Am inclined to feel that I am a failure.
    "sexual_satisfaction",
    "self_control_have_lots",#In general, I have a lot of self-control.
    "self_control_wish_more_r",#I wish I had more self-discipline.(r)
    "emotion_regulation_out_control", # When I feel negative emotions, my emotions feel out of control. w10 - w13
    "emotion_regulation_hide_neg_emotions", # When I feel negative emotions, I suppress or hide my emotions. w10 - w13
    "emotion_regulation_change_thinking_to_calm"#,#, # When I feel negative emotions, I change the way I think to help me stay calm. w10 - w13
   # "emp_work_life_balance"# I have a good balance between work and other important things in my life.
    #"respect_self"
  )
  
outcome_vars_reflective = c(
    "gratitude", ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of people.
    "pwi_health",#Your health.
    "pwi_relationships",#Your personal relationships.
    "pwi_security",#Your future security.
    "pwi_standardliving",#Your standard of living.
    "lifesat_satlife",# I am satisfied with my life.
    "lifesat_ideal",# In most ways my life is close to ideal.
    "meaning_purpose",# My life has a clear sense of purpose.
    "meaning_sense"# I have a good sense of what makes my life meaningful.
  )


outcome_vars_social = c(
    "permeability_individual",#I believe I am capable, as an individual\nof improving my status in society.
    "impermeability_group", #The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change.
    "neighbourhood_community", #I feel a sense of community with others in my local neighbourhood.
    "support_help",# 'There are people I can depend on to help me if I really need it.
    "support_turnto",# There is no one I can turn to for guidance in times of stress.
    "support_rnoguidance", #There is no one I can turn to for guidance in times of stress.
    "belong_accept", #Know that people in my life accept and value me.
    "belong_routsider",# Feel like an outsider.
    "belong_beliefs"#,# Know that people around me share my attitudes and beliefs.
   # "charity_donate",#How much money have you donated to charity in the last year?
   # "hours_charity"#,#Hours spent in activities/Hours spent … voluntary/charitable work
  #  "nwi" # The economic situation in New Zealand./# The social conditions in New Zealand. # Business in New Zealand.
  )

# health vars
prep_health <- margot_wide(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_health)

# checks
str(prep_health)
nrow(prep_health)

# emobodied vars
prep_embodied <- margot_wide(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_embodied)

str(prep_embodied)
nrow(prep_embodied)

prep_practical <- margot_wide(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_practical)

str(prep_practical)

prep_reflective <- margot_wide(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_reflective)

str(prep_reflective)

prep_social <- margot_wide(dat_long_t, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_social)

str(prep_social)

# check exposure variable
exposure_var

# assign name
exposure_vars = "t1_religion_religious"

#check
exposure_vars

# save for late use
saveRDS(exposure_vars, here::here(push_mods,"exposure_vars"))

# create dataframes, one for each level of the factor.  This allows valid multiple imputation see: 
# https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-023-01843-6

prep_health_multiple <- margot_filter(prep_health, exposure_vars = exposure_vars) 
prep_embodied_multiple <- margot_filter(prep_embodied, exposure_vars = exposure_vars) 
prep_practical_multiple <- margot_filter(prep_practical, exposure_vars = exposure_vars) 
prep_reflective_multiple <- margot_filter(prep_reflective, exposure_vars = exposure_vars) 
prep_social_multiple <- margot_filter(prep_social, exposure_vars = exposure_vars) 

# get levels for checks 
levels(prep_health$t1_religion_religious)

# checks
c <- nrow( prep_social_multiple$`0`)
d <-nrow( prep_social_multiple$`1`)

prep_social
# check
 c + d == nrow(prep_social)
 
# save for baseline table
saveRDS(prep_reflective, here::here(push_mods, "prep_reflective"))
```

```{r}
#| label: save-positivity-data
#| eval: false

# make data for positivity
dt_positivity_full <- dat_long|>
  filter(wave == 2018 | wave == 2019)

saveRDS(dt_positivity_full, here::here(push_mods,"dt_positivity_full"))
```


```{r}
#| label: imputations-health
#| echo: false
#| include: false
#| eval: false
# check missing

dev.off()
# visually inspect missingness
naniar::vis_miss(prep_health, warn_large_data = FALSE)

# check for collinear vars
mice:::find.collinear(prep_health)


colnames(prep_health)
# impute  
mice_health <- impute_and_combine(prep_health_multiple,  m = 10 )

# check path
push_mods

# save imputed data
saveRDS(mice_health,
        here::here(push_mods, "mice_health"))

# spit-shine
mice_health_c <- mice::complete(mice_health, action = 'long', include = TRUE)

# remove bad cols: spit-shine
mice_health_c <- mice_health_c |> select(-c(.id.1, .imp.1))

# more spit-shine
row.names(mice_health_c) <- NULL

# post-impute arrange
mice_health_mids <- mice_health_c %>%
    arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
         t0_education_level_coarsen = as.factor(t0_education_level_coarsen),
         t0_smoker = as.factor(t0_smoker),
         t2_smoker = as.factor(t2_smoker),
         t0_hours_exercise_log = log(t0_hours_exercise + 1),
         t2_hours_exercise_log =  log(t2_hours_exercise +1)) |>
  dplyr::group_by(.imp, id) |>
 # rowwise() |> # group by id within .imp 
  # dplyr::mutate(t0_sfhealth = mean(
  #   c(
  #     t0_sfhealth_your_health,
  #     t0_sfhealth_get_sick_easier,
  #     t0_sfhealth_expect_worse_health  ),
  #   na.rm = TRUE
  # # )) |>
  #   dplyr::mutate(t2_sfhealth = mean(
  #   c(
  #     t2_sfhealth_your_health,
  #     t2_sfhealth_get_sick_easier,
  #     t2_sfhealth_expect_worse_health  ),
  #   na.rm = TRUE
  # )) |>
  dplyr::ungroup() |>
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-.imp_z,-.id_z, -t0_hours_exercise, -t2_hours_exercise) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
 # relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate(t0_smoker = as.integer(t0_smoker)-1,
         t2_smoker = as.integer(t2_smoker)-1) |> 
  arrange(.imp, id) |> 
  droplevels() |> 
  mutate_if(is.matrix, as.vector) |> 
  as.mids()

# save long versoin 
mice_health_long <- mice::complete(mice_health_mids, "long", inc = TRUE)

# check
skim(mice_health_long)
# save
saveRDS(mice_health_mids, here::here(push_mods, "mice_health_mids"))
saveRDS(mice_health_long, here::here(push_mods, "mice_health_long"))
```

```{r}
#| label: imputations-embodied
#| echo: false
#| include: false
#| eval: false
# embodied
naniar::vis_miss(prep_embodied, warn_large_data = FALSE)
#dev.off()

# check for collinear vars
mice:::find.collinear(prep_embodied)

# impute
mice_embodied <- impute_and_combine(prep_embodied_multiple,  m=10)

# save imputed data
saveRDS(mice_embodied,
        here::here(push_mods, "mice_embodied"))

# read of necessary
#mice_embodied <- readRDS(
#       here::here(push_mods, "mice_embodied"))

# spit-shine
mice_embodied_c  <- mice::complete(mice_embodied, action = 'long', include = TRUE)

# spit-shine
mice_embodied_c <- mice_embodied_c |> select(-c(.id.1, .imp.1))

# spit-shine
row.names(mice_embodied_c) <- NULL

# post-imputation wrangle
mice_embodied_mids <- mice_embodied_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate( 
         t0_eth_cat = as.factor(t0_eth_cat),
         t0_education_level_coarsen = as.factor(t0_education_level_coarsen)) |> 
  dplyr::group_by(.imp) |> # means within imputations 
  rowwise() |> 
  # dplyr::mutate(t0_kessler_6 = mean(
  #   c(
  #   t0_kessler_depressed,
  #   t0_kessler_effort,
  #   t0_kessler_hopeless,
  #   t0_kessler_nervous,
  #   t0_kessler_restless,
  #   t0_kessler_worthless ),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t2_kessler_6 = mean(
  #   c(
  #   t2_kessler_depressed,
  #   t2_kessler_effort,
  #   t2_kessler_hopeless,
  #   t2_kessler_nervous,
  #   t2_kessler_restless,
  #   t2_kessler_worthless ),
  #   na.rm = TRUE
  # )) |> 
  #   dplyr::mutate(t2_kessler_6_depression = mean(
  #   c(
  #   t2_kessler_depressed,
  #   t2_kessler_hopeless,
  #   t2_kessler_worthless ),
  #   na.rm = TRUE
  #   )) |>
  # dplyr::mutate(t2_kessler_6_anxiety = mean(
  #   c(t2_kessler_effort,
  #     t2_kessler_nervous,
  #     t2_kessler_restless ),
  #   na.rm = TRUE
  # )) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()

# make long version  
mice_embodied_long <- mice::complete(mice_embodied_mids, "long", inc = TRUE)

# save
saveRDS(mice_embodied_mids, here::here(push_mods, "mice_embodied_mids"))
saveRDS(mice_embodied_long, here::here(push_mods, "mice_embodied_long"))

```

```{r}
#| label: imputations-practical
#| echo: false
#| include: false
#| eval: false
# practical
naniar::vis_miss(prep_practical, warn_large_data = FALSE)

# check for collinear vars
mice:::find.collinear(prep_practical)

colnames(prep_practical)
# prep factors remove for speed

# impute
mice_practical <- impute_and_combine(prep_practical_multiple,  m=10)

# save imputed data
saveRDS(mice_practical,
        here::here(push_mods, "mice_practical"))

# read if needed
#mice_practical <- readRDS(here::here(push_mods, "mice_practical"))

# for wrangling
mice_practical  <- mice::complete(mice_practical, action = 'long', include = TRUE)

# spit and shine
mice_practical <- mice_practical |> select(-c(.id.1, .imp.1))

# more spit and shine
row.names(mice_practical) <- NULL

# post-imutation wrangling 
mice_practical_mids <- mice_practical %>%
  arrange(.imp, id) |>
  rename(sample_weights = t0_sample_weights) |>
  mutate(
    t0_eth_cat = as.factor(t0_eth_cat),
    t0_education_level_coarsen = as.factor(t0_education_level_coarsen)
  ) |>
  dplyr::group_by(.imp) |>
  rowwise() |>
  # dplyr::mutate(t0_powerdependence = mean(
  #   c(
  #   t0_power_self_nocontrol,
  #   t0_power_others_control),
  #   na.rm = TRUE
#  )) |>
  # dplyr::mutate(t0_selfesteem = mean(
  #   c(
  #     t0_selfesteem_satself,
  #     t0_selfesteem_postiveself,
  #     t0_selfesteem_rfailure
  #   ),
  #   na.rm = TRUE
  # )) |>
  # dplyr::select(-c(
  #   t0_selfesteem_satself,
  #   t0_selfesteem_postiveself,
  #   t0_selfesteem_rfailure
  # )) |>
  # dplyr::mutate(t0_self_control = mean(
  #   c(t0_self_control_have_lots,
  #     t0_self_control_wish_more_r),
  #   na.rm = TRUE
  # )) |>
  # dplyr::select(-c(t0_self_control_have_lots,
  #                  t0_self_control_wish_more_r)) |>
  # dplyr::mutate(t0_emotion_regulation = mean(
  #   c(
  #     t0_emotion_regulation_out_control,
  #     t0_emotion_regulation_hide_neg_emotions,
  #     t0_emotion_regulation_change_thinking_to_calm
  #   ),
  #   na.rm = TRUE
  # )) |>
  # dplyr::select(-c(
  #     t0_emotion_regulation_out_control,
  #     t0_emotion_regulation_hide_neg_emotions,
  #     t0_emotion_regulation_change_thinking_to_calm
  #   )
  # ) |>
  #   dplyr::mutate(t2_powerdependence = mean(
  #   c(
  #   t2_power_self_nocontrol,
  #   t2_power_others_control),
  #   na.rm = TRUE
  # )) |>
  # dplyr::mutate(t2_selfesteem = mean(
  #   c(
  #     t2_selfesteem_satself,
  #     t2_selfesteem_postiveself,
  #     t2_selfesteem_rfailure
  #   ),
  #   na.rm = TRUE
  # )) |>
  # dplyr::mutate(t2_self_control = mean(
  #   c(t2_self_control_have_lots,
  #     t2_self_control_wish_more_r),
  #   na.rm = TRUE
  # )) |>
  # dplyr::mutate(t2_emotion_regulation = mean(
  #   c(
  #     t2_emotion_regulation_out_control,
  #     t2_emotion_regulation_hide_neg_emotions,
  #     t2_emotion_regulation_change_thinking_to_calm
  #   ),
  #   na.rm = TRUE
  # )) |>
  dplyr::ungroup() |>
  dplyr::mutate(across(where(is.numeric) &
                         !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
  select(where(is.factor),
         sample_weights,
         ends_with("_z"),
         .imp,
         .id) |>
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  |>
  droplevels() |>
  mutate_if(is.matrix, as.vector) %>%
  as.mids()

# make long verson 
mice_practical_long <- mice::complete(mice_practical_mids, "long", inc = TRUE)

# save
saveRDS(mice_practical_mids, here::here(push_mods, "mice_practical_mids"))
saveRDS(mice_practical_long, here::here(push_mods, "mice_practical_long"))
```

```{r}
#| label: imputations-reflective
#| echo: false
#| include: false
#| eval: false

# reflective
naniar::vis_miss(prep_reflective, warn_large_data = FALSE)

# check 
mice:::find.collinear(prep_reflective)

# impute
mice_reflective <- impute_and_combine(prep_reflective_multiple, m = 10)

# save imputed data
saveRDS(mice_reflective,
        here::here(push_mods, "mice_reflective"))

# read if needed
# mice_reflective <- readRDS(here::here(push_mods, "mice_reflective"))

# work with data
mice_reflective_c  <- mice::complete(mice_reflective, action = 'long', include = TRUE)

# spit and shine
mice_reflective_c <- mice_reflective_c |> select(-c(.id.1, .imp.1))

# more spit and shine
row.names(mice_reflective_c) <- NULL

# post imputation wrangle
mice_reflective_mids <- mice_reflective_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate( t0_eth_cat = as.factor(t0_eth_cat),
         t0_education_level_coarsen = as.factor(t0_education_level_coarsen)) |> 
  dplyr::group_by(.imp) |>
  rowwise() |> 
  # dplyr::mutate(t0_pwi = mean(
  #   c(
  #   t0_pwi_health,
  #   t0_pwi_relationships,
  #   t0_pwi_security,
  #   t0_pwi_standardliving),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t0_lifesat = mean(
  #   c(
  #   t0_lifesat_satlife,
  #   t0_lifesat_ideal),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t0_meaning = mean(
  #   c(
  #   t0_meaning_purpose,
  #   t0_meaning_sense),
  #   na.rm = TRUE
  # )) |> 
  #   dplyr::mutate(t2_pwi = mean(
  #   c(
  #   t2_pwi_health,
  #   t2_pwi_relationships,
  #   t2_pwi_security,
  #   t2_pwi_standardliving),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t2_lifesat = mean(
  #   c(
  #   t2_lifesat_satlife,
  #   t2_lifesat_ideal),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t2_meaning = mean(
  #   c(
  #   t2_meaning_purpose,
  #   t2_meaning_sense),
  #   na.rm = TRUE
  # )) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
    
   ) |>
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  droplevels() |>
  as.mids()
  
# long version 
mice_reflective_long <- mice::complete(mice_reflective_mids, "long", inc = TRUE)

# save
saveRDS(mice_reflective_mids, here::here(push_mods, "mice_reflective_mids"))
saveRDS(mice_reflective_long, here::here(push_mods, "mice_reflective_long"))
```

```{r}
#| label: imputations-social
#| echo: false
#| include: false
#| eval: false

# check missing
naniar::vis_miss(prep_social, warn_large_data = FALSE)

# check for collinear vars
mice:::find.collinear(prep_social)

# impute
mice_social <- impute_and_combine(prep_social_multiple, m = 10)

# save imputed data
saveRDS(mice_social,
        here::here(push_mods, "mice_social"))

# read if needed
#mice_social <- readRDS(here::here(push_mods, "mice_social"))

# to manipulate data
mice_social_c  <- mice::complete(mice_social, action = 'long', include = TRUE)

# spit and shine
mice_social_c <- mice_social_c |> select(-c(.id.1, .imp.1))

# more spit and shine
row.names(mice_social_c) <- NULL

# post-imputation wrangling
mice_social_mids <- mice_social_c %>%
  arrange(.imp, id) |> 
  rename(sample_weights = t0_sample_weights) |> 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
         t0_education_level_coarsen = as.factor(t0_education_level_coarsen)) |> 
       #  t0_charity_donate_log = log(t0_charity_donate + 1),
       #  t2_charity_donate_log = log(t2_charity_donate + 1),
      #   t0_volunteers = as.factor(ifelse(t0_hours_charity > 1,1,0)),
        # t2_volunteers = as.factor(ifelse(t2_hours_charity > 1,1,0)))|>
  dplyr::group_by(.imp) |>
  rowwise() |> 
  # dplyr::mutate(t0_support = mean(
  #   c(
  #   t0_support_help,
  #   t0_support_turnto,
  #   t0_support_rnoguidance),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t0_belong = mean(
  #   c(
  #   t0_belong_accept,
  #   t0_belong_routsider,
  #   t0_belong_beliefs),
  #   na.rm = TRUE
  # )) |> 
  #  dplyr::mutate(t2_support = mean(
  #   c(
  #   t2_support_help,
  #   t2_support_turnto,
  #   t2_support_rnoguidance),
  #   na.rm = TRUE
  # )) |>
  #   dplyr::mutate(t2_belong = mean(
  #   c(
  #   t2_belong_accept,
  #   t2_belong_routsider,
  #   t2_belong_beliefs),
  #   na.rm = TRUE
  # )) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-.imp_z, -.id_z) |> 
         # -t0_charity_donate, 
         # t0_charity_donate) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(id, .before = sample_weights)  %>%
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
 #  mutate(t0_volunteers = as.integer(t0_volunteers) - 1,
 #        t2_volunteers = as.integer(t2_volunteers) - 1) |>
  mutate_if(is.matrix, as.vector) %>%
  droplevels() |> 
  as.mids()
  
# make long verson
mice_social_long <- mice::complete(mice_social_mids, "long", inc = TRUE)

colnames(mice_social_long)
# save
saveRDS(mice_social_mids, here::here(push_mods, "mice_social_mids"))
saveRDS(mice_social_long, here::here(push_mods, "mice_social_long"))
```
```{r}
#| label: models-health
#| eval: false
#| include: false
#| echo: false

#check path
push_mods

# fetch expposure fvar name
exposure_vars <- readRDS(here::here(push_mods,exposure_vars))

# import data
mice_health_mids <- readRDS(here::here(push_mods, "mice_health_mids"))

# long data 
mice_health_long <- readRDS(here::here(push_mods, "mice_health_long"))

table(mice_health_long$t1_religion_religious)
# check exposure name and set
exposure_vars

# set exposure 
X <- exposure_vars
str(X)

# set estimand
estimand = "ATE"

# matching
library(MatchThem)

# get baseline vars
baseline_vars_health = mice_health_long |> 
  dplyr::select(starts_with("t0"), -t0_religion_religious)|> colnames() # target trial, randomised baseline
baseline_vars_health


# set-data


# propensity score matching using ebalance -- generally very good
match_ebal_health <- match_mi_general(data = mice_health_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_health, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "ebal", 
                                 sample_weights = "sample_weights")

# save
saveRDS(match_ebal_health, here::here(push_mods, "match_ebal_health"))

# use energy balance, and only engergy balance if the exposure is continuous.
match_energy_health <- match_mi_general(data = mice_health_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_health, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights")

# save
here_save(match_energy_health, "match_energy_health")


# use energy balance, and only engergy balance if the exposure is continuous.
match_energy_health <- match_mi_general(data = mice_health_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_health, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights",
                                verbose = TRUE )

# save
# personal function loaded at start: equivalent saveRDS(match_ebal_health, here::here(push_mods, "match_ebal_health"))
here_save(match_energy_health, "match_energy_health")


# propensity scores by covariate balanced matching 
match_cbps_health <- match_mi_general(data = mice_health_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_health, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "cbps", 
                                 sample_weights = "sample_weights")

here_save(match_cbps_health, "match_cbps_health")

# checks results
# ebal method
bal.tab(match_ebal_health)
love.plot(match_ebal_health, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2) 

# consider results 
sum_ebal_health <- summary(match_ebal_health)
sum_ebal_health
plot(sum_ebal_health)

# energy method
#graph
bal.tab(match_energy_health)
love.plot(match_energy_health, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2)) 

# consider results 
sum_energy_health <- summary(match_energy_health)
sum_energy_health
plot(sum_ebal_health)


# cbps score method
#graph
bal.tab(match_energy_health)
summary(match_cbps_health)
plot(sum_cbps_health)

love.plot(match_cbps_health, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
love_plot_match_cbps_health

# consider results 
sum_cbps_health <- summary(match_cbps_health)
sum_cbps_health
plot(sum_cbps_health)



# For trimmed weights e.g.
# trim if needed (weights > 10 might be a problem)
# match_ebal_trim_health <- WeightIt::trim(match_ebal_health, at = .99)
#graph
# bal.tab(match_ebal_trim_health)
# summary(match_ebal_trim_health)
# plot(match_ebal_trim_health)
# 
# love_plot_match_ebal_trim_health <- love.plot(match_ebal_trim_health, binary = "std", thresholds = c(m = .1),
#           wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
# love_plot_match_ebal_trim_health
# 
# # consider results 
# sum_ebal_trim_health <- summary(match_ebal_trim_health)
# sum_ebal_trim_health
# plot(sum_ebal_trim_health)



# models
# set df
# do not need to trim data in this study
dt_health = match_ebal_health


# set treatment
treat_0 = "0" # secular
treat_1 = "1" # religious 
treat_0
# bootstrap simulations ( generally use 1000)
nsims <- 200

# cores
cl =  parallel::detectCores () 

estimand = "ATE"

# as specified
vcov = "HC2" # robust standard errors. 

# cores
cores = parallel::detectCores () # use all course

# checks
cores 
X

# model outcomes

#"How often do you have a drink containing alcohol?"
mod_health_alcohol_frequency  <- double_robust(
  df = dt_health,  # note change
  Y = "t2_alcohol_frequency_z",
  X = X,
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Alcohol frequency (sd)",
)

# read and save model
mod_health_alcohol_frequency
saveRDS(mod_health_alcohol_frequency, here::here(push_mods, "mod_health_alcohol_frequency"))

# How many drinks containing alcohol do you have on a typical day when drinking?
mod_health_alcohol_intensity  <- double_robust(
  df = dt_health,  # note change
  X = X,
  Y = "t2_alcohol_intensity_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Alcohol intensity (sd)"
)
# read and save model
mod_health_alcohol_intensity
saveRDS(mod_health_alcohol_intensity, here::here(push_mods, "mod_health_alcohol_intensity"))

# " What is your height? (metres)\nWhat is your weight? (kg)\nKg
mod_health_hlth_bmi  <- double_robust(
  df = dt_health,  # note change
  X = X,
  Y = "t2_hlth_bmi_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "BMI (sd)"
)

# read and save model
mod_health_hlth_bmi
saveRDS(mod_health_hlth_bmi, here::here(push_mods, "mod_health_hlth_bmi"))

# Hours spent … exercising/physical activity
mod_health_hours_exercise  <- double_robust(
  df = dt_health,  # note change
  X = X,
  Y = "t2_hours_exercise_log_z",
  baseline_vars =  baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Hours exercise (log sd)"
)
# read and save model
mod_health_hours_exercise
saveRDS(mod_health_hours_exercise, here::here(push_mods, "mod_health_hours_exercise"))

# "In general, would you say your health is...
mod_health_sfhealth_your_health  <- double_robust(
 df = dt_health,  # note change
  X = X,
  Y = "t2_sfhealth_your_health_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Your health (sd)"
)

# save model
mod_health_sfhealth_your_health
saveRDS(mod_health_sfhealth_your_health, here::here(push_mods, "mod_health_sfhealth_your_health"))

#"I seem to get sick a little easier than other people.
mod_health_sfhealth_get_sick_easier  <- double_robust(
  df = dt_health,  # note change
  X = X,# note change
  Y = "t2_sfhealth_get_sick_easier_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Get sick easier (reversed sd)"
)
# save model
mod_health_sfhealth_get_sick_easier
saveRDS(mod_health_sfhealth_get_sick_easier, here::here(push_mods, "mod_health_sfhealth_get_sick_easier"))

#I expect my health to get worse."
mod_health_sfhealth_expect_worse_health  <- double_robust(
  df = dt_health,  # note change
  X = X,
  Y = "t2_sfhealth_expect_worse_health_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Expect worse health (sd)"
)
# save model
mod_health_sfhealth_expect_worse_health
# save model
saveRDS(mod_health_sfhealth_expect_worse_health, here::here(push_mods, "mod_health_sfhealth_expect_worse_health"))

# if a single measure
# mod_health_sfhealth_comp  <- double_robust(
#   df = dt_health,  # note change
#   X = X,
#   Y = "t2_sfhealth_z",
#   baseline_vars = baseline_vars_health,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE,
#   vcov = vcov,
#   new_name = "sfhealth_z (composite)"
# )
# 
# mod_health_sfhealth_comp

# # save model
# saveRDS(mod_health_sfhealth_comp, here::here(push_mods, "mod_health_sfhealth_comp"))


#"During the past month, on average, how many hours of actual sleep did you get per night?"
mod_health_hlth_sleep_hours  <- double_robust(
  df = dt_health,  
  X = X,
  Y = "t2_hlth_sleep_hours_z",
  baseline_vars = baseline_vars_health,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  vcov = vcov,
  splines = FALSE, 
  new_name = "Sleep hours (sd)")

mod_health_hlth_sleep_hours
# save model
saveRDS(mod_health_hlth_sleep_hours, here::here(push_mods, "mod_health_hlth_sleep_hours"))

#"Do you currently smoke?"
mod_health_smoker_rr  <- double_robust(
  df = dt_health,  
  X = X,
  Y = "t2_smoker",
  baseline_vars = 1,# baseline_vars_health, # wont converge
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RR",
  nsims = nsims,
  cores = cores,
  family =  "poisson", 
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "Smoker y/n")


# use IPTW only
mod_health_smoker_rr
# save model
saveRDS(mod_health_smoker_rr, here::here(push_mods, "mod_health_smoker_rr"))
```

```{r}
#| label: models-embodied
#| fig-cap: "Causal effects of religious loss on embodied well-being"
#| eval: false
#| include: false
#| echo: false

# fetch expposure fvar name
exposure_vars <- readRDS(here::here(push_mods,"exposure_vars"))

#X <- exposure_vars
X
# import data
mice_embodied_mids <- readRDS(here::here(push_mods, "mice_embodied_mids"))

# long data for names
mice_embodied_long <- readRDS(here::here(push_mods, "mice_embodied_long"))

# get baseline names
baseline_vars_embodied = mice_embodied_long |>
  dplyr::select(starts_with("t0"), -t0_religion_religious) |> colnames()

# check
baseline_vars_embodied

estimand = "ATE"
# ebal propensity scores

# note these functions work the same
# match_ebal_embodied <- match_mi(data = mice_embodied_mids, 
#                                  X = X, 
#                                  baseline_vars = baseline_vars_embodied, 
#                                  estimand = estimand,  
#                                  method = "ebal", 
#                                  sample_weights = "sample_weights")
# 
# match_ebal_embodied <- match_mi_general(data = mice_embodied_mids, 
#                                  X = X, 
#                                  baseline_vars = baseline_vars_embodied, 
#                                  estimand = estimand,  
#                                  method = "ebal", 
#                                  sample_weights = "sample_weights")

# for use in the appendix
# save once
#saveRDS(match_ebal_embodied, here::here(push_mods, "match_ebal_embodied"))
#match_ebal_embodied <- readRDS( here::here(push_mods, "match_ebal_embodied"))

#  only use engergy balance if the exposure is continuous.
match_ebal_embodied <- match_mi_general(data = mice_embodied_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_embodied, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "ebal", 
                                 sample_weights = "sample_weights")

# save
here_save(match_ebal_embodied, "match_ebal_embodied")


# use energy balance, and only energy balance if the exposure is continuous.
match_energy_embodied <- match_mi_general(data = mice_embodied_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_embodied, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights",
                                verbose = TRUE )

# save
# personal function loaded at start: equivalent saveRDS(match_ebal_embodied, here::here(push_mods, "match_ebal_embodied"))
here_save(match_embodied_embodied, "match_energy_embodied")


# propensity scores by covariate balanced matching 
match_cbps_embodied <- match_mi_general(data = mice_embodied_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_embodied, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "cbps", 
                                 sample_weights = "sample_weights")

here_save(match_cbps_embodied, "match_cbps_embodied")

# checks results
# ebal method
bal.tab(match_ebal_embodied)
love.plot(match_ebal_embodied, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2) 

# consider results 
sum_ebal_embodied <- summary(match_ebal_embodied)
sum_ebal_embodied
plot(sum_ebal_embodied)

# energy method
#graph
bal.tab(match_energy_embodied)
love_plot_match_energy_embodied <- love.plot(match_energy_embodied, binary = "std", thresholds = c(m = .1),wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_energy_embodied <- summary(match_energy_embodied)
sum_energy_embodied
plot(sum_ebal_embodied)


# cbps score method
#graph
bal.tab(match_energy_embodied)
summary(match_cbps_embodied)
plot(sum_cbps_embodied)

love_plot_match_cbps_embodied <- love.plot(match_cbps_embodied, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
love_plot_match_cbps_embodied

# consider results 
sum_cbps_embodied <- summary(match_cbps_embodied)
sum_cbps_embodied
plot(sum_cbps_embodied)



# For trimmed weights e.g.
# trim if needed (weights > 10 might be a problem)
# match_ebal_trim_embodied <- WeightIt::trim(match_ebal_embodied, at = .99)
#graph
# bal.tab(match_ebal_trim_embodied)
# summary(match_ebal_trim_embodied)
# plot(match_ebal_trim_embodied)
# 
# love_plot_match_ebal_trim_embodied <- love.plot(match_ebal_trim_embodied, binary = "std", thresholds = c(m = .1),
#           wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
# love_plot_match_ebal_trim_embodied
# 
# # consider results 
# sum_ebal_trim_embodied <- summary(match_ebal_trim_embodied)
# sum_ebal_trim_embodied
# plot(sum_ebal_trim_embodied)

# settings 
dt_embodied = match_ebal_embodied

# check treatment
treat_0
treat_1

# bootstrap simulations ( generally use 1000)
#check
nsims

# cores check
cl
#cl =  parallel::detectCores () 
#cores = cl
#"During the last 30 days, how often did.... you feel exhausted?"
estimand
cores
X
#vcov = "HC2"
mod_embodied_hlth_fatigue  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_hlth_fatigue_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Fatigue (sd)"
)

# save model
mod_embodied_hlth_fatigue
saveRDS(mod_embodied_hlth_fatigue,
        here::here(push_mods, "mod_embodied_hlth_fatigue"))

# "During the last 30 days, how often did.... you have negative thoughts that repeated over and over?"
mod_embodied_rumination  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_rumination_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Rumination (sd)"
)

# save model
mod_embodied_rumination
saveRDS(mod_embodied_rumination,
        here::here(push_mods, "mod_embodied_rumination"))

#"During the last 30 days, how often did.... you feel so depressed that nothing could cheer you up?"
mod_embodied_kessler_depressed  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_depressed_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler depressed (sd)"
)
# save model
mod_embodied_kessler_depressed
saveRDS(
  mod_embodied_kessler_depressed,
  here::here(push_mods, "mod_embodied_kessler_depressed")
)

#"During the last 30 days, how often did.... you feel that everything was an effort?"
mod_embodied_kessler_effort  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_effort_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler effort (sd)"
)

# save model
mod_embodied_kessler_effort

saveRDS(
  mod_embodied_kessler_effort,
  here::here(push_mods, "mod_embodied_kessler_effort")
)


## kessler_hopeless
mod_embodied_kessler_hopeless  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_hopeless_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler hopeless (sd)"
)
# save model
mod_embodied_kessler_hopeless

saveRDS(
  mod_embodied_kessler_hopeless,
  here::here(push_mods, "mod_embodied_kessler_hopeless")
)


## kessler_nervous
mod_embodied_kessler_nervous  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_nervous_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler nervous (sd)"
)
# save model
mod_embodied_kessler_nervous

saveRDS(
  mod_embodied_kessler_nervous,
  here::here(push_mods, "mod_embodied_kessler_nervous")
)


## kessler_restless
mod_embodied_kessler_restless  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_restless_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler restless (sd)"
)
# save model
mod_embodied_kessler_restless

saveRDS(
  mod_embodied_kessler_restless,
  here::here(push_mods, "mod_embodied_kessler_restless")
)

## kessler_worthless
mod_embodied_kessler_worthless  <- double_robust(
  df = dt_embodied,
  # note change
  Y = "t2_kessler_worthless_z",
  X = X,
  baseline_vars = baseline_vars_embodied,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Kessler worthless (sd)"
)
# save model
mod_embodied_kessler_worthless
saveRDS(
  mod_embodied_kessler_worthless,
  here::here(push_mods, "mod_embodied_kessler_worthless")
)

# 
# ## t2_kessler_6
# mod_embodied_kessler_6  <- double_robust(
#   df = dt_embodied,  # note change
#   Y = "t2_kessler_6_z",
#   X = X,
#   baseline_vars = baseline_vars_embodied,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "kessler_6_z (composite)"
# )
# 
# mod_embodied_kessler_6
# # save model
# saveRDS(mod_embodied_kessler_6, here::here(push_mods, "mod_embodied_kessler_6"))
# 
#
# 
# mod_embodied_kessler_6_depression  <- double_robust(
#   df = dt_embodied,  # note change
#   Y = "t2_kessler_6_depression_z",
#   X = X,
#   baseline_vars = baseline_vars_embodied,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "kessler_6_depression_z (composite)"
# )
# 
# mod_embodied_kessler_6_depression

# 
# # save model
# saveRDS(mod_embodied_kessler_6_depression, here::here(push_mods, "mod_embodied_kessler_6_depression"))
# 
# 
# 
# mod_embodied_kessler_6_anxiety <- double_robust(
#   df = dt_embodied,  # note change
#   Y = "t2_kessler_6_anxiety_z",
#   X = X,
#   baseline_vars = baseline_vars_embodied,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "kessler_6_anxiety_z (composite)"
# )
# 
# mod_embodied_kessler_6_anxiety

# 
# # save model
# saveRDS(mod_embodied_kessler_6_anxiety, here::here(push_mods, "mod_embodied_kessler_6_anxiety"))


## combo-table
```
```{r}
#| label: models-practical
#| eval: false
#| include: false
#| echo: false

# fetch expposure fvar name
exposure_vars <- readRDS(here::here(push_mods,exposure_vars))


# read data
mice_practical_mids <- readRDS(here::here(push_mods, "mice_practical_mids"))

# for names
mice_practical_long <- readRDS(here::here(push_mods, "mice_practical_long"))

# get baseline vars
baseline_vars_practical = mice_practical_long |> 
  dplyr::select(starts_with("t0"), -t0_religion_religious_not)|> colnames() # strange to include these -- as they  are income by other names

# check baseline vars
baseline_vars_practical

# use energy balance, and only energy balance if the exposure is continuous.
match_ebal_practical <- match_mi_general(data = mice_practical_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_practical, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "ebal", 
                                 sample_weights = "sample_weights")

# save
here_save(match_ebal_practical, "match_ebal_practical")


# use energy balance, and only engergy balance if the exposure is continuous.
match_energy_practical <- match_mi_general(data = mice_practical_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_practical, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights",
                                verbose = TRUE )

# save
# personal function loaded at start: equivalent saveRDS(match_ebal_practical, here::here(push_mods, "match_ebal_practical"))
here_save(match_practical_practical, "match_energy_practical")


# propensity scores by covariate balanced matching 
match_cbps_practical <- match_mi_general(data = mice_practical_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_practical, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "cbps", 
                                 sample_weights = "sample_weights")

here_save(match_cbps_practical, "match_cbps_practical")

# checks results
# ebal method
bal.tab(match_ebal_practical)
love_plot_match_ebal_practical <- love.plot(match_ebal_practical, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_ebal_practical <- summary(match_ebal_practical)
sum_ebal_practical
plot(sum_ebal_practical)

# energy method
#graph
bal.tab(match_energy_practical)
love_plot_match_energy_practical <- love.plot(match_energy_practical, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_energy_practical <- summary(match_energy_practical)
sum_energy_practical
plot(sum_ebal_practical)


# cbps score method
#graph
bal.tab(match_energy_practical)
summary(match_cbps_practical)
plot(sum_cbps_practical)

love_plot_match_cbps_practical <- love.plot(match_cbps_practical, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
love_plot_match_cbps_practical

# consider results 
sum_cbps_practical <- summary(match_cbps_practical)
sum_cbps_practical
plot(sum_cbps_practical)



# For trimmed weights e.g.
# trim if needed (weights > 10 might be a problem)
# match_ebal_trim_practical <- WeightIt::trim(match_ebal_practical, at = .99)
#graph
# bal.tab(match_ebal_trim_practical)
# summary(match_ebal_trim_practical)
# plot(match_ebal_trim_practical)
# 
# love_plot_match_ebal_trim_practical <- love.plot(match_ebal_trim_practical, binary = "std", thresholds = c(m = .1),
#           wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
# love_plot_match_ebal_trim_practical
# 
# # consider results 
# sum_ebal_trim_practical <- summary(match_ebal_trim_practical)
# sum_ebal_trim_practical
# plot(sum_ebal_trim_practical)


# Set DF 
dt_practical = match_ebal_practical

# bootstrap simulations #check
nsims

# cores check
cl
cores
#cl =  parallel::detectCores () 

# check X
X
# check 
treat_0
# check 
treat_1 

# check
vcov


# models                                

# sex sat
mod_practical_sexual_satisfaction <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_sexual_satisfaction_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Sexual satisfaction (sd)"
 )

# view and save model
mod_practical_sexual_satisfaction
saveRDS(mod_practical_sexual_satisfaction, here::here(push_mods, "mod_practical_sexual_satisfaction"))

# perfectionism
mod_practical_perfectionism <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_perfectionism_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Perfectionism (sd)"
 )
# view and save model
mod_practical_perfectionism
saveRDS(mod_practical_perfectionism, here::here(push_mods, "mod_practical_perfectionism"))

# nzsei
mod_practical_nzsei13  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_nzsei13_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "NZSEI13 (sd)"
)

# view and save model
mod_practical_nzsei13
saveRDS(mod_practical_nzsei13, here::here(push_mods, "mod_practical_nzsei13"))

# body satisifaction 
mod_practical_bodysat  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_bodysat_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Body satisfaction (sd)"
)

# view and save
mod_practical_bodysat
saveRDS(mod_practical_bodysat, here::here(push_mods, "mod_practical_bodysat"))

# ven rumin
mod_practical_vengeful_rumin  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_vengeful_rumin_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Vengeful rumination (sd)"
)
# view and save
mod_practical_vengeful_rumin
saveRDS(mod_practical_vengeful_rumin, here::here(push_mods, "mod_practical_vengeful_rumin"))



mod_practical_power_self_nocontrol  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_power_self_nocontrol_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov=vcov,
  new_name = "Power self nocontrol (sd)"
)
# view and save model
mod_practical_power_self_nocontrol
saveRDS(mod_practical_power_self_nocontrol, here::here(push_mods, "mod_practical_power_self_nocontrol"))


# power other ovr me
mod_practical_power_others_control  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_power_others_control_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov=vcov,
  new_name = "Power others control (sd)"
)
# view and save model
mod_practical_power_others_control
saveRDS(mod_practical_power_others_control, here::here(push_mods, "mod_practical_power_others_control"))

# 
# # power dependence combo
# mod_practical_powerdependence  <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_power_dependence_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   vcov=vcov,
#   new_name = "power_others_control_z"
# )
# # view and save model
# mod_practical_powerdependence
# saveRDS(mod_practical_powerdependence, here::here(push_mods, "mod_practical_powerdependence"))


# On the whole am satisfied with myself.
mod_practical_selfesteem_satself  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_selfesteem_satself_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Selfesteem satself (sd)"
)

# view and save
mod_practical_selfesteem_satself
saveRDS(mod_practical_selfesteem_satself, here::here(push_mods, "mod_practical_selfesteem_satself"))


# self-esteem - positive self
mod_practical_selfesteem_postiveself  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_selfesteem_postiveself_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
   vcov=vcov,
  new_name = "Selfesteem postiveself (sd)"
)

# save model
mod_practical_selfesteem_postiveself
saveRDS(mod_practical_selfesteem_postiveself, here::here(push_mods, "mod_practical_selfesteem_postiveself"))


mod_practical_selfesteem_rfailure  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_selfesteem_rfailure_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
   vcov=vcov,
  new_name = "Selfesteem failure (reversed, sd)"
)

# view and save
mod_practical_selfesteem_rfailure
saveRDS(mod_practical_selfesteem_rfailure, here::here(push_mods, "mod_practical_selfesteem_rfailure"))

# combo
# mod_practical_selfesteem  <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_selfesteem_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "selfesteem_z"
# )
# 
# mod_practical_selfesteem

# save model
# saveRDS(mod_practical_selfesteem, here::here(push_mods, "mod_practical_selfesteem"))

# self control have lots
mod_practical_self_control_have_lots  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_self_control_have_lots_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Self control have lots (sd)"
)

# view and save
mod_practical_self_control_have_lots
saveRDS(mod_practical_self_control_have_lots, here::here(push_mods, "mod_practical_self_control_have_lots"))

# self control wish more
mod_practical_self_control_wish_more_r  <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_self_control_wish_more_r_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Self control wish more  (reversed, sd)"
)

mod_practical_self_control_wish_more_r

# view and save
saveRDS(mod_practical_self_control_wish_more_r, here::here(push_mods, "mod_practical_self_control_wish_more_r"))

# combo
# mod_practical_self_control <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_self_control_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "self_control_z"
# )
# 
# mod_practical_self_control

# save model
#saveRDS(mod_practical_self_control, here::here(push_mods, "mod_practical_self_control"))


# emo reg out control
mod_practical_emotion_regulation_out_control <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_emotion_regulation_out_control_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov,
  new_name = "Emotion reg out control (sd)"
)

# save model
mod_practical_emotion_regulation_out_control
saveRDS(mod_practical_emotion_regulation_out_control, here::here(push_mods, "mod_practical_emotion_regulation_out_control"))

mod_practical_emotion_regulation_hide_neg_emotions <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_emotion_regulation_hide_neg_emotions_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Emotion reg hide neg emotions (sd)"
)

# view and save model
mod_practical_emotion_regulation_hide_neg_emotions
saveRDS(mod_practical_emotion_regulation_hide_neg_emotions, here::here(push_mods, "mod_practical_emotion_regulation_hide_neg_emotions"))


# emo reg change thinking
mod_practical_emotion_regulation_change_thinking_to_calm <- double_robust(
  df = dt_practical,  # note change
  Y = "t2_emotion_regulation_change_thinking_to_calm_z",
  X = X,
  baseline_vars = baseline_vars_practical,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
  vcov = vcov, 
  new_name = "Emotion reg change thinking to calm (sd)"
)
# view and save model
mod_practical_emotion_regulation_change_thinking_to_calm
saveRDS(mod_practical_emotion_regulation_change_thinking_to_calm, here::here(push_mods, "mod_practical_emotion_regulation_change_thinking_to_calm"))

# 
# mod_practical_emotion_regulation <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_emotion_regulation_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "emotion_regulation_z"
# )
# 
# mod_practical_emotion_regulation
# save model
# saveRDS(mod_practical_emotion_regulation, here::here(push_mods, "mod_practical_emotion_regulation"))


# 
# mod_practical_emp_work_life_balance <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_emp_work_life_balance_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "emp_work_life_balance (no baseline)"
# )
# 
#mod_practical_emp_work_life_balance
# # save model
# saveRDS(mod_practical_emp_work_life_balance, here::here(push_mods, "mod_practical_emp_work_life_balance"))



# 
# mod_practical_perfectionism <- double_robust(
#   df = dt_practical,  # note change
#   Y = "t2_perfectionism_z",
#   X = X,
#   baseline_vars = baseline_vars_practical,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "perfectionism_z"
# )
# 
# # save model
# saveRDS(mod_practical_emp_work_life_balance, here::here(push_mods, "mod_practical_emp_work_life_balance"))
#
```

```{r}
#| label: models-reflective
#| eval: false
#| include: false
#| echo: false

# fetch expposure fvar name
exposure_vars <- readRDS(here::here(push_mods,"exposure_vars"))
exposure_vars
X <- exposure_vars
mice_reflective_mids <- readRDS(here::here(push_mods, "mice_reflective_mids"))

# longform data if necessary
mice_reflective_long <- readRDS(here::here(push_mods, "mice_reflective_long"))

# check exposure
X

baseline_vars_reflective = mice_reflective_long |> 
  dplyr::select(starts_with("t0"), -t0_religion_religious)|> colnames() # no variance at baseline


# propensity scores
estimand = "ATE"
# use energy balance, and only energy balance if the exposure is continuous.
match_ebal_reflective <- match_mi_general(data = mice_reflective_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_reflective, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "ebal", 
                                 sample_weights = "sample_weights")

# save
here_save(match_ebal_reflective, "match_ebal_reflective")


# use energy balance, and only engergy balance if the exposure is continuous.
match_energy_reflective <- match_mi_general(data = mice_reflective_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_reflective, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights" )

# save
# personal function loaded at start: equivalent saveRDS(match_ebal_reflective, here::here(push_mods, "match_ebal_reflective"))
here_save(match_reflective_reflective, "match_energy_reflective")


# propensity scores by covariate balanced matching 
match_cbps_reflective <- match_mi_general(data = mice_reflective_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_reflective, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "cbps", 
                                 sample_weights = "sample_weights")

here_save(match_cbps_reflective, "match_cbps_reflective")

# checks results
# ebal method
bal.tab(match_ebal_reflective)
love.plot(match_ebal_reflective, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2) 

# consider results 
sum_ebal_reflective <- summary(match_ebal_reflective)
sum_ebal_reflective
plot(sum_ebal_reflective)

# energy method
#graph
bal.tab(match_energy_reflective)
love_plot_match_energy_reflective <- love.plot(match_energy_reflective, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_energy_reflective <- summary(match_energy_reflective)
sum_energy_reflective
plot(sum_ebal_reflective)


# cbps score method
#graph
bal.tab(match_energy_reflective)
summary(match_cbps_reflective)
plot(sum_cbps_reflective)

love.plot(match_cbps_reflective, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2) 
love_plot_match_cbps_reflective

# consider results 
sum_cbps_reflective <- summary(match_cbps_reflective)
sum_cbps_reflective
plot(sum_cbps_reflective)

# if trim is needed
# mice_reflective_ebal_trim <- WeightIt::trim(mice_reflective_ebal, at = .99)
# sum_ebal_trim <- summary(mice_reflective_ebal_trim)
# sum_ebal_trim
# 
# plot(sum_ebal_trim)
# bal.tab(mice_reflective_ebal_trim,stats = c("m", "ks"), abs = TRUE)
# 
# love.plot(mice_reflective_ebal_trim, binary = "std", thresholds = c(m = .1))
# 
# dev.off()

# settings 
# Set DF 

dt_reflective = match_ebal_reflective

# bootstrap simulations
nsims
# cores
cl# = 10
cores# = 10
         
# check
X 

#check
treat_0

#check
treat_1 
# gratitude
mod_reflective_gratitude  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_gratitude_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  vcov = vcov,
  new_name = "Gratitude (sd)"
)
# save model
mod_reflective_gratitude
saveRDS(mod_reflective_gratitude, here::here(push_mods, "mod_reflective_gratitude"))


mod_reflective_pwi_health  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_pwi_health_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Pwi health (sd)"
)

# save model
mod_reflective_pwi_health
saveRDS(mod_reflective_pwi_health, here::here(push_mods, "mod_reflective_pwi_health"))


mod_reflective_pwi_relationships  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_pwi_relationships_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Pwi relationships (sd)"
)
# save model
mod_reflective_pwi_relationships
saveRDS(mod_reflective_pwi_relationships, here::here(push_mods, "mod_reflective_pwi_relationships"))


# security
mod_reflective_pwi_security  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_pwi_security_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Pwi security (sd)"
)
# save model
mod_reflective_pwi_security
saveRDS(mod_reflective_pwi_security, here::here(push_mods, "mod_reflective_pwi_security"))


# standard living
mod_reflective_pwi_standardliving  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_pwi_standardliving_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Pwi standardliving (sd)"
)

# save model
mod_reflective_pwi_standardliving
saveRDS(mod_reflective_pwi_standardliving, here::here(push_mods, "mod_reflective_pwi_standardliving"))


# 
# mod_reflective_pwi  <- double_robust(
#   df = dt_reflective,  # note change
#   Y = "t2_pwi_z",
#   X = X,
#   baseline_vars = baseline_vars_reflective,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "pwi_z"
# )
# 
# mod_reflective_pwi
# 
# # save model
# saveRDS(mod_reflective_pwi, here::here(push_mods, "mod_reflective_pwi"))
# 
# lifesat
mod_reflective_lifesat_satlife  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_lifesat_satlife_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Lifesat satlife (sd)"
)
# save model
mod_reflective_lifesat_satlife
saveRDS(mod_reflective_lifesat_satlife, here::here(push_mods, "mod_reflective_lifesat_satlife"))

# model lifesat ideal
mod_reflective_lifesat_ideal  <- double_robust(
  df = dt_reflective,  # note change
  Y = "t2_lifesat_ideal_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Lifesat ideal (sd)"
)
# save model
mod_reflective_lifesat_ideal
saveRDS(mod_reflective_lifesat_ideal, here::here(push_mods, "mod_reflective_lifesat_ideal"))
# 
# 
# ## lifesat
# mod_reflective_lifesat  <- double_robust(
#   df = dt_reflective,  # note change
#   Y = "t2_pwi_z",
#   X = X,
#   baseline_vars = baseline_vars_reflective,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "lifesat_z"
# )
# 
# mod_reflective_lifesat

# save model
# saveRDS(mod_reflective_lifesat, here::here(push_mods, "mod_reflective_lifesat"))


# meaning

# meaning purpose
mod_reflective_meaning_purpose  <- double_robust(
  df = dt_reflective, 
  Y = "t2_meaning_purpose_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Meaning purpose (sd)"
)
# save model
mod_reflective_meaning_purpose
saveRDS(mod_reflective_meaning_purpose, here::here(push_mods, "mod_reflective_meaning_purpose"))

# meaning sense
mod_reflective_meaning_sense  <- double_robust(
  df = dt_reflective,  
  Y = "t2_meaning_sense_z",
  X = X,
  baseline_vars = baseline_vars_reflective,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Meaning sense (sd)"
)
# save model
mod_reflective_meaning_sense
saveRDS(mod_reflective_meaning_sense, here::here(push_mods, "mod_reflective_meaning_sense"))
# 
# mod_reflective_meaning  <- double_robust(
#   df = dt_reflective,  # note change
#   Y = "t2_meaning_z",
#   X = X,
#   baseline_vars = baseline_vars_reflective,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "meaning_z"
# )

#mod_reflective_meaning

# save model
#saveRDS(mod_reflective_meaning, here::here(push_mods, "mod_reflective_meaning"))


## if needed:
#  <- readRDS( here::here(push_mods, ""))

## rr
 # <- readRDS( here::here(push_mods, ""))
```

```{r}
#| label: models-social
#| eval: false
#| include: false
#| echo: false

# import
mice_social_mids <- readRDS(here::here(push_mods, "mice_social_mids"))

# longform data if necessary
mice_social_long <- readRDS(here::here(push_mods, "mice_social_long"))

# check exposure 
X

# baseline vars
baseline_vars_social = mice_social_long |> 
  dplyr::select(starts_with("t0"), -t0_religion_religious_not)|> colnames() # no variance in exposure at baseline

# check
baseline_vars_social

# outcome vars
outcome_vars_social = mice_social_long |> dplyr::select(starts_with("t2")) |> colnames()



# propensity scores

# use energy balance, and only energy balance if the exposure is continuous.
match_ebal_social <- match_mi_general(data = mice_social_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_social, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "ebal", 
                                 sample_weights = "sample_weights")

# save
here_save(match_ebal_social, "match_ebal_social")


# use energy balance, and only engergy balance if the exposure is continuous.
match_energy_social <- match_mi_general(data = mice_social_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_social, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "energy", 
                                 sample_weights = "sample_weights",
                                verbose = TRUE )

# save
# personal function loaded at start: equivalent saveRDS(match_ebal_social, here::here(push_mods, "match_ebal_social"))
here_save(match_social_social, "match_energy_social")


# propensity scores by covariate balanced matching 
match_cbps_social <- match_mi_general(data = mice_social_mids, 
                                 X = X, 
                                 baseline_vars = baseline_vars_social, 
                                 estimand = estimand,  
                                # focal = "< >", for ATT
                                 method = "cbps", 
                                 sample_weights = "sample_weights")

here_save(match_cbps_social, "match_cbps_social")

# checks results
# ebal method
bal.tab(match_ebal_social)
love_plot_match_ebal_social <- love.plot(match_ebal_social, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_ebal_social <- summary(match_ebal_social)
sum_ebal_social
plot(sum_ebal_social)

# energy method
#graph
bal.tab(match_energy_social)
love_plot_match_energy_social <- love.plot(match_energy_social, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 

# consider results 
sum_energy_social <- summary(match_energy_social)
sum_energy_social
plot(sum_ebal_social)


# cbps score method
#graph
bal.tab(match_energy_social)
summary(match_cbps_social)
plot(sum_cbps_social)

love_plot_match_cbps_social <- love.plot(match_cbps_social, binary = "std", thresholds = c(m = .1),
          wrap = 50, position = "bottom", size =2, limits = list(m = c(-.5, .5))) 
love_plot_match_cbps_social

# consider results 
sum_cbps_social <- summary(match_cbps_social)
sum_cbps_social
plot(sum_cbps_social)

# if trim is needed
# mice_social_ebal_trim <- WeightIt::trim(mice_social_ebal, at = .99)
# sum_ebal_trim <- summary(mice_social_ebal_trim)
# sum_ebal_trim
# 
# plot(sum_ebal_trim)
# bal.tab(mice_social_ebal_trim,stats = c("m", "ks"), abs = TRUE)
# 
# love.plot(mice_social_ebal_trim, binary = "std", thresholds = c(m = .1))
# 
# dev.off()

# settings 
dt_social = match_trim_ebal_social

# cores
cl 
cores

#check
treat_0 
#check
treat_1 

# # save model
# mod_social_belong  <- double_robust(
#   df = dt_social,  # note change
#   Y = "t2_belong_z",
#   X = X,
#   baseline_vars = baseline_vars_social,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "belong_z"
# )
# 
# # save model
# saveRDS(mod_social_belong, here::here(push_mods, "mod_social_belong"))
# 
# 
# mod_social_support  <- double_robust(
#   df = dt_social,  # note change
#   Y = "t2_support_z",
#   X = X,
#   baseline_vars = baseline_vars_social,
#   treat_1 = treat_1,
#   treat_0 = treat_0,
#   estimand = estimand,
#   scale = "RD",
# 
#   nsims = nsims,
#   cores = cores,
#   family = "gaussian",
#   weights = TRUE,
#   continuous_X = FALSE,
#   splines = FALSE, 
#   new_name = "support_z"
# )
# 
# mod_social_support

# # save model
# saveRDS(mod_social_support, here::here(push_mods, "mod_social_support"))
# 

#"I believe I am capable, as an individual of improving my status in society."
mod_social_permeability_individual  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_permeability_individual_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Permeability individual (sd)"
)
# save model
mod_social_permeability_individual
saveRDS(mod_social_permeability_individual, here::here(push_mods, "mod_social_permeability_individual"))



#"The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change."
mod_social_impermeability_group  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_impermeability_group_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Impermeability group (sd)"
)
# save model
mod_social_impermeability_group
saveRDS(mod_social_impermeability_group, here::here(push_mods, "mod_social_impermeability_group"))

# I feel a sense of community with others in my local neighbourhood.
mod_social_neighbourhood_community  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_neighbourhood_community_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Neighbourhood community (sd)"
)
# save model
mod_social_neighbourhood_community
saveRDS(mod_social_neighbourhood_community, here::here(push_mods, "mod_social_neighbourhood_community"))


#'There are people I can depend on to help me if I really need it.
mod_social_support_help  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_support_help_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Support help (sd)"
)
# save model
mod_social_support_help
saveRDS(mod_social_support_help, here::here(push_mods, "mod_social_support_help"))

#There are people I can depend on to help me if I really need it.
mod_social_support_turnto  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_support_turnto_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Support turnto (sd)"
)
# save model
mod_social_support_turnto
saveRDS(mod_social_support_turnto, here::here(push_mods, "mod_social_support_turnto"))

#There is no one I can turn to for guidance in times of stress.
mod_social_support_rnoguidance  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_support_rnoguidance_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Support noguidance (reversed, sd)"
)
# save model
mod_social_support_rnoguidance
saveRDS(mod_social_support_rnoguidance, here::here(push_mods, "mod_social_support_rnoguidance"))

#Know that people in my life accept and value me.
mod_social_belong_accept  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_belong_accept_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Belong accept (sd)"
)

# save model
mod_social_belong_accept
saveRDS(mod_social_belong_accept, here::here(push_mods, "mod_social_belong_accept"))

# Feel like an outsider.
mod_social_belong_routsider  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_belong_routsider_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Belong outsider (reversed, sd)"
)
# save model
mod_social_belong_routsider
saveRDS(mod_social_belong_routsider, here::here(push_mods, "mod_social_belong_routsider"))

# Know that people around me share my attitudes and beliefs.
mod_social_belong_beliefs  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_belong_beliefs_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE,
    vcov = vcov,
  new_name = "Belong beliefs (sd)"
)
# save model
mod_social_belong_beliefs
saveRDS(mod_social_belong_beliefs, here::here(push_mods, "mod_social_belong_beliefs"))

#How much money have you donated to charity in the last year?
mod_social_charity_donate  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_charity_donate_log_z",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RD",
  nsims = nsims,
  cores = cores,
  family = "gaussian",
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
    vcov = vcov,
  new_name = "Charity donate (log sd)"
)
# save model
mod_social_charity_donate
saveRDS(mod_social_charity_donate, here::here(push_mods, "mod_social_charity_donate"))

#Hours spent in activities/Hours spent … voluntary/charitable work
mod_social_volunteers_rr  <- double_robust(
  df = dt_social,  # note change
  Y = "t2_volunteers",
  X = X,
  baseline_vars = baseline_vars_social,
  treat_1 = treat_1,
  treat_0 = treat_0,
  estimand = estimand,
  scale = "RR",
  type = "RR",
  nsims = nsims,
  cores = cores,
  family = quasibinomial(),
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "Volunteers y/n",
  vcov ="HC"
)

# view and save model
mod_social_volunteers_rr
saveRDS(mod_social_volunteers_rr, here::here(push_mods, "mod_social_volunteers_rr"))
```
## Introduction


<!-- Max Weber famously described the loss of religion as "the disenchantment of the world" [@wilson2014]. However, it is unclear whether, and in which ways, disaffiliation causes disenchantment. -->

<!-- Cross-sectional data can sometimes be useful for prediction, however they are generally ill-equipped for insights into causality. Take, for example, a scenario where individuals with lower levels of life meaning are observed to detach from their religious affiliations more frequently than those reporting higher life meaning. Cross-sectional data fall short in conclusively disentangling such complex relationships. It is conceivable that those experiencing a sense of life's futility may self-select out of religious institutions, resulting in a disproportionate representation of disenchanted individuals among non-religious groups in such surveys. Hence, if interventions were employed to encourage these disenchanted individuals to rejoin religious communities, they could potentially amplify feelings of life's meaninglessness. That is, correlations can mislead us to the opposite conclusions about true causation. Indeed the 'hints' suggested in cross-sectional data are known to strongly bias regression coefficients, whose true causal effects may run contrary to manifest correlations [@westreich2013]. However, a persistent habit of suggesting that cross-sectional data may 'hint' at causality presents a serious challenge to psychological science [@bulbulia2022][@bulbulia2021], -->

<!-- To gain clearer insights into the causal effects of religious disaffiliation, we apply longitudinal data in this study. Our approach aims to replicate an idealized experiment, thereby providing a more transparent understanding of causality [@hernán2016; @bulbulia2022; @hernan2023]. -->

## Method

### Sample

Data were collected as part of The New Zealand Attitudes and Values Study (NZAVS) is an annual longitudinal national probability panel study of social attitudes, personality, ideology and health outcomes. The NZAVS began in 2009. It includes questionnaire responses from more than 70,000 New Zealand residents. The study includes researchers from many New Zealand universities, including the University of Auckland, Victoria University of Wellington, the University of Canterbury, the University of Otago, and Waikato University. Because the survey asks the same people to respond each year, it can track subtle change in attitudes and values over time, and is an important resource for researchers both in New Zealand and around the world. The NZAVS is university-based, not- for-profit and independent of political or corporate funding.https://doi.org/10.17605/OSF.IO/75SNB

### Eligibility Criteria

The sample consisted of respondents to NZAVS waves Time 10, 11, and 12 (years 2018-2021) (See Appendix A.)

1.  those participants who stated an identification with religious at the baseline wave (NZAVS wave 10, years 2018-2019) and
2.  stated an identification with religious in the follow up wave (NZAVS wave 11, years 2019-2020)

There were N NZAVS participants who met these criteria.

### The Exposure: Religious Affiliation

```{r}
#| label: verify-positivity-data
#| eval: true
#| echo: false
dt_positivity_full <- readRDS(here::here(push_mods,"dt_positivity_full"))

out <- msm::statetable.msm(religion_religious, id, data = dt_positivity_full)

state_names <- c("religious affiliate", "religious dis-affiliate")

# transition table
t_tab <- transition_table(out, state_names)

# print 
cat(t_tab$explanation)
print(t_tab$table)
```

As indicated in @tbl-transition, of the 12600 people who were religious at baseline, 1977 people dis-affiliated participants one year later (NZAVS wave 2019), at the measurement year. Of the 22142 who were not affiliated at baseline, 1183 affiliated [^1]

[^1]: Cite our Markov paper showing that much religious change is probably artifactual.



|          From           | religious affiliate | religious dis-affiliate |
|:-----------------------:|:-------------------:|:-----------------------:|
|   religious affiliate   |        20959        |          1183           |
| religious dis-affiliate |        1977         |          10623          |

: Transition matrix {#tbl-transition}

### Indicators of well-being.

We assessed well-being following @vanderweele2020 outcome-wide template. Outcomewide studies argue that, rather than cherry-picking one or several domains of well-being, science may advance more rapidly, and with greater hope for replication, by assess well-being across as many range of indicators the data may afford. To assist with interpretation, @vanderweele2020 groups well-being into larger dimensions of interest. Here, we identify five-domains: health, embodied well-being, practical well-being, reflective well-being, and social well-being (see Appendix A.)

### Assumptions for causal inference

To assess a causal effect we must contrast how the world would turn out if we were to intervene. Generally, we cannot observe individual causal effects because for any individual case, we only observe the intervention or its absence. We cannot both intervene and not-intervene at once. This is called the fundamental problem of causal inference [@rubin1976; @holland1986; @bulbulia2022]. Although we cannot generally observe unit-level causal effects, it may be possible to estimate average causal effects. We do this by contrasting the average effect in the exposed group with the average effect in the unexposed unexposed group. For example, average of the contrast (or equivalently the contrast of the the averages)[^2] on the difference scale may be expressed:

[^2]: Note that mathematically, the difference in the average expectation is equivalent to the average of the differences in expectation.

```{=tex}
\begin{alignat*}{2}
ATE & = E[Y(1)) - E(Y(0)]\\
& = E=[Y(1) - Y(0)]
\end{alignat*}
```
Estimating the average treatment effects (ATE) of binary exposures or contrasts between different exposure levels involves understanding causal inference as counterfactual data science. The ATE is expressed as:

```{=tex}
   \begin{align*}
    ATE = E[Y(a) - Y(a*)]
    \end{align*}
```
Our causal inference is grounded on three critical assumptions:

#### Identification assumption 1: Causal consistency

Causal consistency assumes the observed outcome aligns with the potential outcome for a given exposure level:

$$Y^{observed} = AY(a=1) + (1-A)Y(a=0)$$

Observed outcomes can represent counterfactual outcomes under certain exposures, such that:

$$
Y^{observed}_i = 
\begin{cases} 
Y_i(~a^*) & \text{if } A_i = a* \\
Y_i(~a~) & \text{if } A_i = a
\end{cases}
$$

Causal consistency also assumes no interference between unit treatments, allowing potential outcomes to be set to the observed outcomes. For this assumption to hold, we require "treatment variation irrelevance." If there are (1) well-defined outcomes for each treatment version, and (2) no confounding effects, the multiple versions of treatments can be used to estimate the causal effect:

$$K \coprod Y(k) | L$$ or equivalently $$Y(k) \coprod K | L$$

Here, the treatment $A$ is essentially a function of $K$ treatments, $A = f(k_1...k_v)$ versions

Limitations exist, however, when interventions are ill-defined, or the causal effect's interpretation is ambiguous. Put simply, given there are unknown ways of becoming religiously disaffiliated the interpretation of "disaffiliation" may be strained. It is strained in the sense that we would not know how to intervene to *make* a religiously affiliated person disaffiliate. We will return to this question in the discussion.

#### Identification assumption 2: Exchangability

Exchangability assumes treatment assignment is independent of potential outcomes, given observed covariates. This is the "no-confounding" assumption that many psychologists have learned in association with experimental design. In the setting of observational data, we emulate randomisation by conditioning on indicators that may lead to an association of the exposure $A$ and the outcome $Y$ in the absence of causation.

$$Y(a)\coprod  A|L$$ or $$A \coprod  Y(a)|L$$

Where exchangability holds, we calculate the Average Treatment Effect (ATE)

$$
ATE = E[Y(a*)|L = l] - E[Y(a)|L = l] 
$$

Put differently, conditioning on confounders ensures *balance* in their distribution across exposures.

#### Identification assumption 3: Positivity

Positivity is satisfied if there is a positive probability of receiving or not receiving exposure at all covariate levels. Expressed as:

```{=tex}
\begin{equation}
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall a \in L
\end{equation}
```
There are two types of positivity violation.

-   **Random non-positivity**: Occurs when the causal effect of a missing observation is presumed to exist. This violation is the only one verifiable by data. Here, we check and report it.

-   **Deterministic non-positivity**: Occurs when the causal effect is inconceivable. For example, the causal effect of hysterectomy in biological males violates deterministic non-positivity.

### Causal identification Strategy

Effects must follow causes. To avoid the problems of reverse causation, we measured outcomes during the year following the exposure (NZAVS wave 2020). The causal graph presented in @fig-outcomewide-dag describes our method for confouding control. We follow @vanderweele2020 in adopting a modified disjunctive cause criterion whisch states:

1.  **Identify all relevant factors**: first, find every covariates that can influence either the exposure (disaffiliation) or the outcomes (across the five domains), or both. These factors are any variable that can have an impact on the exposure or outcome, are that might be the effect of such a factor.

2.  **Remove instrumental variables**: next, take out any factors that are known to be 'instrumental variables'. These are factors that cause the exposure but do not affect the outcome. Including instrumental variables reduces efficiency.

3.  **Include proxy variables for unmeasured common causes**: if there are any unmeasured factors that influence both the exposure and outcome, but we don not have direct measurements for them, we should try to include a proxy for these. A proxy is an effect of the variable.

4.  **Control for prior exposure**: Controlling for prior exposure assesses the effects of "incident exposure" rather than "prevalent exposure" - and is a critical step in causal inference[@danaei2012; @hernan2023]. By including prior exposure in the analysis, we can more effectively emulate a controlled trial. This approach not only helps interpret the effect of exposure changes but also strengthens confounding control. It aids in avoiding reverse causation and managing other forms of unmeasured confounding. This setup ensures that any unmeasured confounder would have to influence both the outcome and initial exposure, irrespective of previous exposure levels, to explain an observed exposure-outcome association.

5.  **Control for prior outcome**: It is also vital to control for the outcome measured at baseline -- the 'baseline outcome'. This tactic aims to rule out reverse causation by ensuring that the cause-effect relationship follows the right temporal order. Even though it does not eliminate the possibility of reverse causation, controlling for the baseline outcome helps mitigate its effects. Hence, along with a rich set of covariates, the baseline outcome should be included in the covariate set to make the confounding control assumption as plausible as possible. It is often the strongest confounder affecting both the exposure and subsequent outcome. (For a detailed account of confounding control in three-wave panel designs see @vanderweele2020)

To avoid bias, we must also handle missing data arising from non-response or panel attrition (loss-to-follow up). Selection bias occurs when... To address selection bias we perform multiple imputation *separately* by each exposure condition, and combine the imputations after modelling missingness conditional on the observed covariates (see: [@zhang2023; @westreich2015]) . We implement multiple imputation using the `mice` package in R [@vanbuuren2018]. We imputed 10 x missing data sets which were passed separately to the the `MatchThem` and `WeightIt` packages for propensity score matching. There are several ways in which selection bias can occur from missing responses and loss to follow up (see [@hernán2016; @hernan2023], @fig-outcomewide-dag presents a scenario in which the exposure $A$ affects the process of selection. For example ... (say more).

```{tikz}
#| label: fig-outcomewide-dag
#| fig-cap: "Causal graph: three-wave panel design with selection bias"
#| out-width: 80%
#| echo: false
#| include: true
#| eval: true

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {L$_{t0}$ \\A$_{t0}$ \\Y$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (US) at (4, -2) {U};
\node [rectangle, draw=black](S) at (6, 0) {S};
\node [ellipse, draw=white] (Y) at (8, 0) {Y$_{t2}$};

\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, bend left=50, draw=black] (L) to (Y);
\draw [-latex, bend right=50, draw=black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw=black, dotted] (U) to (A);
\draw [-latex, draw=black] (A) to (S);
\draw [-latex, draw=black] (US) to (S);
\draw [-latex, draw=black] (US) to (Y);
\draw [-latex, bend left = 40, draw=red, dashed] (A) to (Y);
\draw [cor, draw=red, bend right=20, dashed] (A) to (US);

\end{tikzpicture}


```

### Causal estimation

To obtain causal contrasts we use doubly robust methods. These combine inverse probability of treatment weights (propensity scores) with regression stratification. There are two models at work in a doubly robust estimator.

We use a Doubly Robust Estimation method, which effectively combines the strengths of the IPTW and G-computation methods (see: [here](https://go-bayes.github.io/psych-434-2023/content/09-content.html#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study-e.g.-assessment-3-option-2). The technique utilises both the propensity score and the outcome model, making it "doubly robust." This implies that if either of these models is correctly specified, the estimation will not be biased.

**Step 1** The first step is to estimate the propensity score. The propensity score, denoted as $e(L)$, is the conditional probability of the exposure $A = 1$ given the covariates $L$. The appropriate model to estimate this can be chosen based on the nature of the data and the exposure.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

In this equation, $f_A(L; \theta_A)$ is a function that estimates the probability of the exposure $A = 1$ given covariates $L$. Here, we use the `ebalance` method from the `clarify` package, which we have found to ensure good balance on the confounders (see fig below). We then calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Here, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

**Step 2** The next step involves fitting a weighted outcome model. Using the weights computed from the estimated propensity scores, a model for the outcome $Y$, conditional on the exposure $A$, is fitted.

$$ \hat{E}(Y|A, L; V) = f_Y(A, L ; \theta_Y, V) $$

In this model, $f_Y$ is a function (in our case a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting the contribution of each observation to the estimation of $θ_Y$, but they are not an additional variable in the model. Additionally, following @agnostic, we take the interaction of the exposure and baseline covariates when estimating our regression model. For binary outcomes we model the rate ratio using Poisson regression. Although binomial regression is acceptable when the outcome is rare (less than 10%), non-collapsability leads means that we cannot interpret results as marginal causal effects. For consistency we use the Poisson model with robust standard errors.

**Step 3** The third step is to simulate the potential outcome for each individual under the hypothetical scenario where everyone is exposed to the intervention $A=a$, irrespective of their actual exposure level:

$$\hat{E}(a) = \hat{E}[Y_i|A=a; L,\hat{\theta}_Y, v_i]$$

This expectation is calculated for each individual $i$, with individual-specific weights $v_i$.

**Step 4** Finally, we estimate the average causal effect. We compute the estimated expected value of the potential outcomes under each intervention level:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The difference $\delta$ represents the average causal effect of changing the exposure from level $a'$ to level $a$.

For standard errors and confidence intervals, we use simulation-based inference methods [@greifer2023].

### Baseline confounders, exposure, and outcome measures

( *Say more.* *Tables here* )

((*Insert section on why the assumptions of factor models are much stronger than people are aware, and that -- despite a loss of efficiency -- it is often best to use single item measures except when there are clear* conceptual\* reasons to do otherwise.\* ))

**SEE**: [@vanderweele2022]

## Results

### Effects on health



As indicate in @fig-results-health, the expected + one-year effect of 

```{r}
#| label: fig-results-health
#| fig-cap: "Causal effects of religious loss on reported physical health"
#| eval: true
#| include: true
#| echo: false
# import models 
mod_health_hlth_bmi <- readRDS( here::here(push_mods, "mod_health_hlth_bmi"))
mod_health_alcohol_frequency <- readRDS( here::here(push_mods, "mod_health_alcohol_frequency"))
mod_health_alcohol_intensity <- readRDS( here::here(push_mods, "mod_health_alcohol_intensity")) 
mod_health_hours_exercise <- readRDS( here::here(push_mods, "mod_health_hours_exercise"))
mod_health_sfhealth_your_health <- readRDS( here::here(push_mods, "mod_health_sfhealth_your_health"))
mod_health_sfhealth_get_sick_easier <- readRDS( here::here(push_mods, "mod_health_sfhealth_get_sick_easier"))
mod_health_sfhealth_expect_worse_health <- readRDS( here::here(push_mods, "mod_health_sfhealth_expect_worse_health"))
mod_health_hlth_sleep_hours  <- readRDS( here::here(push_mods, "mod_health_hlth_sleep_hours"))


tab_health <-
  rbind(
mod_health_hlth_bmi,
mod_health_alcohol_frequency,
mod_health_alcohol_intensity,
mod_health_hours_exercise,
mod_health_sfhealth_your_health,
mod_health_sfhealth_get_sick_easier,
mod_health_sfhealth_expect_worse_health,
#mod_health_sfhealth_comp,
mod_health_hlth_sleep_hours
  )
# inspect
# tab_health

group_tab_health <- group_tab(tab_health, type = "RD")
#saveRDS(group_tab_health, here::here(push_mods, "group_tab_health")) # save on first anlaysis, no need after

# print if needed 
#group_tab_health

# set title
title = "ATE: +1 year causal effect from affiliate to disaffiliate"
subtitle_health = "Health outcomes"
#
group_plot_ate_health <- margot_plot(group_tab_health,    
                           type = "RD",
                           title = title, 
                           subtitle = subtitle_health, 
                           xlab = "(sd units)", 
                           ylab = "test",
                           estimate_scale = 1,
                           base_size = 8,
                           text_size = 2.5,
                           point_size = .5,
                           title_size = 12,
                           subtitle_size = 11,
                           legend_text_size = 8,
                           legend_title_size = 10,
                           x_offset = -1.5,
                           x_lim_lo = -1.5,
                           x_lim_hi =  .3)  

#check
group_plot_ate_health

# ggsave(
#   group_plot_ate_health,
#   path = here::here(here::here(push_mods, "group_plot_ate_health")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_ate_health.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )
```

```{r}
#| label: tbl-results-health
#| tbl-cap: "Table of results for the health domain"
#| eval: true
#| include: true
#| echo: false

tab_health |> 
  kbl(format="markdown")

# interpret_table(group_tab_health, "causal_difference", "PATE")

```

@tbl-results-health presents the Population Average Treatment Effect (PATE) represents the expected difference in outcomes between treatment and control groups for the New Zealand population. We observed the following:


```{r}
#| label: fig-results-health-rr
#| fig-cap: "Causal effects of religious loss on smoking (risk ratio)"
#| eval: true
#| include: true
#| echo: false



# risk ratio plot
# import
mod_health_smoker_rr <- readRDS( here::here(push_mods, "mod_health_smoker_rr"))

tab_health_rr <- rbind(
  mod_health_smoker_rr
)

#check
#tab_health_rr

# make table
group_tab_health_rr <- group_tab(tab_health_rr, type = "RR")

# print table view
#group_tab_health_rr

group_plot_health_rr <- margot_plot(
  group_tab_health_rr,
  type = "RR",
  title = title,
  subtitle = subtitle_health,
  xlab = "(sd units)",
  ylab = "test",
  estimate_scale = 1,
  base_size = 11,
  text_size = 3,
  point_size = .5,
  title_size = 12,
  subtitle_size = 11,
  legend_text_size = 8,
  legend_title_size = 10,
  x_offset = -1,
  x_lim_lo = -1,
  x_lim_hi = 2.5
)
group_plot_health_rr



# save after modelling
# ggsave(
#   group_plot_health_rr,
#   path = here::here(here::here(push_mods, "group_plot_health_rr")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_health_rr.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )
# dev.off()
```

```{r}
#| label: tbl-results-health-rr
#| tbl-cap: "Table of results for smoking"
#| eval: true
#| include: true
#| echo: false

tab_health_rr |> 
  kbl(format="markdown")

#interpret_table(group_tab_health_rr, "causal_risk_ratio", "PATE")

```

For the outcome 'Smoker y/n', the PATE causal contrast is 1.012. The confidence interval ranges from 0.787 to 1.284. The E-value for this outcome confirms the causal contrast unreliable.

### Effects on embodied well-being

```{r}
#| label: fig-results-embodied
#| fig-cap: "Causal effects of religious loss on embodied well-being"
#| eval: true
#| include: true
#| echo: false

mod_embodied_hlth_fatigue <-
  readRDS(here::here(push_mods, "mod_embodied_hlth_fatigue"))
mod_embodied_rumination <-
  readRDS(here::here(push_mods, "mod_embodied_rumination"))
mod_embodied_kessler_depressed <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_depressed"))
mod_embodied_kessler_effort <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_effort"))
mod_embodied_kessler_hopeless <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_hopeless"))
mod_embodied_kessler_nervous <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_nervous"))
mod_embodied_kessler_restless <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_restless"))
mod_embodied_kessler_worthless <-
  readRDS(here::here(push_mods, "mod_embodied_kessler_worthless"))



tab_embodied <-
  rbind(
mod_embodied_hlth_fatigue,
mod_embodied_rumination,
mod_embodied_kessler_depressed,
mod_embodied_kessler_effort,
mod_embodied_kessler_hopeless,
mod_embodied_kessler_nervous,
mod_embodied_kessler_restless,
mod_embodied_kessler_worthless#
#mod_embodied_kessler_6,
#mod_embodied_kessler_6_depression,
#mod_embodied_kessler_6_anxiety
  )

#tab_embodied
group_tab_embodied <- group_tab(tab_embodied, type = "RD")
# group_tab_embodied

# save first attempt, not needed for making quarto docs
# saveRDS(group_tab_embodied, here::here(push_mods, "group_tab_embodied"))
#group_tab_embodied <- group_tab(tab_embodied, type = "RD")

#check
#title
title = "ATE: +1 year causal effect from affiliate to disaffiliate"
# make subtitle
subtitle_embodied = "Embodied outcomes"

# make graph
group_plot_ate_embodied <- margot_plot(group_tab_embodied,    
                           type = "RD",
                           title = title, 
                           subtitle = subtitle_embodied, 
                           xlab = "(sd units)", 
                           ylab = "test",
                           estimate_scale = 1,
                           base_size = 8,
                           text_size = 2.5,
                           point_size = .5,
                           title_size = 12,
                           subtitle_size = 11,
                           legend_text_size = 8,
                           legend_title_size = 10,
                           x_offset = -1.5,
                           x_lim_lo = -1.5,
                           x_lim_hi =  .3)  
# view graph
group_plot_ate_embodied

# save after first modelling attempt 
# ggsave(
#   group_plot_ate_embodied,
#   path = here::here(here::here(push_mods, "group_plot_ate_embodied")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_ate_embodied.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )
# dev.off()
```

```{r}
#| label: tbl-results-embodied
#| tbl-cap: "Table of results for the embodied well-being domain"
#| eval: true
#| include: true
#| echo: false

tab_embodied |> 
  kbl(format="markdown")

#interpret_table(group_tab_embodied, "causal_difference", "PATE" )

```

@tbl-results-embodied presents the Population Average Treatment Effect (PATE) for the embodied domain.

### Effects on practical well-being



```{r}
#| label: fig-results-practical-well-being
#| fig-cap: "Causal effects of religious loss on practical well-being"
#| eval: true
#| include: true
#| echo: false


## combo-table

## if needed:
mod_practical_sexual_satisfaction  <- readRDS( here::here(push_mods, "mod_practical_sexual_satisfaction"))
mod_practical_perfectionism  <- readRDS( here::here(push_mods, "mod_practical_perfectionism"))
mod_practical_bodysat  <- readRDS( here::here(push_mods, "mod_practical_bodysat"))
mod_practical_vengeful_rumin  <- readRDS( here::here(push_mods, "mod_practical_vengeful_rumin"))
mod_practical_power_self_nocontrol  <- readRDS( here::here(push_mods, "mod_practical_power_self_nocontrol"))
mod_practical_power_others_control <- readRDS( here::here(push_mods, "mod_practical_power_others_control"))
mod_practical_selfesteem_satself  <- readRDS( here::here(push_mods, "mod_practical_selfesteem_satself"))
mod_practical_selfesteem_postiveself  <- readRDS( here::here(push_mods, "mod_practical_selfesteem_postiveself"))
mod_practical_selfesteem_rfailure  <- readRDS( here::here(push_mods, "mod_practical_selfesteem_rfailure"))
mod_practical_self_control_have_lots  <- readRDS( here::here(push_mods, "mod_practical_self_control_have_lots"))
mod_practical_self_control_wish_more_r  <- readRDS( here::here(push_mods, "mod_practical_self_control_wish_more_r"))
mod_practical_emotion_regulation_out_control  <- readRDS( here::here(push_mods, "mod_practical_emotion_regulation_out_control"))
mod_practical_emotion_regulation_hide_neg_emotions  <- readRDS( here::here(push_mods, "mod_practical_emotion_regulation_hide_neg_emotions"))
mod_practical_emotion_regulation_change_thinking_to_calm  <- readRDS( here::here(push_mods, "mod_practical_emotion_regulation_change_thinking_to_calm"))
mod_practical_nzsei13  <- readRDS( here::here(push_mods, "mod_practical_nzsei13"))



## rr
# <- readRDS( here::here(push_mods, ""))

tab_practical <-
  rbind(
  #  mod_practical_nzsei13,
    mod_practical_sexual_satisfaction,
    mod_practical_perfectionism,
    mod_practical_bodysat,
    mod_practical_vengeful_rumin,
    mod_practical_power_self_nocontrol,
    mod_practical_power_others_control,
   # mod_practical_powerdependence,
    mod_practical_selfesteem_satself,
    mod_practical_selfesteem_postiveself,
    mod_practical_selfesteem_rfailure,
  #  mod_practical_selfesteem,
    mod_practical_self_control_have_lots,
    mod_practical_self_control_wish_more_r,
   # mod_practical_self_control,
    mod_practical_emotion_regulation_out_control,
    mod_practical_emotion_regulation_hide_neg_emotions,
    mod_practical_emotion_regulation_change_thinking_to_calm,
    mod_practical_nzsei13
   # mod_practical_emotion_regulation#,
   # mod_practical_emp_work_life_balance
   # mod_practical_perfectionism
  )

# tab_practical

# make tab
group_tab_practical <- group_tab(tab_practical, type = "RD")

# view tab
# group_tab_practical

# save table once
#saveRDS(group_tab_practical, here::here(push_mods, "group_tab_practical"))

# check
# title 
#title
title = "ATE: +1 year causal effect from affiliate to disaffiliate"
subtitle_practical = "Practical outcomes"

group_plot_ate_practical <- margot_plot(group_tab_practical,    
                           type = "RD",
                           title = title, 
                           subtitle = subtitle_practical, 
                           xlab = "(sd units)", 
                           ylab = "test",
                           estimate_scale = 1,
                           base_size = 8,
                           text_size = 2.5,
                           point_size = .5,
                           title_size = 10,
                           subtitle_size = 09,
                           legend_text_size = 6,
                           legend_title_size = 6,
                           x_offset = -1.75,
                           x_lim_lo = -1.75,
                           x_lim_hi =  .3)  

#check
group_plot_ate_practical

# save once
# ggsave(
#   group_plot_ate_practical,
#   path = here::here(here::here(push_mods, "group_plot_ate_practical")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_ate_practical.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )

```

```{r}
#| label: tbl-results-practical
#| tbl-cap: "Table of results for the practical well-being domain"
#| eval: true
#| include: true
#| echo: false

tab_practical|> 
  kbl(format="markdown")

#interpret_table(group_tab_practical, "causal_difference", "PATE" )

```

@tbl-results-practical 


### Effects on reflective well-being

```{r}
#| label: fig-results-reflective-well-being
#| fig-cap: "Causal effects of religious loss on reflective well-being"
#| eval: true
#| include: true
#| echo: false



mod_reflective_gratitude <- readRDS( here::here(push_mods, "mod_reflective_gratitude"))
mod_reflective_pwi_health <- readRDS( here::here(push_mods, "mod_reflective_pwi_health"))
mod_reflective_pwi_relationships <- readRDS( here::here(push_mods, "mod_reflective_pwi_relationships"))
mod_reflective_pwi_security <- readRDS( here::here(push_mods, "mod_reflective_pwi_security"))
mod_reflective_pwi_standardliving <- readRDS( here::here(push_mods, "mod_reflective_pwi_standardliving"))
mod_reflective_lifesat_satlife <- readRDS( here::here(push_mods, "mod_reflective_lifesat_satlife"))
mod_reflective_lifesat_ideal <- readRDS( here::here(push_mods, "mod_reflective_lifesat_ideal"))
mod_reflective_meaning_purpose <- readRDS( here::here(push_mods, "mod_reflective_meaning_purpose"))
mod_reflective_meaning_sense <- readRDS( here::here(push_mods, "mod_reflective_meaning_sense"))

## combo-table
tab_reflective <- rbind(
  mod_reflective_gratitude,
  mod_reflective_pwi_health,
  mod_reflective_pwi_relationships,
  mod_reflective_pwi_security,
  mod_reflective_pwi_standardliving,
  #mod_reflective_pwi,
  mod_reflective_lifesat_satlife,
  mod_reflective_lifesat_ideal,
#  mod_reflective_lifesat,
  mod_reflective_meaning_purpose,
  mod_reflective_meaning_sense#,
 # mod_reflective_meaning
)

# table
#tab_reflective

# group tab
group_tab_reflective <- group_tab(tab_reflective, type = "RD")
#group_tab_reflective

# save
saveRDS(group_tab_reflective, here::here(push_mods, "group_tab_reflective"))

#check
#title

# make subtitle
subtitle_reflective = "Reflective outcomes"

# make graph
group_plot_ate_reflective <- margot_plot(group_tab_reflective,    
                           type = "RD",
                           title = title, 
                           subtitle = subtitle_reflective, 
                           xlab = "(sd units)", 
                           ylab = "test",
                           estimate_scale = 1,
                           base_size = 8,
                           text_size = 2.5,
                           point_size = .5,
                           title_size = 12,
                           subtitle_size = 11,
                           legend_text_size = 8,
                           legend_title_size = 10,
                           x_offset = -1.5,
                           x_lim_lo = -1.5,
                           x_lim_hi =  .3)  
# view graph
group_plot_ate_reflective

# save
# ggsave(
#   group_plot_ate_reflective,
#   path = here::here(here::here(push_mods, "group_plot_ate_reflective")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_ate_reflective.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )
```


```{r}
#| label: tbl-results-reflective
#| tbl-cap: "Table of results for the reflective well-being domain"
#| eval: true
#| include: true
#| echo: false

tab_reflective|> 
  kbl(format="markdown")

#interpret_table(group_tab_reflective, "causal_difference", "PATE" )

```

@tbl-results-reflective



### Effects social well-being


```{r}
#| label: fig-results-social-wellbeing
#| fig-cap: "Causal effects of religious loss on social well-being"
#| eval: true
#| include: true
#| echo: false

# read back models
## if needed:
mod_social_permeability_individual  <-
  readRDS(here::here(push_mods, "mod_social_permeability_individual"))
mod_social_impermeability_group  <-
  readRDS(here::here(push_mods, "mod_social_impermeability_group"))
mod_social_neighbourhood_community  <-
  readRDS(here::here(push_mods, "mod_social_neighbourhood_community"))
mod_social_support_help <-
  readRDS(here::here(push_mods, "mod_social_support_help"))
mod_social_support_turnto <-
  readRDS(here::here(push_mods, "mod_social_support_turnto"))
mod_social_support_rnoguidance  <-
  readRDS(here::here(push_mods, "mod_social_support_rnoguidance"))
mod_social_belong_accept  <-
  readRDS(here::here(push_mods, "mod_social_belong_accept"))
mod_social_belong_routsider  <-
  readRDS(here::here(push_mods, "mod_social_belong_routsider"))
mod_social_belong_beliefs  <-
  readRDS(here::here(push_mods, "mod_social_belong_beliefs"))
# mod_social_charity_donate <-
#   readRDS(here::here(push_mods, "mod_social_charity_donate"))


# bind tables
tab_social <- rbind(
 # mod_social_belong,
 # mod_social_support,
  mod_social_permeability_individual,
  mod_social_impermeability_group,
  mod_social_neighbourhood_community,
  mod_social_support_help,
  mod_social_support_turnto,
  mod_social_support_rnoguidance,
  mod_social_belong_accept,
  mod_social_belong_routsider,
  mod_social_belong_beliefs#,
 # mod_social_charity_donate
)

# make group table
group_tab_social <- group_tab(tab_social, type = "RD")

# view
#group_tab_social

# save
#saveRDS(group_tab_social, here::here(push_mods, "group_tab_social"))

# check title 
#title
title = "ATE: +1 year causal effect from affiliate to disaffiliate"

#check sub
subtitle_social = "Social outcomes"
group_plot_ate_social <- margot_plot(group_tab_social,    
                           type = "RD",
                           title = title, 
                           subtitle = subtitle_social, 
                           xlab = "(sd units)", 
                           ylab = "test",
                           estimate_scale = 1,
                           base_size = 8,
                           text_size = 2.5,
                           point_size = .5,
                           title_size = 12,
                           subtitle_size = 11,
                           legend_text_size = 8,
                           legend_title_size = 10,
                           x_offset = -2.5,
                           x_lim_lo = -2.5,
                           x_lim_hi =  .3)  

#check
group_plot_ate_social


# save once
# ggsave(
#   group_plot_ate_social,
#   path = here::here(here::here(push_mods, "group_plot_ate_social")),
#   width = 6,
#   height = 6,
#   units = "in",
#   filename = "group_plot_ate_social.png",
#   device = 'png',
#   limitsize = FALSE,
#   dpi = 600
# )
```


```{r}
#| label: tbl-results-social
#| tbl-cap: "Table of results for the reflective well-being domain"
#| eval: true
#| include: true
#| echo: false

tab_reflective|> 
  kbl(format="markdown")

#interpret_table(group_tab_social, "causal_difference", "PATE" )

```

@tbl-results-social



<!-- ```{r} -->
<!-- #| label: fig-models-social-risk-ratio -->
<!-- #| fig-cap: "Causal effects of religious loss on volunteering." -->
<!-- #| eval: true -->
<!-- #| include: true -->
<!-- #| echo: false -->

<!-- # read risk model -->
<!-- mod_social_volunteers_rr  <- readRDS( here::here(push_mods, "mod_social_volunteers_rr")) -->

<!-- # risk ratio table -->
<!-- tab_social_rr <- rbind( -->
<!--   mod_social_volunteers_rr -->
<!-- ) -->

<!-- # check -->
<!-- # tab_social_rr -->

<!-- # make table -->
<!-- group_tab_social_rr <- group_tab(tab_social_rr, type = "RR") -->

<!-- # view -->
<!-- #group_tab_social_rr -->
<!-- #title -->
<!-- title = "ATE: +1 year causal effect from affiliate to disaffiliate" -->
<!-- subtitle_social = "Social outcomes" -->

<!-- group_plot_social_rr <- margot_plot( -->
<!--   group_tab_social_rr, -->
<!--   type = "RR", -->
<!--   title = title, -->
<!--   subtitle = subtitle_social, -->
<!--   xlab = "(sd units)", -->
<!--   ylab = "test", -->
<!--   estimate_scale = 1, -->
<!--   base_size = 11, -->
<!--   text_size = 3, -->
<!--   point_size = .5, -->
<!--   title_size = 12, -->
<!--   subtitle_size = 11, -->
<!--   legend_text_size = 8, -->
<!--   legend_title_size = 10, -->
<!--   x_offset = -1.5, -->
<!--   x_lim_lo = -1.5, -->
<!--   x_lim_hi = 2.5 -->
<!-- ) -->

<!-- # ggsave( -->
<!-- #   group_plot_social_rr, -->
<!-- #   path = here::here(here::here(push_mods, "group_plot_social_rr")), -->
<!-- #   width = 6, -->
<!-- #   height = 6, -->
<!-- #   units = "in", -->
<!-- #   filename = "group_plot_social_rr.png", -->
<!-- #   device = 'png', -->
<!-- #   limitsize = FALSE, -->
<!-- #   dpi = 600 -->
<!-- # ) -->
<!-- ``` -->




## Discussion

Here, we combined rigorous methods from causal epidemiology with national scale time-series data to estimate the causal effects of religious disaffiliation on multidimensional well-being. We used doubly robust methods that combine propensity score weights with regression stratification. By controlling for measures of all outcomes at baseline we reduce the probability of unmeasured confounding. Because this cannot be ensured, we report E-values, a sensitivity analysis that clarifies the "worst case" scenario for an unmeasured confounder to explain away the results.

**Health domain**: The expected +1 year effect of religious disaffiliation is to increase both the average intensity and frequency of alcohol consumption. We do not find reliable results on other health domains.

**Embodied well-being domains**: We do not find reliable evidence for a +1 year effect of religious disaffiliation on embodied will being (i.e. distress, fatigue)

**Practical well-being**: The expected +1 year effect of religious disaffiliation is to diminish wishes for more self control. That is good. However the one-year effect of disaffiliation is to increase vengeful rumination. That is not good.

**Reflective well-being**: The expected +1 year effect of religious disaffiliation is increase life satisfaction. That is good. However the one-year effect of disaffiliation is to decrease a sense of purpose in life. That is not good.

**Social well-being-being**: Disaffiliation is expected to cause reduction in charitable giving and volunteering (consistent \[cite a different study\]). However we do not find that disaffiliation as such reduces other aspects of social well-being.

### Generalisability and Transportability

-   We can generalise to the religious population of New Zealand. Whether results transport elsewhere is unclear.

### Assumptions and Limitations

1.  Consistency...
2.  Positivity...
3.  Exhangeability...

Also

1.  Measurement of religious change -- Markov models show less
2.  Measurement error
3.  Loss to follow up attrition (requires modelling assumptions.)

### Theoretical Relevance

This study is important both for its methods and findings.

1.  The bar for causality in this study very high.
2.  It would generally be unexpected that in a country such as New Zealand, which is a highly secular, a change in one's religious affiliation would induce measurable effects on people within only one-year.

### Future Research

1.  We did not compare religious disaffiliates to people who are secular. Loss of religion suggests a loss of charity. However, secular people might be less charitable still. Future research...
2.  Previous research shows differences in these comparison groups [@vantongeren2020; @sibley2012a].

### Real-world Implications

In practical terms, the real-world implications of the findings, are ...

### Ethics Approval Details

The NZAVS is reviewed every three years by the University of Auckland Human Participants Ethics Committee. Our most recent ethics approval statement is as follows: The New Zealand Attitudes and Values Study was approved by the University of Auckland Human Participants Ethics Committee on 26/05/2021 for six years until 26/05/2027, Reference Number UAHPEC22576.

### Acknowledgements

The New Zealand Attitudes and Values Study is supported by a grant from the TempletoReligion Trust (TRT0196; TRT0418). JB received support from the Max Planck Institute for the Science of Human History. The funders had no role in preparing the manuscript or the decision to publish.

{{< pagebreak >}}

## Appendix A. Measures

### Baseline confounding control

#### Age (waves: 1-15)

We asked participants' age in an open-ended question ("What is your age?" or "What is your date of birth").

#### Disability (waves: 5-15)

We assessed disability with a one item indicator adapted from @verbrugge1997, that asks "Do you have a health condition or disability that limits you, and that has lasted for 6+ months?" (1 = Yes, 0 = No).

#### Education Attainment (waves: 1, 4-15)

Participants were asked "What is your highest level of qualification?". We coded participans highest finished degree according to the New Zealand Qualifications Authority. Ordinal-Rank 0-10 NZREG codes (with overseas school quals coded as Level 3, and all other ancillary categories coded as missing) See:https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf

#### Employment (waves: 1-3, 4-11)

We asked participants "Are you currently employed? (This includes self-employed or casual work)". \* note: This question disappeared in the updated NZAVS Technical documents (Data Dictionary).

#### European (waves: 1-15)

Participants were asked "Which ethnic group do you belong to (NZ census question)?" or "Which ethnic group(s) do you belong to? (Open-ended)" (wave: 3). Europeans were coded as 1, whereas other ethnicities were coded as 0.

#### Ethnicity (waves: 3)

Based on the New Zealand Cencus, we asked participants "Which ethnic group(s) do you belong to?". The responses were: (1) New Zealand European; (2) Māori; (3) Samoan; (4) Cook Island Māori; (5) Tongan; (6) Niuean; (7) Chinese; (8) Indian; (9) Other such as DUTCH, JAPANESE, TOKELAUAN. Please state:. We coded their answers into four groups: Maori, Pacific, Asian, and Euro (except for Time 3, which used an open-ended measure).

#### Gender (waves: 1-15)

We asked participants' gender in an open-ended question: "what is your gender?" or "Are you male or female?" (waves: 1-5). Female was coded as 0, Male was coded as 1, and gender diverse coded as 3 [@fraser_coding_2020]. (or 0.5 = neither female nor male)

#### Income (waves: 1-3, 4-15)

Participants were asked "Please estimate your total household income (before tax) for the year XXXX". To stablise this indicator, we first took the natural log of the response + 1, and then centred and standardised the log-transformed indicator.

#### Job Security (waves: 1-3,4-7,9-15)

Participants indicated their feeling of job security by answering "How secure do you feel in your current job?" on a scale from 1 (not secure) to 7 (very secure).

#### Parent (waves: 5-15)

Participants were asked "If you are a parent, what is the birth date of your eldest child?" or "If you are a parent, in which year was your eldest child born?" (waves: 10-15). Parents were coded as 1, while the others were coded as 0.

#### Number of Children (waves: 1-3, 4-15)

We measured number of children using one item from @Bulbulia_2015. We asked participants "How many children have you given birth to, fathered, or adopted. How many children have you given birth to, fathered, or adopted?" or ""How many children have you given birth to, fathered, or adopted. How many children have you given birth to, fathered, and/or parented?" (waves: 12-15).

#### Political Orientation

We measured participants' political orientation using a single item adapted from @jost_end_2006-1.

"Please rate how politically liberal versus conservative you see yourself as being."

(1 = Extremely Liberal to 7 = Extremely Conservative)

#### NZSEI-13 (waves: 8-15)

We assessed occupational prestige and status using the New Zealand Socio-economic Index 13 (NZSEI-13) [@fahy2017]. This index uses the income, age, and education of a reference group, in this case the 2013 New Zealand census, to calculate an score for each occupational group. Scores range from 10 (Lowest) to 90 (Highest). This list of index scores for occupational groups was used to assign each participant a NZSEI-13 score based on their occupation.

Participants were asked "If you are a parent, what is the birth date of your eldest child?".

#### Living with Partner

Participants were asekd "Do you live with your partner?" (1 = Yes, 0 = No).

#### Living in an Urban Area (waves: 1-15)

We coded whether they are living in an urban or rural area (1 = Urban, 0 = Rural) based on the addresses provided.

We coded whether they are living in an urban or rural area (1 = Urban, 0 = Rural) based on the addresses provided.

#### NZ Deprivation Index (waves: 1-15)

We used the NZ Deprivation Index to assign each participant a score based on where they live [@atkinson2019]. This score combines data such as income, home ownership, employment, qualifications, family structure, housing, and access to transport and communication for an area into one deprivation score.

#### NZ-Born (waves: 1-2,4-15)

We asked participants "Which country were you born in?" or "Where were you born? (please be specific, e.g., which town/city?)" (waves: 6-15).

#### Mini-IPIP 6 (waves: 1-3,4-15)

We measured participants personality with the Mini International Personality Item Pool 6 (Mini-IPIP6) [@sibley2011] which consists of six dimensions and each dimensions is measured with four items:

1.  agreeableness,

    i.  I sympathize with others' feelings.
    ii. I am not interested in other people's problems. (r)
    iii. I feel others' emotions.
    iv. I am not really interested in others. (r)

2.  conscientiousness,

    i.  I get chores done right away.
    ii. I like order.
    iii. I make a mess of things. (r)
    iv. I ften forget to put things back in their proper place. (r)

3.  extraversion,

    i.  I am the life of the party.
    ii. I don't talk a lot. (r)
    iii. I keep in the background. (r)
    iv. I talk to a lot of different people at parties.

4.  honesty-humility,

    i.  I feel entitled to more of everything. (r)
    ii. I deserve more things in life. (r)
    iii. I would like to be seen driving around in a very expensive car. (r)
    iv. I would get a lot of pleasure from owning expensive luxury goods. (r)

5.  neuroticism, and

    i.  I have frequent mood swings.
    ii. I am relaxed most of the time. (r)
    iii. I get upset easily.
    iv. I seldom feel blue. (r)

6.  openness to experience

    i.  I have a vivid imagination.
    ii. I have difficulty understanding abstract ideas. (r)
    iii. I do not have a good imagination. (r)
    iv. I am not interested in abstract ideas. (r)

Each dimension was assessed with four items and participants rated the accuracy of each item as it applies to them from 1 (Very Inaccurate) to 7 (Very Accurate). Items marked with (r) are reverse coded.

#### Honesty-Humility-Modesty Facet (waves: 10-14)

Participants indicated the extent to which they agree with the following four statements from @campbell2004 , and @sibley2011 (1 = Strongly Disagree to 7 = Strongly Agree)

```         
i.  I want people to know that I am an important person of high status, (Waves: 1, 10-14)
ii. I am an ordinary person who is no better than others.
iii. I wouldn't want people to treat me as though I were superior to them.
iv. I think that I am entitled to more respect than the average person is.
```

### Exposure variable

#### Religious Identification (waves: 1-15)

If participants answered *yes* to "Do you identify with a religion and/or spiritual group? we asked"How important is your religion to how you see yourself?" (1 = Not important, 7 = Very important). Those participants who were not religious were imputed a score of "1".

### Health well-being outcomes

#### Alcohol Frequency (waves: 6-15)

We measured participants' frequency of drinking alcohol using one item adapted from @Ministry_of_Health_2013 . Participants were asked "How often do you have a drink containing alcohol?" (1 = Never - I don't drink, 2 = Monthly or less, 3 = Up to 4 times a month, 4 = Up to 3 times a week, 5 = 4 or more times a week, 6 = Don't know).

#### Alcohol Intensity (waves: 6-15)

We measured participants' intensity of drinking alcohol using one item adapted from [@Ministry_of_Health_2013]. Participants were asked "How many drinks containing alcohol do you have on a typical day when drinking alcohol? (number of drinks on a typical day when drinking)"

#### Body Mass Index (waves: 2-3, 4-15)

Participants were asked "What is your height? (metres)" and "What is your weight? (kg)". Based on participants indication of their height and weight we calculated the BMI by dividing the weight in kilograms by the square of the height in meters.

#### Short-Form Subjective Health (waves: 5-15)

Participants' subjective health was assessed by three items selected from the MOS 36-item short-form health survey [@warejr1992]. The items were

```         
1.  "In general, would you say your health is...";
2.  "I seem to get sick a little easier than most people.";
3.  "I expect my health to get worse." Participants responded to those items on a scale (1 = Poor to 7 = Excellent).
```

The second and third items were negatively-worded, so we reversed the responses.

#### Hours of Exercise (waves: 1, 4-15)

We measured hours of exercising using one item from @sibley2011. We asked participants to estimate and report how many hours they spend in exercise/physical activity last week. To stablise this indicator, we first took the natural log of the response + 1, and then centred and standardised the log-transformed indicator.

#### Hours of Sleep (waves: 5-15)

Participants were asked "During the past month, on average, how many hours of *actual sleep* did you get per night".

#### Smoker (waves: 4-15)

We asked participants whether they are currently smoking or not (1 = Yes or 0 = No), using a single item: "Do you currently smoke?" or "Do you currently smoke tobacco cigarettes?" (waves: 10-15) from @muriwai_looking_2018.

### Embodied well-being outcomes

#### Kessler-6 (waves: 2-3,4-15)

We measured psychological distress using the Kessler-6 scale [@kessler2002], which exhibits strong diagnostic concordance for moderate and severe psychological distress in large, cross-cultural samples [@kessler2010; @prochaska2012]. Participants rated during the past 30 days, how often did... (

```         
1.  "... you feel hopeless";
2.  "... you feel so depressed that nothing could cheer you up";
3.  "... you feel restless or fidgety";
4.  "... you feel that everything was an effort";
5.  "... you feel worthless";
6.  " you feel nervous?"
```

Ordinal response options for the Kessler-6 are: "None of the time"; "A little of the time"; "Some of the time"; "Most of the time"; "All of the time."

#### Fatigue (waves: 5-15)

We assessed subjective fatigue by asking participants, "During the last 30 days, how often did ... you feel exhausted?" Responses were collected on an ordinal scale (0 = None of The Time, 1 = A little of The Time, 2 = Some of The Time, 3 = Most of The Time, 4 = All of The Time).

#### Rumination

"During the last 30 days, how often did.... you have negative thoughts that repeated over and over?"

Ordinal response options for the Kessler-6 are: "None of the time"; "A little of the time"; "Some of the time"; "Most of the time"; "All of the time."

### Practical well-being outcomes

#### Body Satisfaction (waves: 2-3, 4-15)

We measured body satisfaction with one item from @stronge_facebook_2015: "I am satisfied with the appearance, size and shape of my body", which participants rated from 1 (very inaccurate) to 7 (very accurate).

#### Emotional Regulation (waves: 10-13)

We measured participants' levels of emotional regulation using three items adpated from @gratz_multidimensional_2004 and @gross_individual_2003:

```         
1.  "When I feel negative emotions, my emotions feel out of control.";
2.  "When I feel negative emotions, I suppress or hide my emotions.";
3.  "When I feel negative emotions, I change the way I think to help me stay calm."
```

Participants were asked to indicate the extent to which they agree with these items (1 = Strongly Disagree to 7 = Strongly Agree).

#### Perfectionism (waves: 10-15)

We assessed participants' perfectionism using three items from @rice_short_2014: (1) Doing my best never seems to be enough; (2) My performance rarely measures up to my standards; (3) I am hardly ever satisfied with my performance. Participants indicated the extent to which they agree with these items (1 = Strongly Disagree to 7 = Strongly Agree).

#### Power Dependence

Participants' Power dependence was measured using two items:

```         
1." I do not have enough power or control over important parts of my life."
2". Other people have too much power or control over important parts of my life. 
```

Participants indicated their agreement with these items" (1 = Strongly Disagree to 7 = Strongly Agree).

<!-- #### Self-Respect (waves: 3, 4-11, 15) -->

<!-- We assessed participants' levels of self-respect using an item adapted from @tyler_understanding_1996. Participant indicated the extent to which they agree with the statement ("If they knew me, most NZers would respect what I have accomplished in life") on a likert scale (1 = Strongly Disagree to 7 = Strongly Agree) -->

#### Self-Control (waves: 5-15)

Participants were asked to indicate the extent to which they endorse the two items

```         
1.  "In general, I have a lot of self-control"
2.  "I wish I had more self-discipline"
```

The scale is from @tangney_high_2004. The responses to the items ranged from 1 (Strongly Disagree) to 7 (Strongly Agree).

#### Self-Esteem (waves: 1-3, 4-15)

We measured participants' self-esteem using three items adapted from @Rosenberg1965. Participants were instructed to circle the number that best represents how accurately each statement describes them. Participants responded to the items

```         
1.  "On the whole am satisfied with myself"
2.  "Take a positive attitude toward myself"
3.  "Am inclined to feel that I am a failure") on a likert-type scale (1 = Very inaccurate to 7 = Very accurate).
```

#### Sexual Satisfaction (waves: 10-15)

Participants were asked "How satisfied are you with your sex life?" (1 = Not satisfied to 7 = Very satisfied).

#### Vengeful Rumination (waves: 10-15)

We assessed participants' vengeful rumination using three items, respectively adapted from @caprara_indicators_1986 and @berry_forgivingness_2005, and developed for NZAVS: (1) Sometimes I can't sleep because of thinking about past wrongs I have suffered; (2) I can usually forgive and forget when someone does me wrong; (3) I find myself regularly thinking about past times that I have been wronged. Participants indicated their agreement with these items (1 = Strongly Disagree to 7 = Strongly Agree). The values for the second item were reversely coded.

### Reflective well-being

#### Meaning of Life (waves: 10-15)

We assessed participants' levels of life meaning using two items from @steger_meaning_2006:

```         
1.  My life has a clear sense of purpose;
2.  I have a good sense of what makes my life meaningful.
```

Participants indicated their agreement with these items (1 = Strongly Disagree to 7 = Strongly Agree).

#### Satisfaction with Life (waves: 1-3,4-15)

We measured life satisfaction with two items adapted from the Satisfaction with Life Scale [@diener1985]:

```         
1.  "I am satisfied with my life" and
2.  "In most ways my life is close to ideal".
```

Participants responded on a scale from 1 (Strongly Disagree) to 7 (Strongly Agree).

#### Personal Wellbeing (waves: 1-3, 4-15)

We measured participants' subjective wellbeing using three items from the Australian Unity Wellbeing Index [@cummins_developing_2003]:

```         
1.  your health;
2.  Your standard of living;
3.  Your future security; 4 Your personal relationships.
```

Participants read an instruction ("The following items assess your current satisfaction with different aspects of your life and aspects of New Zealand more generally") and indicated their satisfaction with those items (0 = Completely Dissatisfied to 10 = Completely Satisfied).

#### Standard Living

We measured participants' satisfaction with their standard of living using an item from the Australian Unity Wellbeing Index [@cummins_developing_2003]. Participants read an instruction ("Please rate your level of satisfaction with the following aspects of your life and New Zealand.") and responded to an item

```         
- "Your standard of living"
```

on a 10-point scale (0 = completely dissatisfied to 10 = completely satisfied).

### Social well-being outcomes

#### Charity Donation (waves: 1-3, 4-15)

We asked participants "How much money have you donated to charity in the last year?". To stablise this indicator, we first took the natural log of the response + 1, and then centred and standardised the log-transformed indicator.

#### Felt Belongingness (waves: 1-3, 4-15)

We assessed felt belongingness with three items adapted from the Sense of Belonging Instrument [@hagerty1995]:

```         
1.  "Know that people in my life accept and value me";
2.  "Feel like an outsider";
```

3.  "Know that people around me share my attitudes and beliefs".

Participants responded on a scale from 1 (Very Inaccurate) to 7 (Very Accurate). The second item was reversely coded.

#### Ethnic group impermeability (waves: 9-13)

The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change.

#### Individual Permeability (waves: 9-13)

Participants indicated the extent to which they agree with the statement, "I believe I am capable, as an individual of improving my status in society.", from @tausch2015 (1 = Strongly Disagree to 7 = Strongly Agree).

#### Sense of Community (waves: 6-15)

We measured sense of community with a single item from @sengupta2013: "I feel a sense of community with others in my local neighbourhood." Participants answered on a scale of 1 (strongly disagree) to 7 (strongly agree).

#### Support (waves: 1-3, 4-15)

Participants' perceived social support was measured using three items from @cutrona1987 and @williams_cyberostracism_2000:

```         
1.  "There are people I can depend on to help me if I really need it";
2.  "There is no one I can turn to for guidance in times of stress";
3.  "I know there are people I can turn to when I need help." 
```

Participants indicated the extent to which they agree with those items (1 = Strongly Disagree to 7 = Strongly Agree).

The second item was negatively-worded, so we reversely recorded the responses to this item.

#### Volunteers (waves: 1, 4-15)

Participants were asked,"Please estimate how many hours you spent doing each of the following things last week" and responded to an item ("voluntary/charitable work"), from [@sibley2011].

{{< pagebreak >}}

APPENDIX B. Sample {.appendix}

```{r}
#| label: table-baseline
#| echo: false
#| include: true
#| eval: true

prep_reflective <- readRDS(here::here(push_mods, "prep_reflective"))
rm(dt_tab_p)
dt_tab_p <- prep_reflective |>
  dplyr::mutate(t0_Male = as.factor(as.character(t0_male)),
          t0_Born_NZ = as.factor(t0_born_nz),
          t0_Partner = as.factor(t0_partner),
          t0_Parent  = as.factor(t0_parent),
          t0_Sample_Origin_Year = as.factor(t0_sample_origin)  ) |>
    dplyr::select(-c(t0_male,t0_born_nz, t0_partner, t0_parent, t0_sample_origin)) 

dt_tab <- dt_tab_p|> 
    dplyr::select(sort(names(dt_tab_p)))

baseline_table(dt_tab)
```

{{< pagebreak >}}

## Appendix C Propensity score analysis {.appendix}

### Propensity score analysis for health

Following [@thoemmes2011] we describe our method for obtaining and verifying our propensity score analysis using the WeightIt and Cobalt packages in R. z

**1. Information about data collection**

Information about data collection in the New Zealand Attitudes and Values Study can be obtained from [@sibley2021].

**2. List of all covariates used to estimate the propensity score**

The baseline covariates used in this study are detailed in Appendix A. These include:

``` markdown
- male
- age
- education_level_coarsen
- eth_cat
- nz_dep2018
- nzsei13
- born_nz
- partner
- parent
- pol_orient
- sample_origin
- urban
- household_inc_log
- agreeableness
- conscientiousness
- extraversion
- honesty_humility
- openness
- neuroticism
- modesty
```

3.  **Method for determining the set of covariates**

Covariates were selected based on their likelihood of association with the exposure and the outcome, or with an unmeasured confounder. Despite the comprehensive list of confounders, and the inclusion of the interaction of the exposure an all confounders in the outcome model, we did not consider expanding it given the effective sample size of about 1500 people in the disaffiliation sample.

4.  **Inclusion of polynomial or interaction terms**

Following the guidance of @agnostic, we included an interaction term for the exposure and baseline covariates.

5.  **Estimation method for propensity scores**

Standard inverse probability weighting and the `ebalance` method from the `WeightIt` package were used for estimation. The `ebalance` method consistently performed better and its performance is reported here.

5.  **Conditioning strategy**

A combination of weighting and stratification was used to obtain doubly robust estimation.

6.  **Region of common support**

We did not use histograms to assess regions of common support as we did not apply matching. However, both the propensity score analysis and descriptive results in Appendix A show very good overlap.

7.  **Details on weighting**

We included post-stratification census weights after the `WeightIt` method to obtain a population estimate for New Zealand. This method multiplies the propensity scores by the census weights to obtain a single vector of weights for all participants. We used the `age x gender x nzeuropean` census weights (Sibley, 2021).

8.  **Sample size before and after conditioning**

The effective sample sizes before and after weighting are reported below.

9.  **Standardized difference before and after matching**

Below, we report standardised differences before and after matching on the propensity score.

10. **Point estimate of treatment effect and associated standard error**

These are reported in the main results.

11. **Inclusion of covariates in outcome model**

All those used in the exposure (propensity score model), interacted with the exposure (religious disaffiliation). Additionally, we weighted the regression using the final output of the `WeightIt` and `MatchThem`\`package [@greifer2023a; @greifer2023b; @pishgar2021], which multiplies propensity scores x census weights.

@fig-results-health-propensity-scores shows strong evidence for imbalance at baseline in the confounders for the health domain. We restore balance using entropy weighting.

```{r}
#| label: fig-results-health-propensity-scores
#| fig-cap: "Love plot for propensity score analysis: health outcomes."
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false


match_ebal_health  <- here_read("match_ebal_health")
love_plot_match_ebal_health <- love.plot(match_ebal_health, size = 1, binary = "std", thresholds = c(m = .1))

love_plot_match_ebal_health + theme(
  plot.title = element_text(size = 10, hjust = 0),
  plot.subtitle = element_text(size = 10, hjust = 0),
  axis.text = element_text(size = 4),  # Adjust the size value as per your preference
  legend.text = element_text(size = 6),
  legend.title = element_text(size = 8)
) 

#bal.tab(match_ebal_health, stats = c("m", "v"), thresholds = c(m = .05))



```

@fig-results-health-propensity-dis shows propensity score weights in the unexposed group (remained religiously affiliated) and the exposed group (disasffiated)

```{r}
#| label: fig-results-health-propensity-dis
#| fig-cap: "Distribution of propensity scores by condition: health domain"
#| out-width: 80%
#| eval: true
#| include: true
#| echo: false

plot( summary( match_ebal_health ) )
# + theme(
#   plot.title = element_text(size = 10, hjust = 0),
#   plot.subtitle = element_text(size = 10, hjust = 0),
#   axis.text = element_text(size = 4),  # Adjust the size value as per your preference
#   legend.text = element_text(size = 6),
#   legend.title = element_text(size = 8)
#) 


#cobalt::bal.tab(match_ebal_health, stats = c("m", "v"), binary = "std", thresholds = c(m = .05))
```

**Summary of propensity score weights: health well-being domain**

| **Group** | **Weight Range (Min - Max)** | **Top 5 Extreme Weights**         | **Coefficient of Variation** | **Unweighted Sample Size** | **Weighted Sample Size** |
|------------|------------|------------|------------|------------|------------|
| 0         | 0.722 - 1.552                | 1.445, 1.489, 1.521, 1.522, 1.552 | 0.084                        | 10623                      | 10547.770                |
| 1         | 0.123 - 4.651                | 3.412, 3.441, 3.512, 3.703, 4.651 | 0.524                        | 1977                       | 1551.890                 |

: Summary of propensity scores: health well-being domain. {#tbl-summary-propensity-health}

As illustrated in @tbl-summary-propensity-health, the propensity score weights generated through the `WeightIt` package in R [@greifer2023] for the health well-being domain demonstrate a similar trend to those in the practical well-being domain. For both groups (Group 0 and Group 1), the five most extreme weights are reported.

The Coefficient of Variation (CoV) for each group remains under the threshold of 2, indicating satisfactory weight variation. The CoV for Group 0 (0.084) is lower than that of Group 1 (0.524), signifying less variation in weights for Group 0.

The effective sample sizes, which are critical indicators of the remaining information in the weighted sample, are reported for each group. These sizes being close to the original sample size by condition, as in the practical well-being domain, imply that the propensity score analysis for the health well-being domain maintains a considerable amount of the original data.

We investigated balance using the `Cobalt` package. The balance summary of the health domain, all the Mean Difference Adjusted values fall below our user-specified threshold of 0.05, indicating a well-balanced matching for this sample across all variables.

For the continuous variable for political orientation, the variance ratios are notably higher than most others. The minimum, mean, and maximum adjusted variance ratios are 0.9089, 0.9189, and 0.9336 respectively. This suggests that the variance between the treatment and control groups for political orientation is somewhat more substantial than for most other variables. However in absolute terms the variance ratio is modest.

### Propensity score analysis for embodied well-being

@fig-love-embodied shows strong evidence for imbalance at baseline in the confounders for the embodied well-being domain. We again restore balance using entropy weighting.

```{r}
#| label: fig-love-embodied
#| fig-cap: "Love plot for propensity score analysis: embodied domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

# read data
match_ebal_embodied  <- here_read("match_ebal_embodied")
# love plot
love_plot_match_ebal_embodied <- love.plot(match_ebal_embodied, size = 1, binary = "std", thresholds = c(m = .1))

love_plot_match_ebal_embodied + theme(
  plot.title = element_text(size = 10, hjust = 0),
  plot.subtitle = element_text(size = 10, hjust = 0),
  axis.text = element_text(size = 4),  # Adjust the size value as per your preference
  legend.text = element_text(size = 6),
  legend.title = element_text(size = 8)
) 

#cobalt::bal.tab(match_ebal_embodied, stats = c("m", "v"), binary = "std", thresholds = c(m = .05))
```

@fig-propensity-dis-embodied shows propensity score weights in the unexposed group (remained religiously affiliated) and the exposed group (disasffiated) in the embodied condition.

```{r}
#| label: fig-propensity-dis-embodied
#| fig-cap: "Distribution of propensity scores by condition: embodied domain"
#| out-width: 80%
#| eval: true
#| include: true
#| echo: false

summary_match_ebal_embodied <- summary( match_ebal_embodied )
plot(summary_match_ebal_embodied)



# + theme(
#   plot.title = element_text(size = 10, hjust = 0),
#   plot.subtitle = element_text(size = 10, hjust = 0),
#   axis.text = element_text(size = 4),  # Adjust the size value as per your preference
#   legend.text = element_text(size = 6),
#   legend.title = element_text(size = 8)
#) 
```

**Summary of propensity score weights: embodied well-being domain**

| **Group** | **Weight Range (Min - Max)** | **Top 5 Extreme Weights**         | **Coefficient of Variation** | **Unweighted Sample Size** | **Weighted Sample Size** |
|------------|------------|------------|------------|------------|------------|
| 0         | 0.767 - 1.338                | 1.266, 1.267, 1.294, 1.334, 1.338 | 0.072                        | 10623                      | 10568.710                |
| 1         | 0.218 - 3.734                | 3.309, 3.413, 3.543, 3.559, 3.734 | 0.446                        | 1977                       | 1648.660                 |

: Summary of propensity scores: embodied well-being domain. {#tbl-summary-propensity-embodied}

Table @tbl-summary-propensity-embodied presents the propensity score weights for the embodied well-being domain, as generated by the `WeightIt` package in R [@greifer2023]. The weight range for each group (Group 0 and Group 1) is provided, along with the five most extreme weights in each group.

The Coefficient of Variation (CoV) for each group is well below the threshold of 2, suggesting adequate weight variation. The CoV is lower for Group 0 (0.072), indicating less variation in weights compared to Group 1 (0.446).

The effective sample sizes, which represent the amount of information remaining in the weighted sample, are reported for both groups. These sizes are close to the original sample size per condition, implying that a substantial amount of the original data is retained in the propensity score analysis for the embodied well-being domain.

From the cobalt balance summary for the embodied wellbeing domain, we observe that all Mean Difference Adjusted values fall within the set threshold of 0.05, indicating an effective match across all variables.

We find a higher variance ratios for a few continuous variables. Particularly, `t0_household_inc_log_z` (household income, log transformed) has a minimum adjusted variance ratio of 1.2653, a mean of 1.3351, and a maximum of 1.4413. This suggests a substantial difference in the distribution of this variable between the control and treatment groups. Other notable variables include `t0_kessler_nervous_z` (Kessler scale measure for nervousness) with variance ratios from 1.0664 to 1.0787, and `t0_conscientiousness_z` (Conscientiousness scale) with variance ratios ranging from 1.0506 to 1.0647.

These higher variance ratios suggest that the matching procedure may not have balanced these specific variables as efficiently as others.

The average effective sample sizes across all imputations for the unadjusted group is 10623, and for the adjusted group it's 10568.65. For the group with id 1, the values are 1977 for the unadjusted and 1646.84 for the adjusted group.

### Propensity score analysis for practical well-being

@fig-love-practical shows strong evidence for imbalance at baseline in the confounders for the practical well-being domain. We again restore balance using entropy weighting.

```{r}
#| label: fig-love-practical
#| fig-cap: "Love plot for propensity score analysis: practical domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

# read data
match_ebal_practical  <- here_read("match_ebal_practical")


# love plot
love_plot_match_ebal_practical <- love.plot(match_ebal_practical,size = 1, binary = "std", thresholds = c(m = .1))

love_plot_match_ebal_practical + theme(
  plot.title = element_text(size = 10, hjust = 0),
  plot.subtitle = element_text(size = 10, hjust = 0),
  axis.text = element_text(size = 4),  # Adjust the size value as per your preference
  legend.text = element_text(size = 6),
  legend.title = element_text(size = 8)
) 

#cobalt::bal.tab(match_ebal_practical, stats = c("m", "v"), binary = "std", thresholds = c(m = .05))
```

@fig-propensity-dis-practical shows propensity score weights in the unexposed group (remained religiously affiliated) and the exposed group (disasffiliated) in the practical domain.

```{r}
#| label: fig-propensity-dis-practical
#| fig-cap: "Distribution of propensity scores by condition: practical domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

summary_match_ebal_practical <- summary( match_ebal_practical )
plot(summary_match_ebal_practical)



# + theme(
#   plot.title = element_text(size = 10, hjust = 0),
#   plot.subtitle = element_text(size = 10, hjust = 0),
#   axis.text = element_text(size = 4),  # Adjust the size value as per your preference
#   legend.text = element_text(size = 6),
#   legend.title = element_text(size = 8)
#) 
```

**Summary of propensity score weights: Practical well-being domain**

| **Group** | **Weight Range (Min - Max)** | **Top 5 Extreme Weights**         | **Coefficient of Variation** | **Unweighted Sample Size** | **Weighted Sample Size** |
|------------|------------|------------|------------|------------|------------|
| 0         | 0.722 - 1.552                | 1.445, 1.489, 1.521, 1.522, 1.552 | 0.084                        | 10623                      | 10547.770                |
| 1         | 0.123 - 4.651                | 3.412, 3.441, 3.512, 3.703, 4.651 | 0.524                        | 1977                       | 1551.890                 |

: Summary of propensity scores: practical domain. {#tbl-summary-propensity-practical}

@tbl-summary-propensity-practical summarises the propensity score weights generated through the `WeightIt` package in R [@greifer2023]. The weight range for each group (Group 0 and Group 1) show the five most extreme weights in each group.

The Coefficient of Variation (CoV) for each group is lower for Group 0 (0.084), indicating less variation in weights as compared to Group 1 (0.524). Both of these CoVs are below the threshold of 2.

The effective sample sizes are important indicators of the amount of information remaining in the weighted sample, that these sizes are again close to the original sample size by condition.

From the cobalt balance summary for the practical well-being domain, we observe that all Mean Difference Adjusted values fall within the set threshold of 0.05, indicating an effective match across all variables.

There is a higher variance ratio for the `t0_household_inc_log_z` (household income, log transformed) variable, with minimum, mean, and maximum adjusted variance ratios of 1.2710, 1.3091, and 1.3832, respectively. This indicates stronger differences in the distribution of this variable between the control and treatment groups. Another notable variable is `t0_conscientiousness_z` (Conscientiousness scale) with variance ratios ranging from 1.0443 to 1.0517.

These higher variance ratios suggest that the matching procedure may not have balanced these specific variables as effectively as others.

We also observe variables such as `t0_emotion_regulation_change_thinking_to_calm_z` that have a higher variance ratio, ranging from 1.0512 to 1.0715, indicating potential imbalances between the treatment and control groups for these variables.

The average effective sample sizes across all imputations for the unadjusted group is 10623, while for the adjusted group it's 10562.18. For the group with id 1, the values are 1977 for the unadjusted and 1602.26 for the adjusted group.

It should be noted that despite some variables showing higher variance ratios, the propensity score matching method has overall produced a reasonable match across most variables, ensuring comparability between the treatment and control groups.

### Propensity score analysis for reflective well-being

@fig-love-reflective shows strong evidence for imbalance at baseline in the confounders for the reflective well-being domain. We again restore balance using entropy weighting.

```{r}
#| label: fig-love-reflective
#| fig-cap: "Love plot for propensity score analysis: reflective domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

# read data
match_reflective_ebal <- here_read("match_reflective_ebal")

# love plot
love_plot_match_ebal_reflective <- love.plot(match_reflective_ebal,size = 1, binary = "std", thresholds = c(m = .1))

love_plot_match_ebal_reflective + theme(
  plot.title = element_text(size = 10, hjust = 0),
  plot.subtitle = element_text(size = 10, hjust = 0),
  axis.text = element_text(size = 4),  # Adjust the size value as per your preference
  legend.text = element_text(size = 6),
  legend.title = element_text(size = 8)
) 

#cobalt::bal.tab(match_reflective_ebal, stats = c("m", "v"), binary = "std", thresholds = c(m = .05))
```

@fig-propensity-dis-reflective shows propensity score weights in the unexposed group (remained religiously affiliated) and the exposed group (disasffiliated) in the reflective domain.

```{r}
#| label: fig-propensity-dis-reflective
#| fig-cap: "Distribution of propensity scores by condition: reflective domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

summary_match_ebal_reflective <- summary( match_reflective_ebal)
plot(summary_match_ebal_reflective)



# + theme(
#   plot.title = element_text(size = 10, hjust = 0),
#   plot.subtitle = element_text(size = 10, hjust = 0),
#   axis.text = element_text(size = 4),  # Adjust the size value as per your preference
#   legend.text = element_text(size = 6),
#   legend.title = element_text(size = 8)
#) 
```

**Summary of propensity score weights: reflective well-being domain**

| **Group** | **Weight Range (Min - Max)** | **Top 5 Extreme Weights**         | **Coefficient of Variation** | **Unweighted Sample Size** | **Weighted Sample Size** |
|------------|------------|------------|------------|------------|------------|
| 0         | 0.736 - 1.333                | 1.316, 1.318, 1.319, 1.327, 1.333 | 0.079                        | 10623                      | 10557.770                |
| 1         | 0.133 - 4.251                | 3.416, 3.717, 3.952, 4.084, 4.251 | 0.507                        | 1977                       | 1572.640                 |

: Summary of propensity scores: reflective well-being domain. {#tbl-summary-propensity-reflective}

The propensity score weights for the reflective well-being domain, as generated using the `WeightIt` package in R [@greifer2023], are summarized in @tbl-summary-propensity-reflective. For each group (Group 0 and Group 1), the weight range and the five most extreme weights are reported.

The Coefficient of Variation (CoV) for each group is below the threshold of 2, indicating satisfactory weight variation. The CoV for Group 0 (0.079) is lower than that of Group 1 (0.507), suggesting less variation in weights for Group 0.

The effective sample sizes, which are indicative of the amount of information retained in the weighted sample, are reported for both groups. The closeness of these sizes to the original sample size per condition suggests that the propensity score analysis for the reflective well-being domain maintains a substantial amount of the original data.

From the cobalt balance summary for the practical well-being domain, we observe that all Mean Difference Adjusted values for the given variables fall within the set threshold of 0.05, indicating an effective match across all variables.

There is a higher variance ratio for the `t0_household_inc_log_z` (household income, log transformed) variable, with minimum, mean, and maximum adjusted variance ratios of 1.3100, 1.3365, and 1.3771, respectively. This indicates stronger differences in the distribution of this variable between the control and treatment groups. Another notable variable is `t0_conscientiousness_z` (Conscientiousness scale) with variance ratios ranging from 1.0661 to 1.0754.

These higher variance ratios suggest that the matching procedure may not have balanced these specific variables as effectively as others.

The average effective sample sizes across all imputations for the unadjusted group is 10623, while for the adjusted group it's 10556.45. For the group with id 1, the values are 1977 for the unadjusted and 1561.71 for the adjusted group.

It should be noted that despite some variables showing higher variance ratios, the propensity score matching method has overall produced a reasonable match across most variables, ensuring comparability between the treatment and control groups.

### Propensity score analysis for social well-being

@fig-love-social shows strong evidence for imbalance at baseline in the confounders for the social well-being domain. We again restore balance using entropy weighting.

```{r}
#| label: fig-love-social
#| fig-cap: "Love plot for propensity score analysis: social domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

# read data
match_ebal_social  <- here_read("match_ebal_social")

# love plot
love_plot_match_ebal_social <- love.plot(match_ebal_social, size = 1, binary = "std", thresholds = c(m = .1))

love_plot_match_ebal_social + theme(
  plot.title = element_text(size = 10, hjust = 0),
  plot.subtitle = element_text(size = 10, hjust = 0),
  axis.text = element_text(size = 4),  # Adjust the size value as per your preference
  legend.text = element_text(size = 6),
  legend.title = element_text(size = 8)
) 

#bal.tab(match_ebal_social, stats = c("m", "v"), thresholds = c(m = .05))
#cobalt::bal.tab(match_ebal_social, stats = c("m", "v"), binary = "std", thresholds = c(m = .05))

```

@fig-propensity-dis-social shows propensity score weights in the unexposed group (remained religiously affiliated) and the exposed group (disasffiliated) in the practical domain.

```{r}
#| label: fig-propensity-dis-social
#| fig-cap: "Distribution of propensity scores by condition: practical domain"
#| out-width: 100%
#| eval: true
#| include: true
#| echo: false

summary_match_ebal_social <- summary( match_ebal_social )
plot(summary_match_ebal_social)



# + theme(
#   plot.title = element_text(size = 10, hjust = 0),
#   plot.subtitle = element_text(size = 10, hjust = 0),
#   axis.text = element_text(size = 4),  # Adjust the size value as per your preference
#   legend.text = element_text(size = 6),
#   legend.title = element_text(size = 8)
#) 
```

**Summary of propensity score weights: social well-being domain**

| **Group** | **Weight Range (Min - Max)** | **Top 5 Extreme Weights**         | **Coefficient of Variation** | **Unweighted Sample Size** | **Weighted Sample Size** |
|------------|------------|------------|------------|------------|------------|
| 0         | 0.635 - 1.384                | 1.338, 1.344, 1.346, 1.367, 1.384 | 0.092                        | 10623                      | 10533.970                |
| 1         | 0.109 - 7.830                | 5.951, 6.593, 7.317, 7.567, 7.830 | 0.696                        | 1977                       | 1332.110                 |

: Summary of propensity scores: social well-being domain. {#tbl-summary-propensity-social}

Table @tbl-summary-propensity-social summarizes the propensity score weights for the social well-being domain, generated using the `WeightIt` package in R [@greifer2023]. For each group (Group 0 and Group 1), it provides the weight range and the five most extreme weights.

The Coefficient of Variation (CoV) for each group is beneath the threshold of 2, denoting an acceptable weight variation. The CoV for Group 0 (0.092) is lower than that for Group 1 (0.696), indicating less variation in weights within Group 0.

The effective sample sizes are indicators of the quantity of information retained in the weighted sample. These sizes are close to the original sample size for each group, suggesting that the propensity score analysis for the social well-being domain maintains a substantial portion of the original data.

From the cobalt balance summary for the social well-being domain, we observe that all Mean Difference Adjusted values fall within the set threshold of 0.05, indicating an effective match across all variables.

The variable `t0_household_inc_log_z` (household income, log transformed) presents a higher variance ratio, with minimum, mean, and maximum adjusted variance ratios of 1.7122, 1.8119, and 2.1191 respectively, indicating stronger differences in the distribution of this variable between the control and treatment groups. Another notable variable is `t0_conscientiousness_z` (Conscientiousness scale) with variance ratios ranging from 1.0457 to 1.0604.

Moreover, there are other continuous variables with a higher variance ratio like `t0_permeability_individual_z` with a variance ratio ranging from 1.0997 to 1.1324, and `t0_hours_charity_z` with variance ratios ranging from 1.0735 to 1.2059.

These higher variance ratios suggest that the matching procedure may not have balanced these specific variables as effectively as others.

The average effective sample sizes across all imputations for the unadjusted group is 10623, while for the adjusted group it's 10533.21. For the group with id 1, the values are 1977 for the unadjusted and 1327.73 for the adjusted group.

It should be noted that despite some variables showing higher variance ratios, the propensity score matching method has overall produced a reasonable match across most variables, ensuring comparability between the treatment and control groups.

{{< pagebreak >}}

## Appendix D. Multiple comparisons in outcomewide studies {.appendix}

The concern for multiple comparisons is legitimate in many research settings. However, there are compelling reasons not to adjust for it in the case of outcome-wide science, as proposed by Tyler VanderWeele [@vanderweele2020].

1.  **Nature of the analysis:** Outcome-wide studies are inherently exploratory. They aim to generate hypotheses rather than testing pre-specified ones. In such a scenario, adjusting for multiple comparisons is out of place. Such testing might limit our ability to discover.

2.  **False negatives vs. false positives:** Adjusting for multiple comparisons often results in an increased risk of Type II errors (false negatives). In the context of public health, false negatives could be more problematic than false positives. We might overlook potentially significant associations that could lead to beneficial interventions.

3.  **Independence of outcomes:** The standard corrections for multiple comparisons, such as the Bonferroni or the Holm method, assume that tests are independent. In an outcome-wide study, outcomes are likely to be correlated, so these corrections could be overly conservative.

4.  **Magnitude of effects:** Outcome-wide studies do not only focus on p-values, but also the magnitude of effects, confidence intervals, and their scientific or clinical significance. We advocate assessing E-values, or unmeasured confounding, in place of assessing p-values. Adjusting for multiple comparisons focuses primarily on p-values, potentially undermining the importance of effect sizes. P-values are often a measure of sample size.

5.  **Replication and robustness:** Findings from outcome-wide studies are not intended to be conclusive, but rather to guide further research. Consequently, potential false positives should be addressed in future replication studies and through robustness checks.

For for outcome-wide studies, then, p-value corrections may limit the capacity to generate new hypotheses, increase the risk of missing potential public health interventions, and over-emphasize p-values at the expense of sensitivity analyses and E-values. In causal inference, the main worry is assessing the robustness of results to unmeasured confounding.

{{< pagebreak >}}

## Appendix E. Population Average Treatment Effect {.appendix}

As indicated in the main manuscript, the Average Treatment Effects is obtained by contrasting the expected outcome when a population sampled is exposed to an exposure level, $E[Y(A = a)]$, with the expected outcome under a different exposure level, $E[Y(A=a')]$.

For a binary treatment with levels $A=0$ and $A=1$, the Average Treatment Effect (ATE), on the difference scale, is expressed:

$$ATE_{\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]$$

On the risk ratio scale, the ATE is expressed:

$$ATE_{\text{risk ratio}} = \frac{E[Y(1)|L]}{E[Y(0)|L]}$$

Other effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest.

Here we estimate the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the New Population if applied universally. This quantity can be expressed:

$$PATE_{\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)$$

$$PATE_{\text{risk ratio}} = f\left(\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\right)$$

where $f$ is a function that incorporates post-stratification weights $W$ into the estimation of the expected outcomes from which we obtain causal contrasts. Because the NZAVS is national probability sample, i.e. inverse probability of being sampled 1. However, to incorporate gender, age, and ethnic differences we include post-stratification weight into our outcome wide models.

## References {.appendix}
