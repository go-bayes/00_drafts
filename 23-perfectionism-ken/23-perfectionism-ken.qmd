---
title: "Outcome-Wide Perfectionism"
subtitle: ""
abstract: |
  Perfectly counterfactual
author: 
  - name:  Ken Rice
    affiliation: Georgia State University 
  - name: Don E. Davis
    affiliation: Georgia State University
    orcid_id: 0000-0003-3169-6576 
  - name: Geoffrey Troughton
    affiliation: Victoria University of Wellington
    orcid_id: 0000-0001-7423-0640
  - name          : Chris G. Sibley
    affiliation   : School of Psychology, University of Auckland
    orcid_id: 0000-0002-4064-8800
  - name: Joseph Bulbulia
    orcid: 0000-0002-5861-2056
    affiliation: Victoria University of Wellington, New Zealand
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: no
execute:
  
  warning: false
  eval: false
keywords:
  - Read me
  - Cite me
  - Love me
date: last-modified
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: false

# key functions
# create_wide_data <- function(dat_long, baseline_vars, exposure_var, outcome_vars, exclude_vars = c()) {
#   require(tidyverse)
#   # Add the 'time' column to the data
#   data_with_time <- dat_long %>%
#     mutate(time = as.numeric(wave) - 1) %>%
#     arrange(id, time)
# 
#   # Filter the data based on the time condition
#   data_filtered <- data_with_time %>%
#     filter(time >= 0)
# 
#   # Create the wide data frame
#   wide_data <- data_filtered %>%
#     dplyr::select(-exclude_vars)  %>%  # Exclude specified variables
#     pivot_wider(
#       id_cols = id,
#       names_from = time,
#       values_from = -c(id, time),
#       names_glue = "t{time}_{.value}",
#       names_prefix = "t"
#     )
# 
#   # Define a custom function to filter columns based on conditions
#   custom_col_filter <- function(col_name) {
#     if (startsWith(col_name, "t0_")) {
#       return(col_name %in% c(paste0("t0_", baseline_vars),  paste0("t0_", exposure_var), paste0("t0_", outcome_vars)))
#     } else if (startsWith(col_name, "t1_")) {
#       return(col_name %in% paste0("t1_", exposure_var))
#     } else if (startsWith(col_name, "t2_")) {
#       return(col_name %in% paste0("t2_", outcome_vars))
#     } else if (startsWith(col_name, "t3_")) {
#       return(col_name %in% paste0("t3_", outcome_vars))
#     } else {
#       return(FALSE)
#     }
#   }
# 
#   # Apply the custom function to select the desired columns
#   wide_data_filtered <- wide_data %>%
#     dplyr::select(id, which(sapply(colnames(wide_data), custom_col_filter))) %>%
#     dplyr::relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
#     dplyr::relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
#     dplyr::relocate(starts_with("t3_"), .after = starts_with("t2_"))  %>%
#     arrange(id)%>%
#     select(-id)
# 
#   return(wide_data_filtered)
# }


# uncomment and use these links to load your functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/libs2.R")

# # read functions
# source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")


# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23_perfectionism_ken"
  )

# read data: note that you need use the arrow package in R
dat <- arrow::read_parquet(pull_path)

# for use
#dat<- data.frame(dat)

# count unique individuals
skimr::n_unique(dat$id)

# another way to count: doesn't require skimr
length(unique(dat$id))

# count participants by wave
dat |> 
  dplyr::filter(year_measured == 1) |>
  droplevels() |>
  dplyr::group_by(wave) |> 
  dplyr::count(wave)

# sampling by years
dat |> 
  dplyr::filter(year_measured == 1) |>
  droplevels() |>
  dplyr::count(sample_origin_year)


# more description 

# how many in 2018
dat |>
  filter(wave == 2018 & year_measured==1) |>
  select(hours_work, gender3, id, wave) |>
  drop_na() |>
  summarise(count_distinct = n_distinct(id))



table(dat$gender3)
# perfectionism in 2018
# graph of gender x perfectionism
dev.off()
dt_graph  <- dat |>
  filter(any(wave == 2018 & year_measured == 1))|>
  select(perfectionism, male, id, wave) |>
  drop_na() 
dev.off()
dev.off()
dt_graph |> 
  ggplot(aes(x = male, y = perfectionism, colour = male)) +
  geom_boxplot(notch = TRUE) + geom_jitter(shape = 16,
                                           position = position_jitter(0.2),
                                           alpha = .1) + 
  labs(title = "Perfectionism by Gender: NZAVS years 2018-2019, N = 47823", y = "Doing my best never seems to be enough.\nMy performance rarely measures up to my standards.\nI am hardly ever satisfied with my performance.", x = "Male coded as 1, other identities coded as 0") + 
  scale_color_viridis_d(option = "D")
# graph of religious x perfectionism 
dat |>
  filter(any(wave == 2018 & year_measured==1)) |>
  select(perfectionism, religious_identification_level, id, wave) |>
  mutate(religious_identification = as.factor(religious_identification_level)) |>
  drop_na() |>
  ggplot(aes(x=as.factor(religious_identification_level), y= perfectionism, colour = factor(religious_identification_level))) +
  geom_boxplot(notch = TRUE) + geom_jitter(shape=16, position=position_jitter(0.2), alpha = .1) + labs(
    title = "Perfectionism by religious_identification: NZAVS years 2018-2019, N = 47823",
    y = "Doing my best never seems to be enough.\nMy performance rarely measures up to my standards.\nI am hardly ever satisfied with my performance.",
    x = "Male coded as 1, other identities coded as 0") + scale_color_viridis_d(option = "D")

```


```{r}
#| label: clean data
#| echo: false
#| include: false
#| eval: false

# Variable 

#Occupational prestige/status
#NZSEI06 (NZ Socio-economic index) Milne, B. J., Byun, U., & Lee, A. (2013). New Zealand socio-economic index 2006. Wellington: Statistics New Zealand.
#NZSEI13 (NZ Socio-economic index) Fahy, K. M., Lee, A., & Milne, B. J. (2017). New Zealand socio-economic index 2013. Wellington: Statistics New Zealand.
#NZSEI18 (NZ Socio-economic index) Boven, N., Shackleton, N., Bolton, L., Milne, B. (2021). The 2018 New Zealand Socioeconomic Index (NZSEI-19): A brief technical summary. Compass Research Centre.

# Measures of Perfectionism: 
# 
# * "Doing my best never seems to be enough."
# * "My performance rarely measures up to my standards."
# * "I am hardly ever satisfied with my performance."

# In general, I have a lot of self-control.
# I wish I had more self-discipline.
# #Please estimate your total household income (before tax) for the last year.

# we might look at movement from <4 to >= 4. 
# ask ken
hist(dat$perfectionism, breaks = 100)


  
# Calculate the quantile breaks (cut points)
quantile_breaks <- quantile(dat$perfectionism, probs = seq(0, 1, 1/4), na.rm = TRUE)
cut_labels

# Create labels based on the cut points in the desired format
cut_labels <- paste0(quantile_breaks[-length(quantile_breaks)], "_", quantile_breaks[-1])

# Create the ordered factor variable with the new labels
dat$perfectionism_quartile <- cut(dat$perfectionism,
                                        breaks = quantile_breaks,
                                        labels = cut_labels,
                                        ordered_result = TRUE,
                                        include.lowest = TRUE)

# Print the resulting data frame
print(dat$perfectionism_quartile)


# vars
hist(dat$perfectionism, breaks = 100)

dev.off()

# hist
table(dat$perfectionism_quartile)

# quantile for exposure
labels(dat$perfectionism_quartile)

levels(dat$perfectionism_quartile)

# Print the resulting data frame
table(dat$perfectionism_quartile)
levels(dat$perfectionism_quartile)



# 
# ReligiousAtts01r.T10	I oppose religion in any form.
# ReligiousAtts02.T10	All things considered, religion is a cause for good in the world.
# ReligiousAtts03.T10	The teachings of traditional religions are still helpful today.


# HLTH.SFHealth01.T10	In general, would you say your health is...
# HLTH.SFHealth02r.T10	I seem to get sick a little easier than other people.
# HLTH.SFHealth03r.T10	I expect my health to get worse.

# Perc.Discrim.T10	Feel that I am often discriminated against because of my ethnicity.
# Perc.Gend.Discrim.T10	Feel that I am often discriminated against because of my gender.
# Perc.Religious.Discrim.T10	I feel that I am often discriminated against because of my religious/spiritual beliefs.

#dat$religious_attack


dat_long <- dat |> 
  arrange(id, wave) |> 
    # select variables 
  mutate(religion_church_binary = ifelse(religion_church > 0, 1, 0)) |> 
  mutate(perfectionism_high = ifelse(perfectionism > 4, 1, 0 )) |> 
  rename(religion_religious = religious) |> 
  select(
    "wave",
    "year_measured",
    "sample_frame",
    "id",
    "edu",
    "male",
    "eth_cat", #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed", # Are you currently employed? (this includes self-employment or casual work)
    "gen_cohort", #What is your gender? (open-ended)
    "household_inc", # Please estimate your total household income (before tax) for the last year.
    "nz_dep2018",
    "nzsei13",
    "partner",
    "parent",
    "pol_orient", #Please rate how politically liberal versus conservative you see yourself as being.
    "pol_wing", # Please rate how politically left-wing versus right-wing you see yourself as being.
    "rural_gch2018",
    "sdo",
    "rwa",
    "brk_relationship",
    "began_relationship",
    "agreeableness",
    "conscientiousness",
    "extraversion",
    "honesty_humility",
    "openness",
    "neuroticism",
    "modesty", # I want people to know that I am an important person of high status, I am an ordinary person who is no better than others. , I wouldn’t want people to treat me as though I were superior to them. I think that I am entitled to more respect than the average person is.
    "religion_religious", # Do you identify with a religion and/or spiritual group?
    "religion_identification_level", #How important is your religion to how you see yourself?"
    "religion_church_binary",
    "religion_prayer", # How many times did you pray in the last week?
    "religion_scripture", # How many times did you read religious scripture in the last week?
    "religion_church2", # How many times did you attend a church or place of worship in the last month?
    "religion_believe_spirit",#Do you believe in some form of spirit or lifeforce?
    "religion_believe_god",#Do you believe in a God
    "religion_spiritual_identification", #w8,w10,w12-13 "I identify as a spiritual person."
    "religion_perceive_religious_discrim", #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
    "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers 
    "w_gend_age_euro", # sample_weights
    "alcohol_frequency", #"How often do you have a drink containing alcohol?"
    "alcohol_intensity", # How many drinks containing alcohol do you have on a typical day when drinking?
    "hlth_bmi", # " What is your height? (metres)\nWhat is your weight? (kg)\nKg 
    "hours_exercise", # Hours spent … exercising/physical activity
   # "sfhealth", 
    "sfhealth_your_health",# "In general, would you say your health is...
    "sfhealth_get_sick_easier",#\nI seem to get sick a little easier than other people.
    "sfhealth_expect_worse_health",#\nI expect my health to get worse." ****
    "hlth_sleep_hours", #During the past month, on average, how many hours of actual sleep did you get per night?
    "smoker",#Do you currently smoke?
    "hlth_fatigue", #During the last 30 days, how often did.... you feel exhausted?
    "rumination",# During the last 30 days, how often did.... you have negative thoughts that repeated over and over?
    "kessler_depressed", #During the last 30 days, how often did.... you feel so depressed that nothing could cheer you up?
    "kessler_effort",#During the last 30 days, how often did.... you feel that everything was an effort?
    "kessler_hopeless",# During the last 30 days, how often did.... you feel hopeless?
    "kessler_nervous",#During the last 30 days, how often did.... you feel nervous?
    "kessler_restless", #During the last 30 days, how often did.... you feel restless or fidgety?
    "kessler_worthless",# During the last 30 days, how often did.... you feel worthless?
    "sexual_satisfaction", #  How satisfied are you with your sex life?
    "bodysat", ## Am satisfied with the appearance, size and shape of my body.
    "vengeful_rumin",# Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
    "perfectionism",  # # Doing my best never seems to be enough./# My performance rarely measures up to my standards.
# I am hardly ever satisfied with my performance.
    "power_self_nocontrol",# I do not have enough power or control over\nimportant parts of my life.
    "power_others_control", # Other people have too much power or control over\nimportant parts of my life
    "selfesteem_satself", #  On the whole am satisfied with myself.
    "selfesteem_postiveself",# Take a positive attitude toward myself
    "selfesteem_rfailure", # Am inclined to feel that I am a failure.
    "self_control_have_lots",#In general, I have a lot of self-control.
    "self_control_wish_more_r",#I wish I had more self-discipline.(r)
    "emotion_regulation_out_control", # When I feel negative emotions, my emotions feel out of control. w10 - w13
    "emotion_regulation_hide_neg_emotions", # When I feel negative emotions, I suppress or hide my emotions. w10 - w13
    "emotion_regulation_change_thinking_to_calm", # When I feel negative emotions, I change the way I think to help me stay calm. w10 - w13
    "emp_work_life_balance",# I have a good balance between work and other important things in my life.
    "gratitude", ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of people.
    "pwi_health",#Your health.
    "pwi_relationships",#Your personal relationships.
    "pwi_security",#Your future security.
    "pwi_standardliving",#Your standard of living.
    "lifesat_satlife",# I am satisfied with my life.
    "lifesat_ideal",# In most ways my life is close to ideal.
    "meaning_purpose",# My life has a clear sense of purpose.
    "meaning_sense",# I have a good sense of what makes my life meaningful.
    "perfectionism_high", # > 4
    "perfectionism_quartile", # quartile cuts: 
    "permeability_individual",#I believe I am capable, as an individual\nof improving my status in society.
    "impermeability_group", #The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change.
    "neighbourhood_community", #I feel a sense of community with others in my local neighbourhood.
    "support_help",# 'There are people I can depend on to help me if I really need it.
    "support_turnto",# There is no one I can turn to for guidance in times of stress.
    "support_rnoguidance", #There is no one I can turn to for guidance in times of stress.
    "belong_accept", #Know that people in my life accept and value me.
    "belong_routsider",# Feel like an outsider.
    "belong_beliefs",# Know that people around me share my attitudes and beliefs.
    "charity_donate",#How much money have you donated to charity in the last year?
    "hours_charity",#Hours spent in activities/Hours spent … voluntary/charitable work
    "nwi" # The economic situation in New Zealand./# The social conditions in New Zealand. # Business in New Zealand.
  ) |> 
  # rename(emotion_regulation_out_control = emotion_regulation1,
  #        emotion_regulation_hide_neg_emotions = emotion_regulation2,
  #        emotion_regulation_change_thinking_to_calm = emotion_regulation3) |> 
   dplyr::rename(sample_weights = w_gend_age_euro) |> 
   dplyr::filter((wave == 2018 & year_measured  == 1) |
                  (wave == 2019  &
                     year_measured  == 1) |
                  (wave == 2020)| 
                  (wave ==2021) ) |>  # Eligibility criteria  Observed in 2018/2019 & Outcomes in 2020 or 2021
  group_by(id) |>
  dplyr::mutate(k_18 =  ifelse(wave == 2018 &
                                !is.na(perfectionism), 1, 0)) |>   # creating an indicator for the first wave
  dplyr::mutate(h_18 = mean(k_18, na.rm = TRUE)) |>   # Hack
  dplyr::mutate(k_19 =  ifelse(wave == 2019 &
                                 year_measured == 1 &
                                  !is.na(perfectionism) == 1, 1, 0)) |>   # creating an indicator for the first wave; note that we allow people t
  dplyr::mutate(h_19 = mean(k_19, na.rm = TRUE)) |>  # Hack
  dplyr::filter(h_18 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_19 > 0) |>  # hack to enable repeat of baseline
  mutate(perfectionism_low_became_high =  # exposure
           as.factor(ifelse(((wave == 2019 & perfectionism_high == 0) &
                               (wave == 2019 &  lag(perfectionism_high == 1))
           ), 1, 0))) |>
  mutate(perfectionism_high_same =  # exposure
           as.factor(ifelse(((wave == 2019 & perfectionism_high == 1) &
                               (wave == 2019 & lag(perfectionism_high == 1))
           ), 1, 0))) |>
  mutate(perfectionism_high_became_low =  # exposure
           as.factor(ifelse(((wave == 2019 & perfectionism_high == 1) &
                               (wave == 2019 & lag(perfectionism_high == 0))
           ), 1, 0))) |>
  mutate(perfectionism_low_same =  # exposure
           as.factor(ifelse(((wave == 2019 & perfectionism_high == 0) &
                               (wave == 2019 & lag(perfectionism_high == 0))
           ), 1, 0))) |>
  ungroup() |>
  mutate(perfectionism_change = case_when(
    perfectionism_low_became_high == 1 ~ "perfectionism_low_became_high",
    perfectionism_high_same == 1 ~ "perfectionism_high_same",
    perfectionism_high_became_low == 1 ~ "perfectionism_high_became_low",
    perfectionism_low_same == 1 ~ "perfectionism_low_same"
    #TRUE ~ "Unknown"  # This line is optional and used for cases that don't match any of the specified conditions
  )) |> 
   mutate(perfectionism_change = factor(
    perfectionism_change,
    levels = c(
      "perfectionism_low_same",
      "perfectionism_high_same",
      "perfectionism_high_became_low",
      "perfectionism_low_became_high"
    ),
    ordered = FALSE
  )) |> 
  droplevels() |> 
  select(-c("h_19", "k_19", "h_18", "k_18")) #34762


length(unique(dat_long$id))# 34762

dt_19 <- dat_long |> 
  filter(wave == "2019")

table(dat_long$perfectionism_change)
table(dt_19$perfectionism_change)

table(dat_long$perfectionism_became_low)
# check change

## check numbers of those changed
ds_18 <- dat_long |>
  select(id, perfectionism_high, perfectionism, perfectionism_quartile,perfectionism_change) |>
  mutate(perfectionism_high = as.numeric(perfectionism_high) ) |> 
  mutate(perfectionism_quartile = as.numeric(perfectionism_quartile) - 1) |> # 740
  mutate(perfectionism_change = as.numeric(perfectionism_change) ) # 740


table(ds_18$perfectionism_high)


# check: finds same numbers
msm::statetable.msm(round(perfectionism, 0), id, data = ds_18) |>
  kbl() |>
  kable_paper(full_width = F)


# three years
msm::statetable.msm(round(perfectionism_high, 0), id, data = ds_18) |>
  kbl() |>
  kable_paper(full_width = F)


# this looks best
msm::statetable.msm(round(perfectionism_quartile, 0), id, data = ds_18) |>
  kbl() |>
  kable_paper(full_width = F)




## select variables for domains of outcome
## always to be determined with expert

# comment out what makes sense for a study
# household income not a great measurement

baseline_vars = c(
    "edu",
    "male",
    "eth_cat", #factor(EthCat, labels = c("Euro", "Maori", "Pacific", "Asian")),
    "employed", # Are you currently employed? (this includes self-employment or casual work)
    "gen_cohort", #What is your gender? (open-ended)
   # "household_inc", # Please estimate your total household income (before tax) for the last year.
    "nz_dep2018",
    "nzsei13",
    "partner",
    "parent",
    "pol_orient", #Please rate how politically liberal versus conservative you see yourself as being.
    #"pol_wing", # Please rate how politically left-wing versus right-wing you see yourself as being.
    "rural_gch2018",
   # "sdo",
   # "rwa",
   # "brk_relationship",
   # "began_relationship",
    "agreeableness",
    "conscientiousness",
    "extraversion",
    "honesty_humility",
    "openness",
    "neuroticism",
    "modesty", # I want people to know that I am an important person of high status, I am an ordinary person who is no better than others. , I wouldn’t want people to treat me as though I were superior to them. I think that I am entitled to more respect than the average person is.
    "religion_religious", # Do you identify with a religion and/or spiritual group?
    "religion_identification_level", #How important is your religion to how you see yourself?"
    "religion_church_binary" #,
   # "religion_prayer", # How many times did you pray in the last week?
   # "religion_scripture", # How many times did you read religious scripture in the last week?
   # "religion_church2", # How many times did you attend a church or place of worship in the last month?
  #  "religion_believe_spirit",#Do you believe in some form of spirit or lifeforce?
  #  "religion_believe_god",#Do you believe in a God
   # "religion_spiritual_identification", #w8,w10,w12-13 "I identify as a spiritual person."
   # "religion_perceive_religious_discrim", #	I feel that I am often discriminated against because of my religious/spiritual beliefs.
  #  "bigger_doms", #What religion or spiritual group?#  Not_Rel, Anglican , Buddist, Catholic , Christian_nfd, Christian_Others, Hindu, Jewish           Muslim, PresbyCongReform, TheOthers 
)

exposure_var = c("perfectionism", "perfectionism_high") # we could construct this after imputation

outcome_vars_health = c(
    "alcohol_frequency",
    "alcohol_intensity",
    "hlth_bmi",
    "hours_exercise",
    "sfhealth_your_health",# "In general, would you say your health is...
    "sfhealth_get_sick_easier",#\nI seem to get sick a little easier than other people.
    "sfhealth_expect_worse_health",
    "hlth_sleep_hours",
    "smoker"
  )

outcome_vars_embodied = c(
    "hlth_fatigue",
    "rumination",
    "kessler_depressed",
    "kessler_effort",
    "kessler_hopeless",
    "kessler_nervous",
    "kessler_restless",
    "kessler_worthless"
  )

rm(outcome_vars_social)

# nzsei
outcome_vars_practical = c(
    "nzsei13", # objective job success
    "bodysat", ## Am satisfied with the appearance, size and shape of my body.
    "vengeful_rumin",# Sometimes I can't sleep because of thinking about past wrongs I have suffered.//# I can usually forgive and forget when someone does me wrong.# I find myself regularly thinking about past times that I have been wronged.
   # "perfectionism",  # # Doing my best never seems to be enough./# My performance rarely measures up to my standards.
# I am hardly ever satisfied with my performance.
    "power_self_nocontrol",# I do not have enough power or control over\nimportant parts of my life.
    "power_others_control", # Other people have too much power or control over\nimportant parts of my life
    "selfesteem_satself", #  On the whole am satisfied with myself.
    "selfesteem_postiveself",# Take a positive attitude toward myself
    "selfesteem_rfailure", # Am inclined to feel that I am a failure.
    "self_control_have_lots",#In general, I have a lot of self-control.
    "self_control_wish_more_r",#I wish I had more self-discipline.(r)
     "emotion_regulation_out_control", # When I feel negative emotions, my emotions feel out of control. w10 - w13
    "emotion_regulation_hide_neg_emotions", # When I feel negative emotions, I suppress or hide my emotions. w10 - w13
    "emotion_regulation_change_thinking_to_calm", # When I feel negative emotions, I change the way I think to help me stay calm. w10 - w13
    "emp_work_life_balance"# I have a good balance between work and other important things in my life.
  )
  
outcome_vars_reflective = c(
    "gratitude", ## I have much in my life to be thankful for. # When I look at the world, I don’t see much to be grateful for. # I am grateful to a wide variety of people.
    "pwi_health",#Your health.
    "pwi_relationships",#Your personal relationships.
    "pwi_security",#Your future security.
    "pwi_standardliving",#Your standard of living.
    "lifesat_satlife",# I am satisfied with my life.
    "lifesat_ideal",# In most ways my life is close to ideal.
    "meaning_purpose",# My life has a clear sense of purpose.
    "meaning_sense"# I have a good sense of what makes my life meaningful.
  )


outcome_vars_social = c(
    "permeability_individual",#I believe I am capable, as an individual\nof improving my status in society.
    "impermeability_group", #The current income gap between New Zealand Europeans and other ethnic groups would be very hard to change.
    "neighbourhood_community", #I feel a sense of community with others in my local neighbourhood.
    "support_help",# 'There are people I can depend on to help me if I really need it.
    "support_turnto",# There is no one I can turn to for guidance in times of stress.
    "support_rnoguidance", #There is no one I can turn to for guidance in times of stress.
    "belong_accept", #Know that people in my life accept and value me.
    "belong_routsider",# Feel like an outsider.
    "belong_beliefs",# Know that people around me share my attitudes and beliefs.
    "charity_donate",#How much money have you donated to charity in the last year?
    "hours_charity"#,#Hours spent in activities/Hours spent … voluntary/charitable work
  #  "nwi" # The economic situation in New Zealand./# The social conditions in New Zealand. # Business in New Zealand.
  )


exclude_vars = c("year_measured")


# data for mice
prep_health <- create_wide_data(dat_long, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_health)

head(prep_health)
str(prep_health)
nrow(prep_health)


prep_embodied <- create_wide_data(dat_long, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_embodied)

str(prep_embodied)

prep_practical <- create_wide_data(dat_long, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_practical)

str(prep_practical)

prep_reflective <- create_wide_data(dat_long, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_reflective)

str(prep_reflective)

prep_social <- create_wide_data(dat_long, 
  baseline_vars = baseline_vars, 
  exposure_var = exposure_var,
  outcome_vars = outcome_vars_social)

str(prep_social)

```


```{r}
#| label: tables
#| echo: false
#| include: false
#| eval: false


# only look at vars at baseline
dat_18 <- dat_long |> 
  dplyr::filter(wave == 2018)

# check consistent n's
colnames(prep_health)

  
#table
# functions for table
my_render_cont <- function(x) {
  with(stats.apply.rounding(stats.default(x), digits=3), c("",
                                                           "Mean (SD)"=sprintf("%s (&plusmn; %s)", MEAN, SD)))
}

my_render_cat <- function(x) {
  c("", sapply(stats.default(x), function(y) with(y,
                                                  sprintf("%d (%0.0f %%)", FREQ, PCT))))
}


table_baseline_vars <- paste(baseline_vars, collapse = "+")
formula_string_table_baseline <- paste("~", table_baseline_vars, "|wave")

#formula_string <- paste("~", output_string)
formula_obj_baseline <- as.formula(formula_string_table_baseline)


# baseline table 
table_baseline  <-
  table1::table1(
    formula_obj_baseline,
    data = dat_18,
    overall = FALSE,
    render.continuous = my_render_cont,
    render.categorical = my_render_cat
  )


# make demographic tablem markdown
table_baseline |> 
  as.data.frame() |> 
  kbl(format = "markdown")


# can do for others...
```


```{r}
#| label: imputations health
#| echo: false
#| include: false
#| eval: false

# reduce missingness by looking at +2 only , and remove factor for faster imputation
prep_health_2only <- prep_health |> 
  select(-starts_with("t3_")) |> 
  mutate(across(where(is.double), as.numeric)) |> 
  mutate(t0_male = as.numeric(t0_male)-1) |> 
  mutate(t0_religion_religious = as.numeric(t0_religion_religious)-1) |>
  mutate(t0_rural_gch2018 = as.integer(as.factor(t0_rural_gch2018)))
# check
str(prep_health_2only)

dev.off()
# health
naniar::vis_miss(prep_health_2only, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_health_2only)



# prep factors remove for speed


## impute missing variables
mice_health  <- mice::mice(prep_health_2only, m = 10)

# save imputations
saveRDS(mice_health,
        here::here(push_mods, "mice_health"))

# recall imputations if needed
mice_health <-
  readRDS(here::here(push_mods, "mice_health"))


# check mi model
outlist2 <-row.names(mice_health)[mice_health$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_health$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_health, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

N <- length(vnames)/nrow(prep_health_2only) # (11 datasets)



# if we need weights
newdat <- data.frame( rep(dat_18$sample_weights, N))

colnames(newdat) <- "sample_weights"

# check
nrow(newdat) == nrow(mc)

mc_v <- bind_cols(newdat, mc ) |>
  relocate("sample_weights", .before = starts_with("t0_"))

# checks out

# comment out if using weights with the above code

skimr::skim(mc_v)

n_id <- nrow(dat_18) # number of ids
# n_id_3 = 3 * n_id # made long so need 3 x N # three waves

outcome_vars_health

ml_health<- mc_v %>%
  dplyr::mutate(id = as.factor(rep(1:n_id, 11))) |> # needed 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
         t0_rural_gch2018 = as.factor(t0_rural_gch2018),
         t0_smoker = as.factor(t0_smoker),
         t1_perfectionism_high = as.factor(t1_perfectionism_high),
         t2_smoker = as.factor(t2_smoker),
         t0_hours_exercise = log(t0_hours_exercise +1),
         t2_hours_exercise =  log(t2_hours_exercise +1)) |>
  dplyr::group_by(id) |>
  dplyr::mutate(t0_sfhealth = mean(
    c(
      t0_sfhealth_your_health,
      t0_sfhealth_get_sick_easier,
      t0_sfhealth_expect_worse_health  ),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_sfhealth = mean(
    c(
      t2_sfhealth_your_health,
      t2_sfhealth_get_sick_easier,
      t2_sfhealth_expect_worse_health  ),
    na.rm = TRUE
  )) |>
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()
  

# Confirm that ml is of class "mids"
class(ml_health)
str(ml_health)

mf_health <- mice::complete(ml_health, "long", inc = TRUE)

str(mf_health)
colnames(mf_health)
# test
head(mf_health$sample_weights)
str(dat_18$sample_weights)

saveRDS(ml_health, here::here(push_mods, "ml_health"))
saveRDS(mf_health, here::here(push_mods, "mf_health"))
```

```{r}
#| label: imputations embodied
#| echo: false
#| include: false
#| eval: false

#| label: imputations health
#| echo: false
#| include: false
#| eval: false

# reduce missingness by looking at +2 only , and remove factor for faster imputation
prep_embodied_2only <- prep_embodied |> 
  select(-starts_with("t3_")) |> 
  mutate(across(where(is.double), as.numeric)) |> 
  mutate(t0_male = as.numeric(t0_male)-1) |> 
  mutate(t0_religion_religious = as.numeric(t0_religion_religious)-1) |>
  mutate(t0_rural_gch2018 = as.integer(as.factor(t0_rural_gch2018)))
# check
str(prep_embodied_2only)

dev.off()
# health
naniar::vis_miss(prep_embodied_2only, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_embodied_2only)



# prep factors remove for speed

## impute missing variables
mice_embodied  <- mice::mice(prep_embodied_2only, m = 10)

# save imputations
saveRDS(mice_embodied,
        here::here(push_mods, "mice_embodied"))

# recall imputations if needed
mice_embodied <-
  readRDS(here::here(push_mods, "mice_embodied"))


# check mi model
outlist2 <-row.names(mice_embodied)[mice_embodied$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_embodied$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_embodied, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

N <- length(vnames)/nrow(prep_embodied_2only) # (11 datasets)



# if we need weights
newdat <- data.frame( rep(dat_18$sample_weights, N))

colnames(newdat) <- "sample_weights"

# check
nrow(newdat) == nrow(mc)

mc_v <- bind_cols(newdat, mc ) |>
  relocate("sample_weights", .before = starts_with("t0_"))

# checks out

# comment out if using weights with the above code

skimr::skim(mc_v)

n_id <- nrow(dat_18) # number of ids
# n_id_3 = 3 * n_id # made long so need 3 x N # three waves

outcome_vars_embodied

ml_embodied<- mc_v %>%
  dplyr::mutate(id = as.factor(rep(1:n_id, 11))) |> # needed 
  mutate( 
         t0_eth_cat = as.factor(t0_eth_cat),
         t0_rural_gch2018 = as.factor(t0_rural_gch2018),
         t1_perfectionism_high = as.factor(t1_perfectionism_high)) |>
  dplyr::group_by(id) |>
  dplyr::mutate(t0_kessler_6 = mean(
    c(
    t0_kessler_depressed,
    t0_kessler_effort,
    t0_kessler_hopeless,
    t0_kessler_nervous,
    t0_kessler_restless,
    t0_kessler_worthless ),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_kessler_6 = mean(
    c(
    t2_kessler_depressed,
    t2_kessler_effort,
    t2_kessler_hopeless,
    t2_kessler_nervous,
    t2_kessler_restless,
    t2_kessler_worthless ),
    na.rm = TRUE
  )) |>
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()
  

# Confirm that ml is of class "mids"
class(ml_embodied)
str(ml_embodied)

mf_embodied <- mice::complete(ml_embodied, "long", inc = TRUE)


colnames(mf_embodied)
# test
head(mf_embodied$sample_weights)
str(dat_18$sample_weights)

str(mf_embodied)
str(ml_embodied)
saveRDS(ml_embodied, here::here(push_mods, "ml_embodied"))
saveRDS(mf_embodied, here::here(push_mods, "mf_embodied"))
```



```{r}
#| label: imputations practical
#| echo: false
#| include: false
#| eval: false
prep_practical_2only <- prep_practical |> 
  select(-starts_with("t3_")) |> 
  mutate(across(where(is.double), as.numeric)) |> 
  mutate(t0_male = as.numeric(t0_male)-1) |> 
  mutate(t0_religion_religious = as.numeric(t0_religion_religious)-1) |>
  mutate(t0_rural_gch2018 = as.integer(as.factor(t0_rural_gch2018))) |> 
  select(-t0_emp_work_life_balance) # not at baseline
# check
str(prep_practical_2only)

dev.off()
# health
naniar::vis_miss(prep_practical_2only, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_practical_2only)



# prep factors remove for speed

## impute missing variables
mice_practical  <- mice::mice(prep_practical_2only, m = 10)

# save imputations
saveRDS(mice_practical,
        here::here(push_mods, "mice_practical"))

# recall imputations if needed
mice_practical <-
  readRDS(here::here(push_mods, "mice_practical"))


# check mi model
outlist2 <-row.names(mice_practical)[mice_practical$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_practical$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_practical, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

N <- length(vnames)/nrow(prep_practical_2only) # (11 datasets)



# if we need weights
newdat <- data.frame( rep(dat_18$sample_weights, N))

colnames(newdat) <- "sample_weights"

# check
nrow(newdat) == nrow(mc)

mc_v <- bind_cols(newdat, mc ) |>
  relocate("sample_weights", .before = starts_with("t0_"))

# checks out

# comment out if using weights with the above code

skimr::skim(mc_v)

n_id <- nrow(dat_18) # number of ids
# n_id_3 = 3 * n_id # made long so need 3 x N # three waves

outcome_vars_practical

ml_practical <- mc_v %>%
  dplyr::mutate(id = as.factor(rep(1:n_id, 11))) |> # needed 
  mutate( t0_eth_cat = as.factor(t0_eth_cat),
         t0_rural_gch2018 = as.factor(t0_rural_gch2018),
         t1_perfectionism_high = as.factor(t1_perfectionism_high)) |>
  dplyr::group_by(id) |>
  dplyr::mutate(t0_powerdependence = mean(
    c(
    t0_power_self_nocontrol,
    t0_power_others_control),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_selfesteem = mean(
    c(
    t0_selfesteem_satself,
    t0_selfesteem_postiveself,
    t0_selfesteem_rfailure),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_self_control = mean(
    c(
    t0_self_control_have_lots,
    t0_self_control_wish_more_r),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_emotion_regulation = mean(
    c(
    t0_emotion_regulation_out_control,
    t0_emotion_regulation_hide_neg_emotions,
    t0_emotion_regulation_change_thinking_to_calm),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_powerdependence = mean(
    c(
    t2_power_self_nocontrol,
    t2_power_others_control),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_selfesteem = mean(
    c(
    t2_selfesteem_satself,
    t2_selfesteem_postiveself,
    t2_selfesteem_rfailure),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_self_control = mean(
    c(
    t2_self_control_have_lots,
    t2_self_control_wish_more_r),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_emotion_regulation = mean(
    c(
    t2_emotion_regulation_out_control,
    t2_emotion_regulation_hide_neg_emotions,
    t2_emotion_regulation_change_thinking_to_calm),
    na.rm = TRUE
  )) |>
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()
  

# Confirm that ml is of class "mids"
class(ml_practical)
str(mf_practical)

mf_practical <- mice::complete(ml_practical, "long", inc = TRUE)

str(mf_practical)
colnames(mf_practical)
# test
head(ml_practical$sample_weights)
str(dat_18$sample_weights)

saveRDS(ml_practical, here::here(push_mods, "ml_practical"))
saveRDS(mf_practical, here::here(push_mods, "mf_practical"))
```



```{r}
#| label: imputations reflective
#| echo: false
#| include: false
#| eval: false
prep_reflective_2only <- prep_reflective |> 
  select(-starts_with("t3_")) |> 
  mutate(across(where(is.double), as.numeric)) |> 
  mutate(t0_male = as.numeric(t0_male)-1) |> 
  mutate(t0_religion_religious = as.numeric(t0_religion_religious)-1) |>
  mutate(t0_rural_gch2018 = as.integer(as.factor(t0_rural_gch2018))) 
# check
str(prep_reflective_2only)

dev.off()
# health
naniar::vis_miss(prep_reflective_2only, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_reflective_2only)



# prep factors remove for speed

## impute missing variables
mice_reflective  <- mice::mice(prep_reflective_2only, m = 10)

# save imputations
saveRDS(mice_reflective,
        here::here(push_mods, "mice_reflective"))

# recall imputations if needed
mice_reflective <-
  readRDS(here::here(push_mods, "mice_reflective"))


# check mi model
outlist2 <-row.names(mice_reflective)[mice_reflective$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_reflective$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_reflective, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

N <- length(vnames)/nrow(prep_reflective_2only) # (11 datasets)



# if we need weights
newdat <- data.frame( rep(dat_18$sample_weights, N))

colnames(newdat) <- "sample_weights"

# check
nrow(newdat) == nrow(mc)

mc_v <- bind_cols(newdat, mc ) |>
  relocate("sample_weights", .before = starts_with("t0_"))

# checks out

# comment out if using weights with the above code

skimr::skim(mc_v)

n_id <- nrow(dat_18) # number of ids
# n_id_3 = 3 * n_id # made long so need 3 x N # three waves

outcome_vars_reflective

ml_reflective <- mc_v %>%
  dplyr::mutate(id = as.factor(rep(1:n_id, 11))) |> # needed 
  mutate( t0_eth_cat = as.factor(t0_eth_cat),
         t0_rural_gch2018 = as.factor(t0_rural_gch2018),
         t1_perfectionism_high = as.factor(t1_perfectionism_high)) |>
  dplyr::group_by(id) |>
  dplyr::mutate(t0_pwi = mean(
    c(
    t0_pwi_health,
    t0_pwi_relationships,
    t0_pwi_security,
    t0_pwi_standardliving),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_lifesat = mean(
    c(
    t0_lifesat_satlife,
    t0_lifesat_ideal),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_meaning = mean(
    c(
    t0_meaning_purpose,
    t0_meaning_sense),
    na.rm = TRUE
  )) |> 
    dplyr::mutate(t2_pwi = mean(
    c(
    t2_pwi_health,
    t2_pwi_relationships,
    t2_pwi_security,
    t2_pwi_standardliving),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_lifesat = mean(
    c(
    t2_lifesat_satlife,
    t2_lifesat_ideal),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_meaning = mean(
    c(
    t2_meaning_purpose,
    t2_meaning_sense),
    na.rm = TRUE
  )) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(id, .before = sample_weights)  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()
  

# Confirm that ml is of class "mids"
class(ml_reflective)
str(ml_reflective)

mf_reflective <- mice::complete(ml_reflective, "long", inc = TRUE)


colnames(mf_reflective)
# test
head(mf_reflective$sample_weights)
str(dat_18$sample_weights)
str(ml_reflective)
str(mf_reflective)

saveRDS(ml_reflective, here::here(push_mods, "ml_reflective"))
saveRDS(mf_reflective, here::here(push_mods, "mf_reflective"))
```



```{r}
#| label: imputations social
#| echo: false
#| include: false
#| eval: false
prep_social_2only <- prep_social |> 
  select(-starts_with("t3_")) |> 
  mutate(across(where(is.double), as.numeric)) |> 
  mutate(t0_male = as.numeric(t0_male)-1) |> 
  mutate(t0_religion_religious = as.numeric(t0_religion_religious)-1) |>
  mutate(t0_rural_gch2018 = as.integer(as.factor(t0_rural_gch2018))) 
# check
str(prep_social_2only)

dev.off()
# health
naniar::vis_miss(prep_social_2only, warn_large_data = FALSE)

dev.off()

# check for collinear vars
mice:::find.collinear(prep_social_2only)



# prep factors remove for speed

## impute missing variables
mice_social  <- mice::mice(prep_social_2only, m = 10)

# save imputations
saveRDS(mice_social,
        here::here(push_mods, "mice_social"))

# recall imputations if needed
mice_social <-
  readRDS(here::here(push_mods, "mice_social"))


# check mi model
outlist2 <-row.names(mice_social)[mice_social$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_social$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_social, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

N <- length(vnames)/nrow(prep_social_2only) # (11 datasets)



# if we need weights
newdat <- data.frame( rep(dat_18$sample_weights, N))

colnames(newdat) <- "sample_weights"

# check
nrow(newdat) == nrow(mc)

mc_v <- bind_cols(newdat, mc ) |>
  relocate("sample_weights", .before = starts_with("t0_"))

# checks out

# comment out if using weights with the above code

skimr::skim(mc_v)

n_id <- nrow(dat_18) # number of ids
# n_id_3 = 3 * n_id # made long so need 3 x N # three waves

outcome_vars_social

ml_social<- mc_v %>%
  dplyr::mutate(id = as.factor(rep(1:n_id, 11))) |> # needed 
  mutate(t0_eth_cat = as.factor(t0_eth_cat),
         t0_rural_gch2018 = as.factor(t0_rural_gch2018),
         t0_charity_donate = log(t0_charity_donate + 1),
         t1_perfectionism_high = as.factor(t1_perfectionism_high),
         t2_charity_donate = log(t2_charity_donate + 1),
         t0_volunteers = as.factor(ifelse(t0_hours_charity > 1,1,0)),
        t2_volunteers = as.factor(ifelse(t2_hours_charity > 1,1,0)))|>
  dplyr::group_by(id) |>
  dplyr::mutate(t0_support = mean(
    c(
    t0_support_help,
    t0_support_turnto,
    t0_support_rnoguidance),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t0_belong = mean(
    c(
    t0_belong_accept,
    t0_belong_routsider,
    t0_belong_beliefs),
    na.rm = TRUE
  )) |> 
   dplyr::mutate(t2_support = mean(
    c(
    t2_support_help,
    t2_support_turnto,
    t2_support_rnoguidance),
    na.rm = TRUE
  )) |>
    dplyr::mutate(t2_belong = mean(
    c(
    t2_belong_accept,
    t2_belong_routsider,
    t2_belong_beliefs),
    na.rm = TRUE
  )) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(across(where(is.numeric) & !sample_weights, ~ scale(.x), .names = "{col}_z")) %>%
  select(-c(.imp_z, .id_z)) %>%
   select(
    where(is.factor),
    sample_weights,
    ends_with("_z"),
    .imp,
    .id
  ) |> 
  relocate(id, .before = sample_weights)  %>%
  relocate(sample_weights, .before = starts_with("t1_"))  %>%
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  relocate(starts_with("t3_"), .after = starts_with("t3_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()
  

# Confirm that ml is of class "mids"
class(ml_social)
str(ml_social)

mf_social <- mice::complete(ml_social, "long", inc = TRUE)

str(mf_social)
colnames(mf_social)
# test
head(mf_social$sample_weights)
str(dat_18$sample_weights)

saveRDS(ml_social, here::here(push_mods, "ml_social"))
saveRDS(mf_social, here::here(push_mods, "mf_social"))
```




```{r}
#| label: models heath
#| eval: false

ml_health <- readRDS(here::here(push_mods, "ml_health"))

# longform data if necessary
mf_health <- readRDS(here::here(push_mods, "mf_health"))

colnames(mf_health)

mf_health$t1_perfectionism_high

# Set exposure 
X <- "t1_perfectionism_high"


# baselin vars ---------------------------------------------------------

baseline_vars_health = mf_health |> 
  dplyr::select(starts_with("t0"), -t0_perfectionism_z, -t0_sfhealth_z) |> colnames()

baseline_vars_health

options(scipen = 999)

is.mids(ml_health)

dt_match_health <- match_mi(data = ml_health, X = "t1_perfectionism_high", baseline_vars = baseline_vars_health, estimand = "ATE",  method = "ebal", sample_weights = "sample_weights")

saveRDS(dt_match_health, here::here(push_mods, "dt_match_health"))

sum <- summary(dt_match_health)
sum
plot(sum)
bal.tab(dt_match_health)

dt_match_trim_health <- WeightIt::trim(dt_match_health, at = .99)
sum_trim <- summary(dt_match_trim_health)
sum_trim

bal.tab(dt_match_trim_health)

love.plot(dt_match_trim_health, binary = "std", thresholds = c(m = .1))
love.plot(dt_match_health, binary = "std", thresholds = c(m = .1))

dev.off()


# settings 
dt_match_health_use = dt_match_health # matched dataset from propensity scores.  If no propensity score model make ml_match = ml



# bootstrap simulations
nsims <- 200

# cores
cl =  parallel::detectCores () 


# x variable 
X = "t1_perfectionism_high"
Y = "t2_alcohol_frequency_z"


# as specified

# cores
cores = parallel::detectCores () # use all course
cores 

# outcomes

outcome_vars_health


mod_health_alcohol_frequency  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_alcohol_frequency_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "alcohol_frequency_z"
)

mod_health_alcohol_frequency
# save model
saveRDS(mod_health_alcohol_frequency, here::here(push_mods, "mod_health_alcohol_frequency"))



mod_health_alcohol_intensity  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_alcohol_intensity_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "alcohol_intensity_z"
)

mod_health_alcohol_intensity
# save model
saveRDS(mod_health_alcohol_intensity, here::here(push_mods, "mod_health_alcohol_intensity"))


mod_health_hlth_bmi  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_hlth_bmi_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "hlth_bmi_z"
)

mod_health_hlth_bmi
# save model
saveRDS(mod_health_hlth_bmi, here::here(push_mods, "mod_health_hlth_bmi"))


mod_health_hours_exercise  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_hours_exercise_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "hours_exercise_log_z"
)

mod_health_hours_exercise
# save model
saveRDS(mod_health_hours_exercise, here::here(push_mods, "mod_health_hours_exercise"))

# reduction of an hour
# exp(-.0199)
# exp(.0151)


mod_health_sfhealth_your_health  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_sfhealth_your_health_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "sfhealth_your_health_z"
)

mod_health_sfhealth_your_health


# save model
saveRDS(mod_health_sfhealth_your_health, here::here(push_mods, "mod_health_sfhealth_your_health"))
mod_health_sfhealth_your_health

mod_health_sfhealth_get_sick_easier  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_sfhealth_get_sick_easier_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "sfhealth_get_sick_easier_z (reversed)"
)

mod_health_sfhealth_get_sick_easier


# save model
saveRDS(mod_health_sfhealth_get_sick_easier, here::here(push_mods, "mod_health_sfhealth_get_sick_easier"))



mod_health_sfhealth_expect_worse_health  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_sfhealth_expect_worse_health_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "sfhealth_expect_worse_health_z"
)

mod_health_sfhealth_expect_worse_health


# save model
saveRDS(mod_health_sfhealth_expect_worse_health, here::here(push_mods, "mod_health_sfhealth_expect_worse_health"))




mod_health_sfhealth_comp  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_sfhealth_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "sfhealth_z (composite)"
)

mod_health_sfhealth_comp

# save model
saveRDS(mod_health_sfhealth_comp, here::here(push_mods, "mod_health_sfhealth_comp"))




## 
mod_health_hlth_sleep_hours  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_hlth_sleep_hours_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "hlth_sleep_hours"
)

mod_health_hlth_sleep_hours
# save model
saveRDS(mod_health_hlth_sleep_hours, here::here(push_mods, "mod_health_hlth_sleep_hours"))



## Risk Ratio

mod_health_smoker  <- gcomp_sim(
  df = dt_match_health_use,  # note change
  Y = "t2_smoker",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_health,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RR",
  type = "RR",
  nsims = 200,
  cores = cores,
  delta = 1,
  sd = 1,
  family = quasibinomial(),
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "smoker"
)


mod_health_smoker

# save model
saveRDS(mod_health_smoker, here::here(push_mods, "mod_health_smoker"))


# needs work
# interpret_table(mod_health_hlth_sleep_hours, estimand = "hours sleep", causal_scale = "risk_difference")

## combo-table

tab_health <-
  rbind(
mod_health_alcohol_frequency,
mod_health_alcohol_intensity,
mod_health_hlth_bmi,
mod_health_hours_exercise,
mod_health_sfhealth_your_health,
mod_health_sfhealth_get_sick_easier,
mod_health_sfhealth_expect_worse_health,
mod_health_sfhealth_comp,
mod_health_hlth_sleep_hours
  )

tab_health

#tab_cont_df <- as.data.frame(tab_cont)



group_tab_health <- group_tab(tab_health, type = "RD")

group_tab_health

dev.off()

group_plot_ate_health <- group_plot_ate(group_tab_health,    
                           type = "RD", 
                           title = "ATE of Hight Perfectionism Discrepency", 
                           subtitle = "Health Outcomes", 
                           xlab = "(sd units)", 
                           ylab = "test",
                           x_offset = -.5,
                           x_lim_lo = -.5,
                           x_lim_hi = 0.1)  
group_plot_ate_health


ggsave(
  group_plot_ate_health,
  path = here::here(here::here(push_mods, "group_plot_ate_health")),
  width = 8,
  height = 4,
  units = "in",
  filename = "group_plot_ate_health.png",
  device = 'png',
  limitsize = FALSE,
  dpi = 600
)

dev.off()
```



```{r}
#| label: models embodied
#| eval: false

ml_embodied <- readRDS(here::here(push_mods, "ml_embodied"))

# longform data if necessary
mf_embodied <- readRDS(here::here(push_mods, "mf_embodied"))

colnames(mf_embodied)

mf_embodied$t1_perfectionism_high

# Set exposure 
X <- "t1_perfectionism_high"


# baselin vars ---------------------------------------------------------

baseline_vars_embodied = mf_embodied |> 
  dplyr::select(starts_with("t0"), -t0_perfectionism_z, 
                -t0_kessler_6_z) |> colnames()


options(scipen = 999)
baseline_vars_embodied

dt_match_embodied <- match_mi(data = ml_embodied, X = "t1_perfectionism_high", baseline_vars = baseline_vars_embodied , estimand = "ATE",  method = "ebal", sample_weights = "sample_weights")

saveRDS(dt_match_embodied , here::here(push_mods, "dt_match_embodied"))

sum <- summary(dt_match_embodied)
sum
plot(sum)
bal.tab(dt_match_embodied)

dt_match_trim_embodied <- WeightIt::trim(dt_match_embodied, at = .99)
sum_trim <- summary(dt_match_trim_embodied)
sum_trim

bal.tab(dt_match_trim_embodied)

love.plot(dt_match_trim_embodied, binary = "std", thresholds = c(m = .1))
love.plot(dt_match_embodied, binary = "std", thresholds = c(m = .1))

dev.off()


# settings 
dt_match_embodied_use = dt_match_embodied # matched dataset from propensity scores.  If no propensity score model make ml_match = ml



# bootstrap simulations
nsims <- 200

# cores
cl =  parallel::detectCores () 

X = "t1_perfectionism_high"

# cores
cores = parallel::detectCores () # use all course
cores 

# outcomes

outcome_vars_embodied
# 1] "hlth_fatigue"      "rumination"        "kessler_depressed"
# [4] "kessler_effort"    "kessler_hopeless"  "kessler_nervous"  
# [7] "kessler_restless"  "kessler_worthless"

# add composite t2_kessler_6


mod_embodied_hlth_fatigue  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_hlth_fatigue_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "hlth_fatigue_z"
)

mod_embodied_hlth_fatigue
# save model
saveRDS(mod_embodied_hlth_fatigue, here::here(push_mods, "mod_embodied_hlth_fatigue"))

# rumination
mod_embodied_rumination  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_rumination_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "rumination_z"
)

mod_embodied_rumination
# save model
saveRDS(mod_embodied_rumination, here::here(push_mods, "mod_embodied_rumination"))

## kessler_depressed
mod_embodied_kessler_depressed  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_depressed_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_depressed_z"
)

mod_embodied_kessler_depressed
# save model
saveRDS(mod_embodied_kessler_depressed, here::here(push_mods, "mod_embodied_kessler_depressed"))



## kessler_effort
mod_embodied_kessler_effort  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_effort_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_effort_z"
)

mod_embodied_kessler_effort
# save model
saveRDS(mod_embodied_kessler_effort, here::here(push_mods, "mod_embodied_kessler_effort"))


## kessler_hopeless
mod_embodied_kessler_hopeless  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_hopeless_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_hopeless_z"
)

mod_embodied_kessler_hopeless
# save model
saveRDS(mod_embodied_kessler_hopeless, here::here(push_mods, "mod_embodied_kessler_hopeless"))


## kessler_nervous
mod_embodied_kessler_nervous  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_nervous_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_nervous_z"
)

mod_embodied_kessler_nervous
# save model
saveRDS(mod_embodied_kessler_nervous, here::here(push_mods, "mod_embodied_kessler_nervous"))


## kessler_restless
mod_embodied_kessler_restless  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_restless_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_restless_z"
)

mod_embodied_kessler_restless
# save model
saveRDS(mod_embodied_kessler_restless, here::here(push_mods, "mod_embodied_kessler_restless"))


## kessler_worthless
mod_embodied_kessler_worthless  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_worthless_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_worthless_z"
)

mod_embodied_kessler_worthless
# save model
saveRDS(mod_embodied_kessler_worthless, here::here(push_mods, "mod_embodied_kessler_worthless"))



## t2_kessler_6
mod_embodied_kessler_6  <- gcomp_sim(
  df = dt_match_embodied_use,  # note change
  Y = "t2_kessler_6_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_embodied,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "kessler_6 (composite)"
)

mod_embodied_kessler_6
# save model
saveRDS(mod_embodied_kessler_6, here::here(push_mods, "mod_embodied_kessler_6"))



## combo-table

tab_embodied <-
  rbind(
mod_embodied_hlth_fatigue,
mod_embodied_rumination,
mod_embodied_kessler_depressed,
mod_embodied_kessler_effort,
mod_embodied_kessler_hopeless,
mod_embodied_kessler_nervous,
mod_embodied_kessler_restless,
mod_embodied_kessler_worthless,
mod_embodied_kessler_6
  )

tab_embodied


group_tab_embodied <- group_tab(tab_embodied, type = "RD")

group_tab_embodied



group_plot_ate_embodied <- group_plot_ate(
  group_tab_embodied,
  type = "RD",
  title = "ATE of High Perfectionism Discrepency",
  subtitle = "Embodied Outcomes",
  xlab = "(sd units)",
  ylab = "test",
  x_offset = -.5,
  x_lim_lo = -.5,
  x_lim_hi = .5
)  

group_plot_ate_embodied


dev.off()
ggsave(
  group_plot_ate_embodied,
  path = here::here(here::here(push_mods, "group_plot_ate_embodied")),
  width = 8,
  height = 4,
  units = "in",
  filename = "ggroup_plot_ate_embodied.png",
  device = 'png',
  limitsize = FALSE,
  dpi = 600
)

dev.off()
```


```{r}
#| label: models practical
#| eval: false


ml_practical <- readRDS(here::here(push_mods, "ml_practical"))

# longform data if necessary
mf_practical <- readRDS(here::here(push_mods, "mf_practical"))

colnames(mf_practical)

mf_embodied$t1_perfectionism_high

# Set exposure 
X <- "t1_perfectionism_high"


# baselin vars ---------------------------------------------------------
baseline_vars_practical = mf_practical |>
  dplyr::select(
    starts_with("t0"),
    -t0_perfectionism_z,
    -t0_selfesteem_z,
    -t0_emotion_regulation_z,
    -t0_self_control_z,
    -t0_powerdependence_z,
  ) |> colnames()

options(scipen = 999)
baseline_vars_practical

dt_match_practical <- match_mi(data = ml_practical, X = "t1_perfectionism_high", baseline_vars = baseline_vars_practical , estimand = "ATE",  method = "ebal", sample_weights = "sample_weights")

saveRDS(dt_match_practical , here::here(push_mods, "dt_match_practical"))

sum <- summary(dt_match_practical)
sum
plot(sum)
bal.tab(dt_match_embodied)

dt_match_trim_practical <- WeightIt::trim(dt_match_practical, at = .99)
sum_trim <- summary(dt_match_trim_practical)
sum_trim

bal.tab(dt_match_trim_practical)

love.plot(dt_match_trim_practical, binary = "std", thresholds = c(m = .1))
love.plot(dt_match_practical, binary = "std", thresholds = c(m = .1))

dev.off()


# settings 
dt_match_practical_use = dt_match_trim_practical # matched dataset from propensity scores.  If no propensity score model make ml_match = ml



# bootstrap simulations
nsims <- 200

# cores
cl =  parallel::detectCores () 

X = "t1_perfectionism_high"

# cores
cores = parallel::detectCores () # use all course
cores 

# outcomes

outcome_vars_practical
                                


mod_practical_nzsei13  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_nzsei13_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "t2_nzsei13_z"
)

mod_practical_nzsei13 # no effect on employment

# save model
saveRDS(mod_practical_nzsei13, here::here(push_mods, "mod_practical_nzsei13"))

mod_practical_bodysat  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_bodysat_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "bodysat_z"
)

mod_practical_bodysat

# save model
saveRDS(mod_practical_bodysat, here::here(push_mods, "mod_practical_bodysat"))


mod_practical_vengeful_rumin  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_vengeful_rumin_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "vengeful_rumin_z"
)

mod_practical_vengeful_rumin

# save model
saveRDS(mod_practical_vengeful_rumin, here::here(push_mods, "mod_practical_vengeful_rumin"))



mod_practical_power_self_nocontrol  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_power_self_nocontrol_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "power_self_nocontrol_z"
)

mod_practical_power_self_nocontrol

# save model
saveRDS(mod_practical_power_self_nocontrol, here::here(push_mods, "mod_practical_power_self_nocontrol"))


mod_practical_power_others_control  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_power_others_control_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "power_others_control_z"
)

mod_practical_power_others_control

# save model
saveRDS(mod_practical_power_others_control, here::here(push_mods, "mod_practical_power_others_control"))


mod_practical_powerdependence  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_powerdependence_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "powerdependence_z"
)

mod_practical_powerdependence

# save model
saveRDS(mod_practical_powerdependence, here::here(push_mods, "mod_practical_powerdependence"))



mod_practical_selfesteem_satself  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_selfesteem_satself_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "selfesteem_satself_z"
)

mod_practical_selfesteem_satself


# save model
saveRDS(mod_practical_selfesteem_satself, here::here(push_mods, "mod_practical_selfesteem_satself"))

mod_practical_selfesteem_postiveself  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_selfesteem_postiveself_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "selfesteem_postiveself_z"
)

mod_practical_selfesteem_postiveself

# save model
saveRDS(mod_practical_selfesteem_postiveself, here::here(push_mods, "mod_practical_selfesteem_postiveself"))


mod_practical_selfesteem_rfailure  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_selfesteem_rfailure_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "selfesteem_failure_z (reversed)"
)

mod_practical_selfesteem_rfailure

# save model
saveRDS(mod_practical_selfesteem_rfailure, here::here(push_mods, "mod_practical_selfesteem_rfailure"))


mod_practical_selfesteem  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_selfesteem_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "selfesteem_z"
)

mod_practical_selfesteem

# save model
saveRDS(mod_practical_selfesteem, here::here(push_mods, "mod_practical_selfesteem"))


mod_practical_self_control_have_lots  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_self_control_have_lots_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "self_control_have_lots_z"
)

mod_practical_self_control_have_lots

# save model
saveRDS(mod_practical_self_control_have_lots, here::here(push_mods, "mod_practical_self_control_have_lots"))

mod_practical_self_control_wish_more_r  <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_self_control_wish_more_r_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "self_control_wish_more_z (reversed)"
)

mod_practical_self_control_wish_more_r

# save model
saveRDS(mod_practical_self_control_wish_more_r, here::here(push_mods, "mod_practical_self_control_wish_more_r"))


mod_practical_self_control <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_self_control_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "self_control_z"
)

mod_practical_self_control

# save model
saveRDS(mod_practical_self_control, here::here(push_mods, "mod_practical_self_control"))



mod_practical_emotion_regulation_out_control <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_emotion_regulation_out_control_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "emotion_regulation_out_control_z"
)

mod_practical_emotion_regulation_out_control

# save model
saveRDS(mod_practical_emotion_regulation_out_control, here::here(push_mods, "mod_practical_emotion_regulation_out_control"))

mod_practical_emotion_regulation_hide_neg_emotions <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_emotion_regulation_hide_neg_emotions_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "emotion_regulation_hide_neg_emotions_z"
)

mod_practical_emotion_regulation_hide_neg_emotions

# save model
saveRDS(mod_practical_emotion_regulation_hide_neg_emotions, here::here(push_mods, "mod_practical_emotion_regulation_hide_neg_emotions"))


mod_practical_emotion_regulation_change_thinking_to_calm <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_emotion_regulation_change_thinking_to_calm_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "emotion_regulation_change_thinking_to_calm_z"
)

mod_practical_emotion_regulation_change_thinking_to_calm

# save model
saveRDS(mod_practical_emotion_regulation_change_thinking_to_calm, here::here(push_mods, "mod_practical_emotion_regulation_change_thinking_to_calm"))


mod_practical_emotion_regulation <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_emotion_regulation_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "emotion_regulation_z"
)

mod_practical_emotion_regulation
# save model
saveRDS(mod_practical_emotion_regulation, here::here(push_mods, "mod_practical_emotion_regulation"))



mod_practical_emp_work_life_balance <- gcomp_sim(
  df = dt_match_practical_use,  # note change
  Y = "t2_emp_work_life_balance_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_practical,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "emp_work_life_balance (no baseline)"
)

mod_practical_emp_work_life_balance
# save model
saveRDS(mod_practical_emp_work_life_balance, here::here(push_mods, "mod_practical_emp_work_life_balance"))

## combo-table



tab_practical <-
  rbind(
    mod_practical_nzsei13,
    mod_practical_bodysat,
    mod_practical_vengeful_rumin,
    mod_practical_power_self_nocontrol,
    mod_practical_power_others_control,
    mod_practical_powerdependence,
    mod_practical_selfesteem_satself,
    mod_practical_selfesteem_postiveself,
    mod_practical_selfesteem_rfailure,
    mod_practical_selfesteem,
    mod_practical_self_control_have_lots,
    mod_practical_self_control_wish_more_r,
    mod_practical_self_control,
    mod_practical_emotion_regulation_out_control,
    mod_practical_emotion_regulation_hide_neg_emotions,
    mod_practical_emotion_regulation_change_thinking_to_calm,
    mod_practical_emotion_regulation,
    mod_practical_emp_work_life_balance
  )

tab_practical


group_tab_practical <- group_tab(tab_practical, type = "RD")

group_tab_practical



group_plot_ate_practical <- group_plot_ate(
  group_tab_practical,
  type = "RD",
  title = "ATE of High Perfectionism Discrepency",
  subtitle = "Practical Outcomes",
  xlab = "(sd units)",
  ylab = "test",
  x_offset = -.8,
  x_lim_lo = -.75,
  x_lim_hi = .5
)

group_plot_ate_practical


dev.off()
ggsave(
  group_plot_ate_practical,
  path = here::here(here::here(push_mods, "group_plot_ate_practical")),
  width = 8,
  height = 4,
  units = "in",
  filename = "ggroup_plot_ate_practical.png",
  device = 'png',
  limitsize = FALSE,
  dpi = 600
)

dev.off()

```


```{r}
#| label: models reflective
#| eval: false


ml_reflective <- readRDS(here::here(push_mods, "ml_reflective"))

# longform data if necessary
mf_reflective <- readRDS(here::here(push_mods, "mf_refective"))

colnames(mf_reflective)

mf_embodied$t1_perfectionism_high

# Set exposure 
X <- "t1_perfectionism_high"


# baselin vars ---------------------------------------------------------
baseline_vars_reflective = mf_reflective |>
  dplyr::select(
    starts_with("t0"),
    -t0_perfectionism_z,
    -t0_pwi_z,
    -t0_meaning_z,
  ) |> colnames()

options(scipen = 999)
baseline_vars_reflective

dt_match_reflective <- match_mi(data = ml_reflective, X = "t1_perfectionism_high", baseline_vars = baseline_vars_reflective , estimand = "ATE",  method = "ebal", sample_weights = "sample_weights")

saveRDS(dt_match_reflective, here::here(push_mods, "dt_match_refectivel"))

sum <- summary(dt_match_reflective)
sum
plot(sum)
bal.tab(dt_match_reflective)

dt_match_trim_reflective <- WeightIt::trim(dt_match_reflective, at = .99)
sum_trim <- summary(dt_match_trim_reflective)
sum_trim

bal.tab(dt_match_trim_reflective)

love.plot(dt_match_trim_reflective, binary = "std", thresholds = c(m = .1))
love.plot(dt_match_reflective, binary = "std", thresholds = c(m = .1))

dev.off()


# settings 
dt_match_reflective_use = dt_match_reflective # matched dataset from propensity scores.  If no propensity score model make ml_match = ml



# bootstrap simulations
nsims <- 200

# cores
cl =  parallel::detectCores () 

X = "t1_perfectionism_high"

# cores
cores = parallel::detectCores () # use all course
cores 

# outcomes

outcome_vars_reflective
                 
#  outcome_vars_reflective
# [1] "gratitude"          "pwi_health"         "pwi_relationships" 
# [4] "pwi_security"       "pwi_standardliving" "lifesat_satlife"   
# [7] "lifesat_ideal"      "meaning_purpose"    "meaning_sense"



# save model
saveRDS(mod_reflective_meaning, here::here(push_mods, "mod_reflective_meaning"))



mod_reflective_gratitude  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_gratitude_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "gratitude_z"
)

mod_reflective_gratitude

# save model
saveRDS(mod_reflective_gratitude, here::here(push_mods, "mod_reflective_gratitude"))


mod_reflective_pwi_health  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_health_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "pwi_health_z"
)

mod_reflective_pwi_health

# save model
saveRDS(mod_reflective_pwi_health, here::here(push_mods, "mod_reflective_pwi_health"))


mod_reflective_pwi_relationships  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_relationships_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "pwi_relationships_z"
)

mod_reflective_pwi_relationships

# save model
saveRDS(mod_reflective_pwi_relationships, here::here(push_mods, "mod_reflective_pwi_relationships"))


mod_reflective_pwi_security  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_security_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "pwi_security_z"
)

mod_reflective_pwi_security

# save model
saveRDS(mod_reflective_pwi_security, here::here(push_mods, "mod_reflective_pwi_security"))


mod_reflective_pwi_standardliving  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_standardliving_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "pwi_standardliving_z"
)

mod_reflective_pwi_standardliving

# save model
saveRDS(mod_reflective_pwi_standardliving, here::here(push_mods, "mod_reflective_pwi_standardliving"))



mod_reflective_pwi  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "pwi_z"
)

mod_reflective_pwi

# save model
saveRDS(mod_reflective_pwi, here::here(push_mods, "mod_reflective_pwi"))


# lifesat

mod_reflective_lifesat_satlife  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_lifesat_satlife_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "lifesat_satlife_z"
)

mod_reflective_lifesat_satlife

# save model
saveRDS(mod_reflective_lifesat_satlife, here::here(push_mods, "mod_reflective_lifesat_satlife"))


mod_reflective_lifesat_ideal  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_lifesat_ideal_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "lifesat_ideal_z"
)

mod_reflective_lifesat_ideal

# save model
saveRDS(mod_reflective_lifesat_ideal, here::here(push_mods, "mod_reflective_lifesat_ideal"))


## lifesat
mod_reflective_lifesat  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_pwi_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "lifesat_z"
)

mod_reflective_lifesat

# save model
saveRDS(mod_reflective_lifesat, here::here(push_mods, "mod_reflective_lifesat"))


# meaning


mod_reflective_meaning_purpose  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_meaning_purpose_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "meaning_purpose_z"
)

mod_reflective_meaning_purpose

# save model
saveRDS(mod_reflective_meaning_purpose, here::here(push_mods, "mod_reflective_meaning_purpose"))


mod_reflective_meaning_sense  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_meaning_sense_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "meaning_sense_z"
)

mod_reflective_meaning_sense

# save model
saveRDS(mod_reflective_meaning_sense, here::here(push_mods, "mod_reflective_meaning_sense"))





mod_reflective_meaning  <- gcomp_sim(
  df = dt_match_reflective_use,  # note change
  Y = "t2_meaning_z",
  X = "t1_perfectionism_high",
  baseline_vars = baseline_vars_reflective,
  treat_1 = 1,
  treat_0 = 0,
  estimand = "ATE",
  scale = "RD",
  type = "RD",
  nsims = 200,
  cores = cores,
  family = gaussian,
  weights = TRUE,
  continuous_X = FALSE,
  splines = FALSE, 
  new_name = "meaning_z"
)

mod_reflective_meaning

## combo-table
tab_reflective <- rbind(
  mod_reflective_gratitude,
  mod_reflective_pwi_health,
  mod_reflective_pwi_relationships,
  mod_reflective_pwi_security,
  mod_reflective_pwi_standardliving,
  mod_reflective_pwi,
  mod_reflective_lifesat_satlife,
  mod_reflective_lifesat_ideal,
  mod_reflective_lifesat,
  mod_reflective_meaning_purpose,
  mod_reflective_meaning_sense,
  mod_reflective_meaning
)

tab_reflective


group_tab_reflective <- group_tab(tab_reflective, type = "RD")

group_tab_reflective



group_plot_ate_reflective <- group_plot_ate(
  group_tab_reflective,
  type = "RD",
  title = "ATE of High Perfectionism Discrepency",
  subtitle = "Reflective Outcomes",
  xlab = "(sd units)",
  ylab = "test",
  x_offset = -.8,
  x_lim_lo = -.75,
  x_lim_hi = .5
)

group_plot_ate_reflective


dev.off()
ggsave(
  group_plot_ate_reflective,
  path = here::here(here::here(push_mods, "group_plot_ate_reflective")),
  width = 8,
  height = 4,
  units = "in",
  filename = "group_plot_ate_reflective.png",
  device = 'png',
  limitsize = FALSE,
  dpi = 600
)

dev.off()

```






```{r}
#| label: fig-meaningless
#| fig-cap: A meaningless scatterplot
#| fig-width: 5
#| fig-height: 5
#| fig-align: center
#| out-width: 50%
#| echo: false
#| include: false
#| eval: false

```

## Introduction

Here we go... [@sibley2012]

## Method



### Questions related to religion are as follows


#### Belief in God

Using one item from Eurobarometer (2005), we asked participants "Do you believe in a God" (1 = Yes, 0 = No) [@eurobarometer2005b].

#### Belief in Sprituality

Using one item from Eurobarometer (2005), we asked participants "Do you believe in some form of spirit or lifeforce? (1 = Yes, 0 = No) [@eurobarometer2005b].

#### Religion Affiliation

Participants were asked to indicate their religion identification ("Do you identify with a religion and/or spiritual group?") on a binary response (1 = Yes, 0 = No). We then asked "What religion or spiritual group?" These questions are used in the New Zealand Census.

#### Religious Identification

If participants answered *yes* to "Do you identify with a religion and/or spiritual group? we asked"How important is your religion to how you see yourself?" (1 = Not important, 7 = Very important). Those participants who were not religious were imputed a score of "1".

#### Frequency of Church Attendence

If participants answered *yes* to "Do you identify with a religion and/or spiritual group?" we measured their frequency of church attendance using one item from @sibley2012: "how many times did you attend a church or place of worship in the last month?". Those participants who were not religious were imputed a score of "0".

#### Spiritual Identification

Spiritual identification was measured using one item ("I identify as a spiritual person.") from @postmes_single-item_2013. Participants indicated their agreement with this item (1 = Strongly Disagree to 7 = Strongly Agree).

#### Frequency of Prayer

If participants answered *yes* to "Do you identify with a religion and/or spiritual group?" we measured their frequency of prayer by asking "how many times did you pray in the last week?" Those participants who were not religious were imputed a score of "0" [@Bulbulia_2015] .

#### Frequency of Scripture Reading

If participants answered *yes* to "Do you identify with a religion and/or spiritual group?" we measured their frequency of scripture reading by asking "how many times did you read religious scripture in the last week?" Those participants who were not religious were imputed a score of "0" [@bulbulia2016].

#### Perceived Discrimination -- Religion

"I feel that I am often discriminated against because of my religious/spiritual beliefs." (1 = Strongly Disagree to 7 = Strongly Agree). (Developed for the NZAVS, Time 7 - time 14)

## Descriptive statistics

```{r}

```

### Analytic approach

We next leveraged longitudinal data to investigate whether changing from transiting from a Christian denomination to a Christian NFD affiliation affect people's religious behaviors. That is, we used the longitudinal features of NZAVS data collection to evalutate the causal question of whether becoming a Christian NFD makes somebody less religious.[@eurobarometer2005b]

### Selection criteria.

1.  We selected people who participated in both the NZAVS 2016 and 2017 waves.
2.  Christian at baseline, not NFD.
3.  Christian at baseline + 1, either NFD or not NFD.
4.  Outcomes are all the variables in the NZAVS that measure religion and spirituality.
5.  Missing data multiply imputed (to adjust for sampling bias).
6.  Control for baseline confounders
7.  Estimation by Inverse probability weighting and G-computation.
8.  Recover the **Average Treatment Effect in the Treated**.

### Sample

|                                        | Time 10 (baseline) |
|:---------------------------------------|:-------------------|
|                                        | (N=10787)          |
| **Male**                               |                    |
| Male                                   | 4003 (37 %)        |
| Not_male                               | 6784 (63 %)        |
| **Cohort**                             |                    |
| Gen_Silent: born\< 1946                | 714 (7 %)          |
| Gen Boomers: born \>= 1946 & b.\< 1965 | 5229 (48 %)        |
| GenX: born \>=1961 & b.\< 1981         | 3311 (31 %)        |
| GenY: born \>=1981 & b.\< 1996         | 1421 (13 %)        |
| GenZ: born \>= 1996                    | 112 (1 %)          |
| **NZ-European**                        |                    |
| No                                     | 2018 (19 %)        |
| Yes                                    | 8730 (81 %)        |
| Missing                                | 39 (0.4%)          |
| **Education**                          |                    |
| Mean (SD)                              | 5.63 (± 2.66)      |
| Missing                                | 37 (0.3%)          |
| **Employed**                           |                    |
| No                                     | 2714 (25 %)        |
| Yes                                    | 8064 (75 %)        |
| Missing                                | 9 (0.1%)           |
| **NZDep2018**                          |                    |
| Mean (SD)                              | 4.70 (± 2.73)      |
| Missing                                | 117 (1.1%)         |
| **NZSEI13**                            |                    |
| Mean (SD)                              | 54.9 (± 16.0)      |
| Missing                                | 56 (0.5%)          |
| **Rural_GCH2018**                      |                    |
| 1                                      | 6632 (61 %)        |
| 2                                      | 2092 (19 %)        |
| 3                                      | 1254 (12 %)        |
| 4                                      | 567 (5 %)          |
| 5                                      | 126 (1 %)          |
| Missing                                | 116 (1.1%)         |
| **Born NZ**                            |                    |
| Mean (SD)                              | 0.800 (± 0.400)    |
| Missing                                | 18 (0.2%)          |
| **Parent**                             |                    |
| No                                     | 2574 (24 %)        |
| Yes                                    | 8212 (76 %)        |
| Missing                                | 1 (0.0%)           |
| **Partner**                            |                    |
| No                                     | 2576 (24 %)        |
| Yes                                    | 7903 (73 %)        |
| Missing                                | 308 (2.9%)         |
| **Politically_Liberal**                |                    |
| Mean (SD)                              | 3.57 (± 1.38)      |
| Missing                                | 497 (4.6%)         |
| **Left_Wing**                          |                    |
| Mean (SD)                              | 3.71 (± 1.31)      |
| Missing                                | 537 (5.0%)         |
| **Religious_Identification**           |                    |
| Mean (SD)                              | 1.72 (± 2.58)      |
| Missing                                | 68 (0.6%)          |

: Sample Statistics (baseline = 2018) {#tbl-sample}

### Description of Changes in Attitudes in Sample Pre-Post Attacks (one year)

The sample consists of 10,878 participants who responded the NZAVS 2016/17 Time 8 survey and who again responded to the NZAVS 2018/19 Time 10 survey.

|                         | Pre Attacks(Time 10) | Post Attacks(Time 11) |
|:------------------------|:---------------------|:----------------------|
|                         | (N=10787)            | (N=10787)             |
| **Warm Muslims**        |                      |                       |
| Mean (SD)               | 4.09 (1.46)          | 4.35 (1.41)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 286 (2.7%)           | 1672 (15.5%)          |
| **Warm Asians**         |                      |                       |
| Mean (SD)               | 4.54 (1.27)          | 4.64 (1.23)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 265 (2.5%)           | 1647 (15.3%)          |
| **Warm Chinese**        |                      |                       |
| Mean (SD)               | 4.39 (1.34)          | 4.47 (1.32)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 280 (2.6%)           | 1673 (15.5%)          |
| **Warm Immigrants**     |                      |                       |
| Mean (SD)               | 4.54 (1.23)          | 4.64 (1.23)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 282 (2.6%)           | 1674 (15.5%)          |
| **Warm Indians**        |                      |                       |
| Mean (SD)               | 4.31 (1.36)          | 4.42 (1.34)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 277 (2.6%)           | 1669 (15.5%)          |
| **Warm Refugees**       |                      |                       |
| Mean (SD)               | 4.68 (1.34)          | 4.80 (1.31)           |
| Median \[Min, Max\]     | 5.00 \[1.00, 7.00\]  | 5.00 \[1.00, 7.00\]   |
| Missing                 | 283 (2.6%)           | 1654 (15.3%)          |
| **Warm Pacific**        |                      |                       |
| Mean (SD)               | 4.78 (1.24)          | 4.87 (1.20)           |
| Median \[Min, Max\]     | 5.00 \[1.00, 7.00\]  | 5.00 \[1.00, 7.00\]   |
| Missing                 | 265 (2.5%)           | 1654 (15.3%)          |
| **Warm Maori**          |                      |                       |
| Mean (SD)               | 5.00 (1.27)          | 5.03 (1.26)           |
| Median \[Min, Max\]     | 5.00 \[1.00, 7.00\]  | 5.00 \[1.00, 7.00\]   |
| Missing                 | 270 (2.5%)           | 1660 (15.4%)          |
| **Warm NZ Euro**        |                      |                       |
| Mean (SD)               | 5.57 (1.23)          | 5.58 (1.24)           |
| Median \[Min, Max\]     | 6.00 \[1.00, 7.00\]  | 6.00 \[1.00, 7.00\]   |
| Missing                 | 282 (2.6%)           | 1659 (15.4%)          |
| **Warm Elderly**        |                      |                       |
| Mean (SD)               | 5.52 (1.16)          | 5.51 (1.15)           |
| Median \[Min, Max\]     | 6.00 \[1.00, 7.00\]  | 6.00 \[1.00, 7.00\]   |
| Missing                 | 258 (2.4%)           | 1648 (15.3%)          |
| **Warm Overweight**     |                      |                       |
| Mean (SD)               | 4.21 (1.37)          | 4.22 (1.38)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 274 (2.5%)           | 1660 (15.4%)          |
| **Warm Mental-illness** |                      |                       |
| Mean (SD)               | 4.60 (1.29)          | 4.64 (1.28)           |
| Median \[Min, Max\]     | 4.00 \[1.00, 7.00\]  | 4.00 \[1.00, 7.00\]   |
| Missing                 | 288 (2.7%)           | 1671 (15.5%)          |

: Average warmth ratings before and one-year after attacks {#tbl-warmth}

|                   | Time 10 (baseline) |
|:------------------|:-------------------|
|                   | (N=10787)          |
| AGREEABLENESS     |                    |
| Mean (SD)         | 5.36 (± 0.968)     |
| Missing           | 36 (0.3%)          |
| CONSCIENTIOUSNESS |                    |
| Mean (SD)         | 5.15 (± 1.01)      |
| Missing           | 33 (0.3%)          |
| EXTRAVERSION      |                    |
| Mean (SD)         | 3.85 (± 1.16)      |
| Missing           | 33 (0.3%)          |
| HONESTY_HUMILITY  |                    |
| Mean (SD)         | 5.51 (± 1.16)      |
| Missing           | 33 (0.3%)          |
| NEUROTICISM       |                    |
| Mean (SD)         | 3.38 (± 1.15)      |
| Missing           | 36 (0.3%)          |
| OPENNESS          |                    |
| Mean (SD)         | 4.95 (± 1.12)      |
| Missing           | 33 (0.3%)          |

: Personality ratings at baseline. In addition to demographic indicators we also used personality ratings to multiply impute missing values {#tbl-personality}

### Selection Bias

Although the timing of the attacks was random with respect to NAVS data collection, non-response and panel attrition may potentially bias inferences. A simple version of this threat is indicated in @fig-dag. $\dots$. We used both demographic indicators (see @tbl-sample) and personality indicators (see @tbl-personality) when multiply imputing missing responses.

```{tikz}
#| label: fig-dag
#| fig-cap: "Causal graph shows potential for selection bias from loss to follow up or non-response. To address this, we multiply impute missing values conditional on the assumption that missing values are random conditional on the imputation model (MAR)."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}


\begin{tikzpicture}[{every node/.append style}=draw]
  \node [ellipse, draw=white] (A) at (0, 0) {$Attacks$};
  \node [rectangle, draw=white] (Ac) at (4, 0) {$Acceptance$};
  \node [rectangle, draw=black] (S) at (8, 0) {$Selection$};
  \draw [-latex, draw=black] (Ac) to (S);
  \draw [-latex, bend left] (A) to (S);
  \draw [-latex, red, dashed] (A) to (Ac);
\end{tikzpicture}

```

## Results

Causal effect estimates on the difference scale are presented in @fig-results1. Contrasts are presented in standardised response units. Again, these causal effect estimates are modelled as a contrast in (1) expected group attitudes for the entire population prior to the attacks (NZAVS Time 10 pre-attacks) with (2) expected group attitudes for the entire population during the following year weighted by 2018 census data to recover post-stratification estimates. Assuming correct model specification and no measurement error, such contrasts would be unbiased estimates for the intention-to-treat effect for random "assignment" to the attack condition. \[Note: see supplement X for a discussion of the distinction between the per-protocol and intention to treat effects\]. Note that standard errors were obtained both by simulation and the delta method (simulated contrasts are reported here.) As indicated in @fig-results1, we replicate previous findings revealing a strong increase in the acceptance of Muslims. Furthermore, we find evidence for the transference of acceptance to prototypical minorities. We do not find a boost in acceptance for non-prototypical minority groups. Nor do we find acceptance for groups that may be regarded as "negative controls." The exception to this pattern is in evidence of an increase in the acceptance of Pacific peoples. Additionally, we find evidence for acceptance of those with mentally illness.

Before attempting to interpret the naive analysis, however, we must adjust for the possibility of temporal trends (see: @tbl-timeproto, @tbl-timenegcontrol, @tbl-timenonproto.)

![Causal effect estimates on the difference scale. Estimates were modelled with post-stratification survey weights (Age/Gender/NZ European Ethnicity), yeilding a population average treatment effect. However, these naive contrasts do not incorporate pre-attack time trends in minority-group acceptance.](fig_1.jpg){#fig-results1}

![Sensitivity analysis for causal contrasts adjusted for the estimated time trends in minority-group acceptance. Panel (a) presents the "worst case" scenario for increasing acceptance in pre-attack trajectories, implying that the attacks would have increased acceptance for all groups. Panel (b) presents the scenario in which increasing acceptance in pre-attack trajectories adjusted at the mean of the pre-attack trends. Here we find stronger evidence for transference of acceptance to non-prototypical groups. Panel (c) presents the "best case" scenario for increasing acceptance in pre-attack acceptance, implying that the attacks did not increase acceptance as strongly as would appear in the naive analysis](fig_2.jpg){#fig-results2}

@fig-results2 presents a sensitivity analysis for causal effect estimates on the difference scale. Panel (a) presents the "worst case" scenario for increasing acceptance in pre-attack trajectories, implying that the attacks would have increased acceptance for all groups. This finding would be consistent with a strong "Jacidina Effect" (see Discussion.)

Panel (b) presents the scenario in which increasing acceptance in pre-attack trajectories adjusted at the mean of the pre-attack trends. Here we find stronger evidence for the transference of acceptance to non-prototypical groups. Panel (c) presents the "best case" scenario for increasing acceptance in pre-attack acceptance, implying that the attacks did not increase acceptance as strongly as would appear in the naive analysis. Prototypical Attitude Response Theory survives the strongest estimate of the pre-attack increase in acceptance. For this reason our most conservative estimats supports Prototypical Attitude Response Theory. Notably, at every level of the sensitivity analysis, the causal effects of attitudes to Muslims are estimated lower than in the naive analysis. This is because the acceptance of Muslims had been growing more steeply in the years prior to the attacks than had the acceptance of other groups. Notably, we find that as people age, they tend to be less accepting of the elderly and of the dominant NZ European majority.

| Parameter | Muslims           | Indians               |                     Asians | Refugees              |                 Immigrants | Chinese               |
|:----------|:----------|:----------|----------:|:----------|----------:|:----------|
| time      | 0.05 (0.04, 0.06) | 0.02 (7.24e-03, 0.03) | 4.55e-03 (-6.34e-03, 0.02) | 0.01 (2.16e-04, 0.03) | 6.38e-03 (-4.39e-03, 0.02) | 0.01 (3.66e-03, 0.02) |

: Estimated annual increase in acceptance for prototypical minority groups. Note that attitudes to refugees were not measured in the 2016/17 NZAVS Wave, rendering estimates for this trajectory less reliable than other estimates. {#tbl-timeproto}

| Parameter   |                  Pacific |           NZ European |                     Maori |
|:-----------------|-----------------:|-----------------:|------------------:|
| (Intercept) |      0.004 (-0.02, 0.02) |    0.035 (0.01, 0.06) |       0.011 (-0.01, 0.03) |
| time        | -0.010 (-0.02, 6.86e-04) | -0.034 (-0.05, -0.02) | -0.016 (-0.03, -4.92e-03) |

: Estimated annual increase in acceptance for non-prototypical groups {#tbl-timenonproto}

| Parameter | Overweight               | Mental Illness          |                   Elderly |
|:-----------------|:-----------------|:-----------------|------------------:|
| time      | -0.006 (-0.02, 4.98e-03) | 0.010 (-6.45e-03, 0.03) | -0.023 (-0.04, -7.72e-03) |

: Estimated annual increase in acceptance for negative controls. Note that attitudes to those with Mental Illness were not measured in the 2016/17 NZAVS Wave, rendering estimates for this trajectory less reliable than other estimates {#tbl-timenegcontrol}

## Discussion

Points to consider:

-   Muslim acceptance post attacks is evident whether the pre-attack acceptance trend is bounded at its highest or lowest confidence interval.
-   Prototypical minority acceptance is also evident whether the pre-attack acceptance trend is bounded at its highest or lowest confidence interval.
-   The magnitude of prototypical minority acceptance is about half that of the Muslim acceptance post-attack benefit.
-   At the lower bound of the pre-attack acceptance trajectory, all groups experience a lift in post-attack acceptance. This scenario suggests the potential for a "Jacinda Effect".
-   However, the complex interplay of social events at that time in New Zealand History remains unclear -- and cannot be disentangled from observed data.$\dots$
-   At the upper bound of the pre-attack acceptance trajectory, only prototypical minority groups saw a lift in acceptance over and above expectations from the pre-attack trajectory.
-   Notably, although the confidence intervals for prototypical minorities were reliably above zero on this "best-case" pre-attack trajectory, the confidence intervals between prototypical and non-prototypical minority groups overlapped. We can therefore infer only somewhat weak overall support for prototyping in the attack responses.
-   This study reveals the potential for psychological science to reframe how popolar understandings of minority groups. In New Zealand Pacific peoples tend to be grouped with Māori peoples. However, the pattern of response to Pacific peoples following the Christchurch attacks is more closely aligned with the prototypical minority group response.
-   Moreover, the declining acceptance of elderly people and for New Zealand Europeans over time merits further attention. Overall acceptance of these populations remains the highest of all groups. The pattern does not necessarily imply increasing prejudice: it may rather reflect declining affective responses to the familar. Whether and how people naturally become less "warm" to others as we age is another matter for future investigations.
-   Overall this study reveals both the power and the limitations of longitudinal data to address questions of fundamental interest across the social sciences.
-   

## Acknowledgments

HERE...

## References


```{r}
#| eval: false

# for another paper


dt <- dat |>
  dplyr::filter((Wave == 2016  & YearMeasured  == 1) |
                  (Wave == 2017  &
                     YearMeasured  == 1) |
                  (Wave == 2018))  |>  # Eligibility criteria
  group_by(Id) |>
  dplyr::mutate(k_16 =  ifelse(Wave == 2016 &
                                 YearMeasured == 1 &
                                 Christian == 1, 1, 0)) |>   # creating an indicator for the first wave
  dplyr::mutate(h_16 = mean(k_16, na.rm = TRUE)) |>   # Hack
  dplyr::mutate(k_17 =  ifelse(Wave == 2017 &
                                 YearMeasured == 1 &
                                 Christian == 1, 1, 0)) |>   # creating an indicator for the first wave; note that we allow people to deconvert
  dplyr::mutate(h_17 = mean(k_17, na.rm = TRUE)) |>  # Hack
  dplyr::filter(h_16 > 0) |>  # hack to enable repeat of baseline
  dplyr::filter(h_17 > 0) |>  # hack to enable repeat of baseline
  ungroup() |>
  droplevels() |>
  mutate(Euro = if_else(EthCat == 1, 1, 0)) |>
  mutate(
    EthCat = as.factor(EthCat),
    Believe.Spirit = as.factor(Believe.Spirit),
    Believe.God = as.factor(Believe.God)
  ) |>
  select(# Age,
    Id,
    YearMeasured,
    #SampleFrame, # how long in study
    #w_GendAgeEuro, not estimating PATE
    Wave,
    BornNZ,
    Edu,
    EthCat,
    Employed,
    # Gender3,
    GenCohort,
    # EthCat,
    #Household.INC, not reliable
    KESSLER6,
    NZDep2013,
    NZSEI13,
    Partner,
    Parent,
    Pol.Orient,
    #  Pol.Wing,
    Rural_GCH2018,
    #  REGC_2022,
    #  SDO,
    RWA,
    AGREEABLENESS,
    CONSCIENTIOUSNESS,
    EXTRAVERSION,
    HONESTY_HUMILITY,
    OPENNESS,
    NEUROTICISM,
    Religion.Scripture,
    Religion.Church,
    Religion.Prayer,
    Believe.Spirit,
    Believe.God,
    Perc.Religious.Discrim,
    religious_identification,
    Spiritual.Identification,
    Christian_nfd, 
    Religious
  ) |>
  arrange(Id, Wave) |>
  mutate(
    Religion.Church = ifelse(Religion.Church > 8, 8, Religion.Church),
    # to avoid unstable models
    Religion.Scripture = ifelse(Religion.Scripture > 8, 8, Religion.Scripture),
    # to avoid unstable models
    Religion.Prayer = ifelse(Religion.Prayer > 8, 8, Religion.Prayer)
  ) |> # to avoid unstable models
  group_by(Id) |>
  mutate(nfd_became_17 =  # exposure
           as.factor( ifelse(
             ((Wave == 2017 & Christian_nfd == 1) &
               (Wave == 2017 & lag(Christian_nfd == 0))), 1, 0)))|>
  mutate(nfd_lost_17 =  # exposure
           as.factor(ifelse(
             ((Wave == 2017 & Christian_nfd == 0) &
               (Wave == 2017 & lag(Christian_nfd == 1))), 1, 0)))|>
  ungroup() |> 
  janitor::clean_names() |> # make names consistent
  # give sensible name
  mutate(rural_gch2018 = case_when(
    rural_gch2018 == 1 ~ "High Urban Accessibility",
    rural_gch2018 == 2 ~ "Medium Urban Accessibility",
    rural_gch2018 == 3 ~ "Low Urban Accessibility",
    rural_gch2018 == 4 ~ "Remote",
    rural_gch2018 == 5 ~ "Very Remote",
    #TRUE ~ "Unknown"  # This line is optional and used for cases that don't match any of the specified conditions
  )) |> 
   mutate(rural_gch2018 = factor(
    rural_gch2018,
    levels = c(
      "High Urban Accessibility",
      "Medium Urban Accessibility",
      "Low Urban Accessibility",
      "Remote",
      "Very Remote"
    ),
    ordered = TRUE
  )) |> 
  rename(religion_believe_god = believe_god) |> 
  rename(religion_believe_spirit = believe_spirit) |> 
  rename(religion_perceive_religious_discrim = perc_religious_discrim) |> 
  rename(religion_identification = religious_identification) |> 
  rename(religion_spiritual_identification = spiritual_identification) |> 
  rename(religion_religious = religious)# make so all religion vars start with religion
# make so all religion vars start with religion
# make so all religion vars start with religion 



n_unique(dt$id)

table(dt$nfd_became_17)
table(dt$nfd_lost_17)
table(dt$wave)

## check numbers of those changed
ds <- dt |>
  filter(year_measured == 1 &
           wave == 2016 | year_measured == 1 & wave == 2017) |>
  select(id, christian_nfd) |>
  mutate(christian_nfd = as.numeric(christian_nfd) - 1)

# check: finds same numbers
msm::statetable.msm(round(christian_nfd, 0), id, data = ds) |>
  kbl() |>
  kable_paper(full_width = F)

dt_mice <- dt |> 
  select(-c(id, year_measured))

# prepare data for mice imputation. 
mice:::find.collinear(dt_mice)

# check consistent n's
table(dt_mice)

  
#table
# functions for table
my_render_cont <- function(x) {
  with(stats.apply.rounding(stats.default(x), digits=3), c("",
                                                           "Mean (SD)"=sprintf("%s (&plusmn; %s)", MEAN, SD)))
}

my_render_cat <- function(x) {
  c("", sapply(stats.default(x), function(y) with(y,
                                                  sprintf("%d (%0.0f %%)", FREQ, PCT))))
}



# get control vars


# baseline wave
# do only for baseline wave
dt_mice_b <- dt_mice |> 
  filter(wave == 2016) 


cvars = dt_mice_b |>
  dplyr::select(!starts_with("religion_"))|>
  dplyr::select(!starts_with("nfd_")) |> 
  dplyr::select(- wave) |>
  colnames()

cvars
# make into an equation

output_string <- paste(cvars, collapse = "+")
formula_string <- paste("~", output_string, "|wave")

#formula_string <- paste("~", output_string)
formula_obj <- as.formula(formula_string)

formula_obj
colnames(dt_mice_b)

c_tab <-
  table1::table1(
    formula_obj,
    data = dt_mice_b,
    overall = FALSE,
    render.continuous = my_render_cont,
    render.categorical = my_render_cat
  )

# make demographic table html
c_tab

# make demographic tablem markdown
c_tab |> 
  as.data.frame() |> 
  kbl(format = "markdown")

# next for religion variables 


rvars = dt_mice_b |>
  dplyr::select(starts_with("religion_"))|>
  colnames()

rvars
# make into an equation

output_string_r <- paste(rvars, collapse = "+")
formula_string_r <- paste("~", output_string_r, "|wave")

#formula_string <- paste("~", output_string)
formula_obj_r <- as.formula(formula_string_r)

c_tab_r <-
  table1::table1(
    formula_obj_r,
    data = dt_mice_b,
    overall = FALSE,
    render.continuous = my_render_cont,
    render.categorical = my_render_cat
  )

# make demographic table html
c_tab_r

# make demographic tablem markdown
c_tab |> 
  as.data.frame() |> 
  kbl(format = "markdown")



# new table
c_tab_b <- table1::table1(formula_obj, data = dt_mice_b, overall = FALSE,
                             render.continuous = my_render_cont,
    render.categorical = my_render_cat)

# make demographic table html
c_tab_b

# make demographic tablem markdown
c_tab_b |> 
  as.data.frame() |> 
  kbl(format = "markdown")



# Prepare data for mice

  
# Prepare data for mice
# needs to use this pipe : %>%
dt_prep <- dt %>%
  mutate(time = as.numeric(wave) - 1)  %>%
  select(-c(wave, year_measured))  %>% 
  pivot_wider(
    id_cols = id,
    names_from = time,
    values_from = -c(id, time),
    names_glue = "t{time}_{.value}",
    names_prefix = "t"
  ) %>%
  select(-c(starts_with("t0_nfd")))  %>%
  select(-c(starts_with("t2_nfd")))  %>%
  select(-t0_religion_religious) %>%
  select(-c((starts_with("t1") | starts_with("t2")) & matches(paste0("(", paste(cvars), ")$"))))  %>%  # control vars only at baseline
  select(-c((starts_with("t1") & matches(paste0("(", paste(rvars), ")$")))))  %>%  # outcome vars only at baseline and outcome
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  arrange(id)


# need to remove id column
dt_prep_no_id <- dt_prep |> 
  select(-id)

colnames(dt_prep_no_id)
str(dt_prep_no_id)
# inspect
dev.off()
naniar::vis_miss(dt_prep_no_id, warn_large_data = FALSE)

# str( dt_19_noe$Id )


# check for collinear vars
mice:::find.collinear(dt_prep_no_id)

## impute missing variables
mice_gt <- mice::mice(dt_prep_no_id, m = 10)

# save imputations
saveRDS(mice_gt,
        here::here(push_mods, "mice_gt"))

# recall imputations if needed
mice_gt <-
  readRDS(here::here(push_mods, "mice_gt"))


# check mi model
outlist2 <-
  row.names(mice_gt)[mice_gt$outflux < 0.5]
length(outlist2)

# checks. We do not impute with weights: area of current research

head(mice_gt$loggedEvents, 10)

# data warangling

mc  <- mice::complete(mice_gt, "long", inc = T)

vnames <- rownames(mc)

cnames <- rownames(mc)

length(vnames)/nrow(dt_prep_no_id) #(11 datasets)


# if we need weights
# newdat <- data.frame( rep( dt_prep$t0_w_GendAgeEuro, 11))
# colnames(newdat ) <- "weights"
# head(newdat)
# length( newdat$weights ) == length( cnames)
# 
# 
# mc_v <- bind_cols(newdat, mc ) |>
#   relocate("weights", .before = "t0_Partner")

# checks out

# comment out if using weights with the above code
mc_v <- mc

skimr::skim(mc_v)

#
N <- nrow(dt_prep_no_id) # number of ids
N2 = 3 * N # made long so need 3 x N # three waves

# checks

head(mc_v)


# only use for long data
# create variables in z score -- NOT WORKING FOR IPTW AT MOMENT
# mc_vv <- mc_v %>%
#   dplyr::mutate(Id = as.factor(rep(1:N, 11))) |> # need ids
#   pivot_longer(
#     cols = starts_with("t"),
#     names_to = c("time", ".value"),
#     names_pattern = "t(\\d+)_(.*)"
#   ) |>
#   relocate("time", .after = "Id") |>
#   arrange(.imp, Id, time)  |>
#   group_by(.imp, Id) |>
#   fill(c(!starts_with("t0_Warm.") |
#            !starts_with("t1_Warm.")), .direction = "down") |> # create baselines
#   ungroup() |>
#   select(-.id) |>
#   mutate(.id = rep(1:N2, 11)) |>  # new id needed  for mice
#   data.frame()
# dim(mc_vv)
# head(mc_vv)
# head(mc_vv[, 27:36]) ## looks good
# # Get data into shape


# ml <- mc_v %>%
#   dplyr::mutate(across(where(~ !is.factor(.x)), ~ scale(.x), .names = "{col}_z")) |>
#   select(-c(.imp_z, .id_z)) |>
#   mutate_if(is.matrix, as.vector) %>%
#   as.mids()



# 
# ml <- mc_v %>%
#   mutate(across(where(~ !is.factor(.x)), ~ scale(.x), .names = "{col}_z")) %>%
#   select_if(~ any(names(.) %in% names(.)[sapply(., is.factor)]) | any(map_lgl(names(.), ~ends_with(.x, "_z")))) %>%
#   select(-c(.imp_z, .id_z)) %>%
#   mutate_if(is.matrix, as.vector) %>%
#   as.mids()

# ml <- mc_v %>%
#   mutate(t1_nfd_became_17 = as.factor(t1_nfd_became_17),
#          t1_nfd_lost_17 = as.factor(t1_nfd_lost_17) )|> 
#   mutate(across(where(~ !is.factor(.x)), ~ scale(.x), .names = "{col}_z")) %>%
#   select(where(is.factor),
#     ends_with("_z"),
#     .imp,
#     .id) %>%
#     select(-c(.imp_z, .id_z)) %>%
#   mutate_if(is.matrix, as.vector) %>%
#   as.mids()

colnames(ml)


ml <- mc_v %>%
  mutate(across(where(~ !is.factor(.x)), ~ scale(.x), .names = "{col}_z")) %>%
  select(
    where(is.factor),
    ends_with("_z"),
    .imp,
    .id
  ) %>%
  select(-c(.imp_z, .id_z)) %>%
  dplyr::mutate(across(starts_with("t2_") & where(is.factor), ~ as.numeric(.x) - 1)) %>% # make factors numeric and subtract 1
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  %>%
  relocate(starts_with("t2_"), .after = starts_with("t1_"))  %>%
  mutate_if(is.matrix, as.vector) %>%
  as.mids()

# Confirm that ml is of class "mids"
class(ml)
str(ml)

mf <- mice::complete(ml, "long", inc = TRUE)

colnames(mf)

saveRDS(ml, here::here(push_mods, "at-mice-ml"))
saveRDS(mf, here::here(push_mods, "at-mice-mf"))


```

```{r}
#| eval: false
# outcomewide analysis
#source(here::here("functions","functions_here.R"))

# read imputed data
ml <- readRDS(here::here(push_mods, "at-mice-ml"))

# longform data if necessary
mf <- readRDS(here::here(push_mods, "at-mice-mf"))

colnames(mf)
# Set exposure 
X <- "t1_nfd_became_17"



# baselin vars ---------------------------------------------------------

baseline_vars = mf |>
  dplyr::select(-c(.imp,
                   .id,
                  # id
                  # time, if df is long
                  # weights, if weights are used
                  )) |> # include?
  dplyr::select(starts_with("t0")) |> 
  dplyr::select(-t0_christian_nfd) |> 
  dplyr::select(!starts_with("t0_religion_religious")) |> colnames()

baseline_vars

outcome_vars = mf |>
  dplyr::select(-c(.imp,
                   .id,
                  # id
                  # time, if df is long
                  # weights, if weights are used
                  )) |> # include?
  dplyr::select(starts_with("t2")) |> colnames()



# set X var

# matching function (more approaches in the outcomewide --> scripts --> johnmark --> covid folder)
# set digits 3
options(scipen = 999)

# match the datasets to the exposure

## matching formula
dt_match <- weightthem(
  as.formula(paste(as.formula(paste(
    paste(X, "~",
          paste(baseline_vars, collapse = "+"))
  )))),
  ml,
  estimand = "ATT",
  stabilize = TRUE,
  method = "ebal"
)


match_mi <- function(X, baselinevars, ml, estimand, method) {
  require(WeightIt)
  require(MatchThem)
  dt_match <- weightthem(
    as.formula(paste(as.formula(paste(
      paste(X, "~",
            paste(baseline_vars, collapse = "+"))
    )))),
    ml,
    estimand = estimand,
    stabilize = TRUE,
    method = method
  )
  dt_match
}

dt_match <- match_mi(X, baselinevars = baselinevars, ml = ml, estimand = "ATT", method = "ebal")

saveRDS(dt_match, here::here(push_mods, "dt_match"))

sum <- summary(dt_match)
plot(sum)
bal.tab(dt_match)







# settings 
dt_match = dt_match # matched dataset from propensity scores.  If no propensity score model make ml_match = ml

#family
family <- "gaussian"

# bootstrap simulations
nsims <- 100

# cores
cl = 8

# x variable 
X = "t1_nfd_became_17"

# contrast value 
delta = 1

# outcomes
# church
Y = "t2_religion_church_z"
m_1 <- glm_contrast_mi(dt_match, nsims, Y = "t2_religion_church_z", X, baseline_vars, cl,family = "gaussian", delta) 
tb_church <- tab_ate_ols(m_1, "church", delta = 1, sd = 1)


# religious id
Y = "t2_religion_identification_z"
m_2 <- glm_contrast_mi(dt_match, nsims, Y, X, baseline_vars, cl,family = "gaussian", delta) 
tb_religious_id <- tab_ate_ols(m_2, "religous identification", delta = 1, sd = 1)
tb_religious_id

#  prayer
Y = "t2_religion_prayer_z"
m_3 <- glm_contrast_mi(dt_match, nsims, Y = "t2_religion_prayer_z", X, baseline_vars, cl,family = "gaussian", delta) 
tb_prayer <- tab_ate_ols(m_3, "prayer", delta = 1, sd = 1)
tb_prayer


#  scripture

m_4 <- glm_contrast_mi(dt_match, nsims, Y = "t2_religion_scripture_z", X, baseline_vars, cl,family = "gaussian", delta)
tb_scripture <- tab_ate_ols(m_4, "scripture", delta = 1, sd = 1)
tb_scripture

# spiritual id
m_5 <- glm_contrast_mi(dt_match, nsims, Y = "t2_religion_spiritual_identification_z", X, baseline_vars, cl,family = "gaussian", delta)

tb_spiritual <- tab_ate_ols(m_5, "spiritual id", delta = 1, sd = 1)
tb_spiritual

# perc relig descr
m_6 <- glm_contrast_mi(dt_match, nsims, Y = "t2_religion_perceive_religious_discrim_z", X, baseline_vars, cl,family = "gaussian", delta)

tb_reldis <- tab_ate_ols(m_6, "perc rel discrim", delta = 1, sd = 1)
tb_reldis

tab_cont <-
  rbind(
    tb_church,
    tb_religious_id,
    tb_prayer,
    tb_scripture,
    tb_spiritual,
    tb_reldis
  
  )


tab_outcomes <- group_tab_ate(tab_cont)
tab_outcomes


library(tidyverse)
library(glue)

library(tidyverse)
library(glue)
interpret_table <- function(df, causal_scale, estimand) {
  estimand_description <- case_when(
    estimand %in% c("PATE", "ATE") ~ "Average Treatment Effect (ATE) represents the expected difference in outcomes between treatment and control groups for the whole population.",
    estimand %in% c("PATT", "ATT") ~ "Average Treatment Effect on the Treated (ATT) represents the expected difference in outcomes between treatment and control groups for the individuals who received the treatment.",
    estimand %in% "CATE" ~ "Conditional Average Treatment Effect (CATE) represents the expected difference in outcomes between treatment and control groups for a specific subgroup of individuals.",
    estimand %in% c("SATE", "SATT") ~ "Sample Average Treatment Effect (SATE) represents the expected difference in outcomes between treatment and control groups within the sampled population.",
    TRUE ~ "The specified estimand is not recognized. Please use one of the following: 'PATE', 'PATT', 'ATE', 'ATT', 'CATE', 'SATE', 'SATT'."
  )
  
  if (causal_scale == "risk_ratio") {
    interpretation <- df %>%
      mutate(
        causal_contrast = round(E_Value / E_Val_bound, 3),
        strength_of_evidence = case_when(
          E_Value >= 1.25 ~ "reliable evidence for causality",
          E_Value >= 1.1 ~ "evidence for causality is not conclusive",
          TRUE ~ "no reliable evidence for causality"
        ),
        outcome_interpretation = glue(
          "For the outcome '{outcome}', the {estimand} causal contrast is {causal_contrast}. ",
          "The confidence interval ranges from {round(`2.5 %`, 3)} to {round(`97.5 %`, 3)}. ",
          "The E-value for this outcome is {round(E_Value, 3)}, indicating {strength_of_evidence}."
        )
      )
  } else if (causal_scale == "risk_difference") {
    interpretation <- df %>%
      mutate(
        causal_contrast = round(`E[Y(1)]-E[Y(0)]`, 3),
        strength_of_evidence = case_when(
          E_Value >= 1.25 ~ "reliable evidence for causality",
          E_Value >= 1.1 ~ "evidence for causality is not conclusive",
          TRUE ~ "no reliable evidence for causality"
        ),
        outcome_interpretation = glue(
          "For the outcome '{outcome}', the {estimand} causal contrast is {causal_contrast}. ",
          "The confidence interval ranges from {round(`2.5 %`, 3)} to {round(`97.5 %`, 3)}. ",
          "The E-value for this outcome is {round(E_Value, 3)}, indicating {strength_of_evidence}."
        )
      )
  } else {
    stop("Invalid causal_scale argument. Please use 'risk_ratio' or 'risk_difference'.")
  }
  
  result <- glue("Table interpretation:\n\n{estimand_description}\n\n{paste(interpretation$outcome_interpretation, collapse = '\n\n')}")
  return(result)
}

# Example usage:
# df1 <- read_csv("path/to/first_table.csv")
# df2 <- read_csv("path/to/second_table.csv")
# interpretation1 <- interpret_table(df1, "risk_difference")
# interpretation2 <- interpret_table(df2, "risk_ratio")
# cat(interpretation1)
# cat(interpretation2)

interpret_table(tab_outcomes,  "risk_difference", "ATT")


tab_outcomes |> kbl(format = "markdown")



#function to make plots
xlab = "Causal Difference Scale (SD)"
x_lim_lo = .35
x_lim_hi= .2
x_offset = -.35
tab_outcomes$Estimate
plot <- group_plot_ate(df = tab_outcomes, title = "", subtitle ="", xlab, ylab = "", x_offset, x_lim_lo, x_lim_hi) 

plot

group_plot_ate <- function(df, title, subtitle, xlab, ylab, x_offset, xlim) {
  # Convert the title string to a symbol
  title_sym <- sym(title)

  out <- ggplot(
    data = df,
    aes(
      y = reorder(outcome, `E[Y(1)]-E[Y(0)]`),
      x = `E[Y(1)]-E[Y(0)]`,
      xmin = `2.5 %`,
      xmax = `97.5 %`,
      fill = Estimate
    )
  ) +
    geom_col(position = position_dodge(width = 0.3)) +
    geom_errorbarh(height = .3, position = position_dodge(width = 0.3)) +
    geom_vline(xintercept = 0, linetype = "solid") +
    geom_vline(
      xintercept = c(-.25, -.1, .1, .25),
      linetype = "twodash",
      alpha = .5
    ) +
    theme_classic(base_size = 10) +
    scale_fill_manual(values = c("gray", "orange", "dodgerblue")) + # dodgerblue
    labs(
      x = xlab,
      y = ylab,
      title = title,
      subtitle = subtitle
    ) +
    #labels so that the graph can also be a table
    geom_text(
      aes(x = x_offset, label = estimate_lab),
      size = 4,
      hjust = 0,
      fontface = ifelse(df$Estimate == "not reliable", "plain", "bold")
    ) +
    coord_cartesian(xlim = c(x_lim_lo, x_lim_hi)) +
    theme(
      panel.border = element_blank(),
      axis.line = element_blank(),
      panel.background = element_blank(),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.title.x = element_text(size = 12),  # Increase x-axis label font size
      axis.title.y = element_text(size = 12),
      plot.title = element_text(face = "bold", size = 16),  # Increase title font size
      plot.subtitle = element_text(size = 14),  # Increase title font size
      axis.text = element_text(size = 12)  # Increase axis text font size
    ) + theme(legend.position = "top",  # or "top"
              legend.direction = "horizontal")
  # return
  out
}




Y = "t2_religion_religious"

m_religion_religious <- glm_contrast_rr_mi(dt_match, nsims, Y = "t2_religion_religious", X, baseline_vars, cl,family = "poisson", delta) 



tab__religion_religious <- tab_ate_rr(m_religion_religious, "religious:yes/no")

tab__religion_religious


```


::: {#refs}
:::
