---
title: "Better causal diagrammes"
author:
  - name: Joseph A. Bulbulia
orcid: 0000-0002-5861-2056
affiliation: Victoria University of Wellington, New Zealand
email: joseph.bulbulia@vuw.ac.nz
corresponding: yes
date-format: short
sanitize: true
keep-tex: true
include-in-header:
      - text: |
          \usepackage{cancel}
execute:
  warning: false
  eval: true
  echo: false
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: false


# for making graphs
library("tinytex")
library(extrafont)
loadfonts(device = "all")


# libraries for jb (when internet is not accessible)
# read libraries
source("/Users/joseph/GIT/templates/functions/libs2.R")

# read functions
source("/Users/joseph/GIT/templates/functions/funs.R")

# read data/ set to path in your computer
pull_path <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/current/nzavs_13_arrow"
  )

# for saving models. # set path fo your computer
push_mods <-
  fs::path_expand(
    "/Users/joseph/v-project\ Dropbox/data/nzvs_mods/00drafts/23_perfectionism_ken"
  )
```

## Abstract

## Introduction

### Objective

Correlation is not causation. However, persistent confusion in the analysis and reporting of correlations across many human sciences has limited scientific progress. The correlations in observed data are frequently biased indicators of causality. True causality may oppose observed correlations. These points are widely known. Nevertheless, many researchers report correlations using hedging language that may suggest causation. This widespread practice -- in which the author has regrettably participated -- has led to what might be called a "causality crisis" [@bulbulia2022]. Addressing the causality crisis is among science's most pressing issues.

When integrated into methodologically rigorous workflows, causal diagrammes or directed acyclic graphs -- "DAGs" -- are powerful tools by which to assist researchers in causal estimation. By the same token, unscrupulous applications of DAGs operates in much the same way as hedging language. Although researchers are increasingly referencing causal DAGs in their work, there is a risk that such applications will perpetuate the causality crisis. For example, when researchers lack time series data they cannot generally estimate unbiased causal effects[@vanderweele2015]. Thus, cross-sectional researchers who use DAGs to report the unrealistic assumptions embedded in their analyses use the tool to disguise unwarrented confidence. However, ideally the tool itself would be equipped with safety mechanisms that prevent self-inflicted injuries.

<!-- causal diagrammes may estimate causal effects. Causal diagrammes clarify assumptions. Science requires assumptions but it also requires data. Researchers armed with DAGs may be tempted to let themselves off the hook. However, it would be better if causal diagrammes directed researchers to pause, and collect data appropriate to their questions, or at least to name the clarify the obstacles. -->

Here, I develop a guide to causal graphs that is grounding in temporally ordered representations of the key elements. We shall see that attention to chronology in the spatial organisation of the dag may greatly assist researchers in avoiding the pitfalls of unscrupulous DAGs. Time ordered causal diagrammes may inform researchers of the data they need to address their causal questions. Although no tool is user-proof, **chronologically conscientious DAGs** are much safer than the alternatives.

There are many excellent resources for drawing causal diagrammes [@rohrer2018; @hernan2023; @cinelli2022; @barrett2021; @mcelreath2020].[^1] One may reasonably question whether another tutorial merely adds clutter. The approach to drawing causal diagrammes that I present hopes to contributes to previous attempts in five ways. First, I link graphs to the counterfactual frameworks that are necessary for conceptualising causality. Second, as mentioned, I underscore the importance of chronology in the presentation of the graph, and show how chronologically conscientious DAGs.[^2] Third, I devote sustained attention to both selection bias and measurement error -- topics for which, outside of epidemiology, there remains insufficient attention and for which causal graphs offer practically important insights. Fourth, I use the Parts 1 - 3 to derive practically useful advice for data collection, arguing that understanding of cultural evolution will be greatly enhanced by the creation of forward-looking longitudinal panels. Fifth, I conclude with a brief compendium of practical advice to help researchers avoid abominable DAGs. Along the way, I use causal graphs to examine the concepts of interaction and mediation, again with the aim of guiding readers clear of trouble.

[^1]: Notice that the causal consistency assumption reveals the priority of counterfactual outcomes over actual outcomes.Causal inference is *counterfactual data-science*.

[^2]: The term "DAG" is unfortunate because not all directed acyclic graphs are causal. For a graph to be causal it must satisfy the conditions of markov factorisation (see Appendix A). In my utopia, I would preferred that causal diagrammes were called markov factorisation graphs (see Appendix A).

The article is organised as follows:

**Part 1.** develops the connection between causal diagrammes and the potential outcomes framework. Understanding this connection is important. Whereas causal diagrammes help researchers to answer questions, we must first understand how to ask causal questions. Without such comprehension, causal graphs can be, at best, unproductive, and at worst, deceptive.

**Part 2.** reviews the four elemental types of confounding, and uses chronologically conscientious causal diagrammes to elucidate their properties. Although this discussion replicates material from other tutorials, by emphasising the temporal order in spatial structure of the graph the conditions in which we may identify causality in the presence of confounding become more apparent. Here, I show how causal graphs may clarify concepts of interaction, mediation, and treatment-confounder feedback of the kind we may expect to be pervasive time-series data. Finally, I describe a simple template that may be useful for evolutionary human scientists, which clarifies how three-waves of data collection may be used to estimate causal effects.

**Part 3.** Applies chronologically sensitive causal graphs substanative problems of selection bias, focussing attention on the imperatives for adequate sampling and retention in the three-wave panel design.

**Part 4.** Applies chronologically sensitive causal graphs to substantative problems of measurement error, focussing attention on the imperative for minimising measurement error and performing sensitivity analyses in the analysis of causality.

**Part 5.** Reviews advice on drawing chronologically conscientious causal diagrammes. Technical details are presented in an Appendix.

## Part 1. Identifiability assumptions

Causal diagrammes are powerful tools for answering causal questions. However before we can answer a causal question, we must first understand what is involved when we ask a causal question. In this section I review key concepts and identification assumptions.

### The fundamental problem of causal inference.

We say that $A$ causes $Y$ if changing $A$ would have made a difference to the outcome of $Y$. The use of the subjective "would have" reveals the need for counterfactuals when conceiving of causal effects.

Suppose there is evidence that bilingual children perform better at cognitive tasks. Here, learning a second language is our exposure or "treatment" of interest.

Define two potential outcomes for each child in a population:

-   $Y_i(a = 1)$: The cognitive ability of child $i$ if they were bilingual. This is the counterfactual outcome when A = 1.
-   $Y_i(a = 0)$: The cognitive ability of child $i$ if they were monolingual. This is the counterfactual outcome when A = 0.

Within a counterfactual or "potential outcomes" framework, the causal effect of bilingualism on cognitive ability for individual $i$ may be defined as a contrast, on the difference scale, between two potential outcomes ($Y(a)$) under the two different levels of the exposure ($A = 1$ (bilingual exposure); $A = 0$ (no-bilingual exposure)). For simplicity we assume these exposures are exhaustive, and well-defined. Under these assumptions:

$$
\text{Causal Effect of Bilingualism}_i = Y_i(1) - Y_i(0) 
$$

The causal effect of biolingualism for child $i$ is defined as a contrast between two states of the world, one in which the child $i$ hypothetically receives bilingual exposure ($Y$ when exposure is set $a=1$) and one in which the child $i$ hypothetically does not ($Y$ when exposure is set $a=0$).[^3] Notice that any child can only receive, at most, one level of the exposure. Only one hypothetical exposure can be realised. The outcome under the exposure that the child does not receive cannot be observed. For this reason, causal inference has been described as a missing data problem [@westreich2015; @edwards2015]. The same holds for individuals within different exposure groups. As shown in @tbl-consistency, at least half the counterfactual outcomes we require for estimating individual causal effects are missing.

[^3]: The counter-factual outcome under the exposure $A = a$ may be written in different ways, such as $Y(a)$ (the notation we use here), $Y^a$, and $Y_a$.

@tbl-consistency expresses the relationship between observable and counterfactual outcomes as a contingency table (This table is modified from a table in [@morgan2014]).

```{r }
#| echo: false
#| code-fold: true
#| warnings: false
#| message: false
#| label: tbl-consistency
#| tbl-cap: Causal estimation as a missing data problem.

library(tidyverse)
library(knitr)
library(kableExtra)

# create data frame
my_data <- tibble(
  Group = c(
    "Y(1)",
    "Y(0)"
  ),
  "Exposure(A=1)" = c("Observable", "Counterfactual"),
  "No Exposure (A=0)" = c("Counterfactual", "Observable"),
  
)

# create table 
my_data %>%
  kbl(format = "markdown")

```

#### Average causal effects

Although we cannot generally observe individual level causal effects, where the three identification assumptions described hold, it may be possible to estimate average causal effects within exposure groups. Where such assumptions hold, we may estimate average casual effects as contrasts in the average responses among the exposed an unexposed groups \[\^4\]. For example, such a contrast on the difference scale may be expressed:

```{=tex}
\begin{alignat*}{2}
ATE & = E=[Y(1) - Y(0)]\\
& = E[Y(1)) - E(Y(0)]
\end{alignat*}
```
The exposure need not be a binary indicator. We may obtain contrasts may be between two different levels of a multinomial categorical or continuous indicator, defined as $A = a$ and $A = a*$. In this case, the causal contrast on the difference scale may be expressed:

```{=tex}
   \begin{align*}
    ATE = E[Y(a) - Y(a*)]
    \end{align*}
```
Note that for the mean, the difference in the average expectation is equivalent to the average of the differences in expectation.

#### Identification assumption 1: Causal consistency

We satisfy the causal consistency assumption when the potential or counterfactual outcome under exposure $Y(A=a)$ corresponds to the observed outcome $Y_{observed}|A=a$.

<!-- The standard expression for counterfactual recovery (e.g. @morgan2014) is given:  -->

<!-- $$Y^{observed} = AY(a=1) + (1-A)Y(a=0)$$ -->

<!-- Where the assumption of causal consistency is tenable, we may obtain the missing counterfactual outcomes under hypothetical exposures as observed outcomes under realised exposures, such that: -->

Where the assumption of causal consistency is tenable, we say that the missing counterfactual outcomes under hypothetical exposures are equal to the observed outcomes under realised exposures. That is, by substituting $Y_{observed}|A$ for $Y(a)$ we may recover counterfactual outcomes required for our causal contrasts from realised outcomes under different levels of exposures.[^4]

[^4]: Notice that the causal consistency assumption reveals the priority of counterfactual outcomes over actual outcomes. Causal inference may be described as *counterfactual data-science*.

$$
Y^{observed}_i = 
\begin{cases} 
Y_i(~a^*) & \text{if } A_i = a* \\
Y_i(~a~) & \text{if } A_i = a
\end{cases}
$$

Casual consistency assumes no interference. The "no interference" assumption can be expressed as follows:

For any units $i$ and $j$ (where $i \neq j$) and any treatment assignments $a_i$ and $a_j$, the potential outcome for unit $i$ under treatment $a_i$ is not affected by the treatment assignment to unit $j$:

$$Y_i(a_i, a_j) = Y_i(a_i, a'_j)$$

for all $a_j, a'_j$.

Causal consistency requires that the potential outcome for unit $i$ when it receives treatment $a_i$ and unit $j$ receives treatment $a_j$ is the same as the potential outcome for unit $i$ when it receives treatment $a_i$ and unit $j$ receives any other treatment $a'_j$. Thus, the treatment assignment to any other unit $j$ does not affect the potential outcome of unit $i$.

Casual consistency also assumes no interference treatment variation irrelevance.[@vanderweele2009] In any study, and especially in observational studies, we assume that there are differences between versions of treatment $A$. Given such differences, how may we substitute observed treatments with counterfactual treatments?

The theory of causal inference under multiple versions of treatment holds that for $K$ versions of treatment $A$, if each element of $K$ is sufficiently well-defined to correspond to well-defined outcome $Y_k$, and if there is no confounding for the effect of $K$ on $Y$ given measured confounders $L$, then we may use $A$ to consistently estimate causal effects on $Y_k$. We write $Y_k$ is independent of $K$ conditional on $L$ [@vanderweele2009; @vanderweele2013; @vanderweele2018] as:

$$K \coprod Y_k | L$$ or equivalently as

$$Y_k \coprod K | L$$

If each treatment must be independent of the counterfactual outcome under exposure conditional on measured covariates, then  $A$ as a coarsened indicator of multiple versions of exposure i.e $A = f(k_1\dots k_n)$. 

Unfortunately, where interventions are ill-defined we may not be able to assess conditional independence assumption. Moreover, even if we assume this assumption holds for all versions we might be at a loss to understand the causal effect we have estimated. For example, consider the effect of weight-loss at age 40 on all cause mortality at age 50, noting there are potentially many way in which people lose weight, including exercise, caloric restriction, liposuction, stomach stapling, smoking, cancer, and famine. To estimate "the causal effect of weight-loss" without specifying the intervention in question leaves it unclear precisely which effects we are consistently estimating much less whether such effects transport to populations in which the distribution of $k \in K$ interventions differs. For example, if the distribution of unhealthy interventions exceeds the distribution of health interventions, we might erroneously infer that all weight loss is unhealthy.
Given the variability in measured observational data, human scientists must appreciate the limitations of validating and interpreting their results. (We will return to this mission critical realisation in Part 2.)

Finally, note that although causal consistency assumption allow us to link observed outcomes with counterfactual outcomes, half of the observations we require to obtain causal contrasts remain missing. Consider an experiment in which assignment to a binary treatment $A = {0,1}$ is random. We observe the realised outcomes $Y^{observed}|A = 1$ and $Y^{observed}|A = 0$, By causal consistency, $(Y^{observed}|A = 1) = Y(1)$ and $(Y^{observed}|A = 0) = Y(0)$. Nevertheless, the counterfactual outcomes for the treatments that participants did not receive are missing.

$$
ATE = \large(\underbrace{E[Y(1)|A = 1]}_\text{observed} + \underbrace{E[Y(1)|A = 0]}_\text{unobserved}\large) - \large(\underbrace{E[Y(0)|A = 0]}_\text{observed}  + \underbrace{E[Y(0)|A = 1]}_\text{unobserved}\large)
$$ We next turn to the exchangability assumption, which when satisifed allows us to impute those missing counterfactuals required for estimating causal effects.


We will next consider how the exchangability assumption allows us to recover the missing counterfactual outcomes. 


#### Identification assumption 2: Exchangability

When we assume exchangability we assume that the treatment assignment is independent of the potential outcomes, given a set of observed covariates or equivalently, conditional on observed covariates, the treatment assignment mechanism does not depend on the unobserved potential outcomes. This condition is one of "exchangeability" because conceptually, were we to "exchange" or "swap" individuals between the exposure and contrast conditions the distribution of potential outcomes would remain the same. Put differently, we say there is balance between the treatment conditions in the confounders that might affect the outcome.
Where $L$ is a measured covariate, exchangability may be expressed:

$$Y(a)\coprod  A|L$$

or equivalently:

$$A \coprod  Y(a)|L$$

Where such exchangability conditional on measured covariates holds, then:

$$
\begin{aligned}
ATE = E[Y(a*)|L = l] - E[Y(a)|L = l] 
\end{aligned}
$$

Again, conditioning on variables that might lead to an association between the exposure and outcomes in the absense of a causal association ensures *balance* in the distribution of such confounders across the exposures.  Although causal diagrammes or DAGs may be used to assess causal consistency and positivity, their primary use is to clarify the conditions under which we may consistently estimate causal effects by conditioning on (or omitting) covariates.


#### Identification assumption 3: Positivity

The positivity assumption is satisfied if there is a positive probability of receiving the exposure or non-receiving the exposure within every level of the the covariates.  The probability of receiving every value of the exposure within all strata of co-variates is greater than zero may be expressed:

```{=tex}
\begin{equation}
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall a \in L
\end{equation}
```

This assumption is crucial for causal inference because we cannot conceive of causal contrasts in the absence of causal interventions.There are two types of positivity violations:

-   **Random non-positivity**: the casual effect of ageing with observations missing within our data, but may be assumed to exist. For example every continuous exposure will lack (infinitely many) realisations on the number line, yet we may nevertheless use statistical models to estimate causal contrasts.

-   **Deterministic non-positivity**: the causal effect is inconceivable. For example, the causal effect of hysterectomy in biological males violates deterministic non-positivity.


### Relevance to cultural evolution

Consider the causal consistency, exchangability, and positivity assumptions in the setting where we are interested in estimating causal effects for religious beliefs and practices. Such questions have interested cultural evolutionary scholars, however, the causal identification assumptions make clear how difficult it may be to address them.

**Causal Consistency and No Interference**: Historical context can lead to different 'versions' of a cultural trait within the same nominal category, violating the causal consistency assumption. For example, the practice of Buddhism in Japan, influenced by historical interactions with Shinto beliefs, is different from the practice of Buddhism in India, where it originated. If we were studying the effect of practicing Buddhism on an outcome like charitable giving, this historical variation could lead to different effects, violating the causal consistency assumption. Furthermore, in historical contexts where the treatment of one individual affects the outcomes of others, such as in the spread of cultural traits or practices, the assumption of no interference (which is part of the causal consistency assumption) could be violated. We may claim ...

**Exchangeability and Ignorability**: Historical context can introduce unmeasured confounders that violate the exchangability assumption. For instance, the historical prevalence of certain religions in different regions could be associated with both the religion one practices and other outcomes of interest. If these historical factors are not measured and controlled for, they could confound the relationship between religion and the outcome, violating the exchangeability assumption. We may assume many such unmeasured factors...

**Positivity**: Historical context may lead to deterministic 'treatments', violating the positivity assumption. For example, the historical dominance of Catholicism in Italy means that someone born in Italy is almost certainly exposed to Catholicism, leading to a violation of the positivity assumption... (say more)

Thus, while history provides a rich context for understanding cultural evolution, it can also introduce complexities that challenge the identifiability assumptions of causal inference. We should not ask causal questions -- and therefore not attempt to write DAGs -- where the assumptions of causal inference are invalid.

In this section, we have seen that when it comes to causal inference, correlation is not the problem. The problem is that observational may fall short of the causal consistency assumption, the exchangability assumption, and the positivity assumption. 

<!-- 1. **Causal Consistency**: The causal consistency assumption might be violated if the 'treatment' (religious exposure) is not consistently defined. For instance, consider two individuals who identify as Christians. While both are exposed to Christianity, the 'version' of Christianity they practice could vary based on factors like denomination (e.g., Catholic, Protestant), personal beliefs, and local cultural practices. If these versions of the treatment have different effects on the outcome of interest (say, moral attitudes), then the causal consistency assumption is violated because the treatment (religious exposure) is not consistently defined across individuals. -->

<!-- 2. **Exchangeability**: The exchangability assumption might be violated if there are unmeasured confounders that affect both the treatment and the outcome. For example, consider the effect of religion (Christianity vs. Islam) on a particular outcome such as charitable giving. There could be unmeasured confounders like community influence or family traditions that influence both the religion one practices and the propensity to give to charity. If these confounders are not measured and controlled for, the exchangability assumption is violated, and the observed association between religion and charitable giving may not represent a causal association. -->

<!-- 3. **Positivity**: The positivity assumption might is violated if there are deterministic 'treatments' due to historical and geographical context. For example, someone born in a predominantly Muslim country like Saudi Arabia will almost certainly grow up practicing Islam, a deterministic 'treatment' that violates the positivity assumption. Similarly, someone born in Vatican City, the headquarters of the Roman Catholic Church, will almost certainly grow up practicing Catholicism. In these cases, the historical and geographical context leads to near-absolute probabilities of certain religious exposures, violating the positivity assumption. -->

<!-- In all these cases, the historical and geographical context, which heavily influences cultural traits such as religion, can lead to violations of the causal consistency, exchangability, and positivity assumptions. Just as history can constrain cultural evolution and lead to violations of these assumptions, it can also lead to violations of other key assumptions in causal inference. -->

<!-- In cultural evolution, the scope for violation of deterministic non-positivity would appear to be rather wide, because the constraints are history are arguably rather strong. For example, the language one speaks, a cultural trait, is heavily influenced by one's historical and geographical context. For example, someone born in rural Japan will almost certainly grow up speaking Japanese, a deterministic 'treatment' that violates the positivity assumption. History places substantial constraints on cultural evolution, often leading to near-absolute probabilities of certain cultural exposures such as language, arising from one's place and history. This arguably leads to widespread violations of deterministic non-positivity for many questions cultural evolution. -->

<!-- bias when estimating contrasts between counterfactual outcomes from observational data. -->

<!-- The data that we observe only give us insight into the counterfactual outcomes to be contrasted under the identifying assumptions of causal consistency, exchangeability, and positivity. When we ask a causal question we are must state our exposure question, outcome(s), and the variables that lead to an association between them, and these variables must correspond to well-defined features in our data. We cannot generally test the assumptions of "no-unmeasured confounding," and so must take every effort to examine unmeasured sources of bias. Only after we have stated our causal question may we use causal diagrammes to assist in answering that question. -->

We next review how causal diagrammes may help researchers to diagnose -- and avoid -- four elemental types of confounding and consider how adding chronological structure to our graphs assists in these tasks.


## Part 2. Temporal action graphs for the four basic confounds

### Conventions

Causal diagrammes are composed of the following elements:

1.  Nodes
2.  Vertices
3.  Markov factorisation

By Convention

-   Outcome: Y
-   Exposure or treatment: A or X
-   Confounders: C, L, D, generally should include A and Y at baseline
-   Selection: S
-   Box: conditioning

General Advice:

-   Clearly define all variables
-   Clearly define novel conventions
    -   dotted arrows
    -   colours
-   Minimalism (including avoiding graphs when words suffice).
-   *Temporal order*
    -   Left to right, top to bottom
    -   Index repeated measures
    -   Avoid enslavement: depart from this advice if doing so clarifies your objective.
    -   No multi-level models
    -   Good measures
    -   Retention
    -   Check positivity -- how many change.

### Elemental counfounds

There are four elemental confounds [@mcelreath2020 p.185]

### 1. The problem of confounding by common cause

The problem of confounding by common cause arises when there is an unmeasured or unaccounted-for variable, denoted as "L," that influences both the treatment variable, denoted by $A,$ and the outcome variable, denoted as $Y.$ This confounder, $L$, creates an association between $A$ and $Y$ that is not solely due to the direct causal effect of $A$ on $Y$. Instead, the observed association between $A$ and $Y$ may be partially or entirely driven by the presence of $L$, making it difficult to isolate and accurately estimate the true causal effect of $A$ on $Y$.

```{tikz}
#| label: fig-dag-common-cause
#| fig-cap: "Counfounding by common cause. The dashed red arrow indicates bias arising from the open backdoor path from A to Y."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]
\node [ellipse, draw=white] (L) at (0, 0) {L$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [rectangle, draw=white] (Y) at (8, 0) {Y$_{t2}$};
\draw [-latex, draw=red, dashed] (A) to (Y);
\draw [-latex, bend left, draw =black] (L) to (Y);
\draw [-latex, black] (L) to (A);
\end{tikzpicture}
```

### Solution to the problem of confounding by a common cause: adjust for all measured pre-exposure confounders

Confounding by common cause can be addressed by adjusting for it. Typically we adjust through through statistical techniques such as regression, matching, or inverse probability of treatment weighting. It is beyond the scope of this tutorial to describe these techniques (though see (Bubulia b this issue)). Figure @fig-dag-common-cause-solution clarifies that any confounding that is a cause of $A$ and $Y$ will precede $A$ (and so $Y$), because causes precede effects. Confounding control typically requires time-series data.

```{tikz}
#| label: fig-dag-common-cause-solution
#| fig-cap: "Solution: adjust for pre-exposure confounder."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=black] (L) at (0, 0) {L$_t0$};
\node [ellipse, draw=white] (A) at (4, 0) {A$_t1$};
\node [rectangle, draw=white] (Y) at (8, 0) {Y$_t2$};
\draw [-latex, draw=white] (A) to (Y);
\draw [-latex, bend left, draw =black] (L) to (Y);
\draw [-latex, black] (L) to (A);
\end{tikzpicture}

```

### 2. Confounding by collider stratification (conditioning on a common effect)

Conditioning on a common effect occurs when a variable $L$ is affected by both the treatment $A$ and an outcome $Y$. Conditioning on $L$ creates a spurious association between $A$ and $Y$, biasing the true causal relationship. This occurs because $L$ gives information about the relationship of $A$ and $Y$.

```{tikz}
#| label: fig-dag-common-effect
#| fig-cap: "Confounding by conditioning on a collider."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (A) at (0, 0) {A$_{t0}$};
\node [ellipse, draw=white] (Y) at (4, 0) {Y$_{t1}$};
\node [rectangle, draw=black] (L) at (8, 0) {L$_{t2}$};
\draw [-latex, draw=black, bend right] (A) to (L);
\draw [-latex, draw=black] (Y) to (L);
\draw [-latex, draw=red, dashed] (A) to (Y);

\end{tikzpicture}

```

### Solution to the problem of conditioning on a collider: (typically) ensure that all confounders are measured before the exposure and outcome has occurred.

To address the problem of conditioning on a common effect, we should generally ensure that the potential confounder $L$ that may affect $A$ is measured before $A$. If such temporal order is preserved, $L$ cannot be an effect of $A$, and thus neither of $Y$. By measuring all relevant confounders in advance, researchers can minimize bias and obtain more reliable estimates of the true causal relationship between $A$ and $Y$.

```{tikz}
#| label: fig-dag-common-effect-solution
#| fig-cap: "Solution: avoid colliders"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=black] (L) at (0, 0) {L$_{t0}$};
\node [ellipse, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [rectangle, draw=white] (Y) at (8, 0) {Y$_{t2}$};
\draw [-latex, draw=white] (A) to (Y);
\draw [-latex, bend left, draw =black] (L) to (Y);
\draw [-latex, black] (L) to (A);
\end{tikzpicture}



```

As with any rule, the guideline that confounders should be measured before their exposures has exceptions.

For example, as shown in @fig-m-bias, collider stratification may arise even if $L$ occurs before $A$, when $L$ does not affect $A$ or $Y$. This is called M-bias. We describe this case below. Note, however, that if $L$ is not a common cause of $A$ and $Y$, $L$ should not be included in our model because it is not a source of confounding.

```{tikz}
#| label: fig-m-bias
#| fig-cap: "M-bias: confounding control by including previous measures of the outcome"
#| out-width: 80%
#| echo: false


\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzstyle{DoubleArrow} = [-, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U1) at (0, 2) {U1};
\node [rectangle, draw=white] (U2) at (0, -2) {U2};
\node [rectangle, draw=black, align=left] (L) at (4, 0) {L$_{t0}$};
\node [rectangle, draw=white] (A) at (8, 0) {A$_{t1}$};
\node [rectangle, draw=white] (Y) at (12, 0) {Y$_{t2}$};

\draw [-latex, draw=black] (U1) to (L);
\draw [-latex, draw =black] (U2) to (L);
\draw [-latex, draw=black, bend left] (U1) to (Y);
\draw [-latex, draw =black, bend right] (U2) to (A);
\draw [-latex,  draw=red, red, dashed] (A) to (Y);


\end{tikzpicture}
```

However we will find another exception to the conditioning rule when we consider conditioning on descendants.

### 3 The problem of conditioning on a mediator

Conditioning on a mediator occurs when $L$ lies on the causal pathway between the treatment $A$ and the outcome $Y$. Conditioning on $L$ can lead to biased estimates by blocking or distort the true causal pathway between $A$ and $Y$, obscuring the total effect of $A$ on $Y$. Where $L$ is a collider between $A$ and an unmeasured confouder $U$, then including $L$ may increase the strength of association between $A$ and $Y$ \[JB to do: draw this graph\].

In either case, unless one is interested in mediation analysis (see below), conditioning on a post-treatment variable is nearly always a bad idea. \[JB to discuss the exception\]

```{tikz}
#| label: fig-dag-mediator
#| fig-cap: "Confounding by a mediator."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]
\node [ellipse, draw=white] (A) at (0, 0) {A$_{t0}$};
\node [rectangle, draw=black] (L) at (4, 0) {L$_{t1}$};
\node [rectangle, draw=white] (Y) at (8, 0) {Y$_{t2}$};
\draw [-latex, bend left, draw=black, dotted] (A) to (Y);
\draw [-latex, draw =black] (L) to (Y);
\draw [-latex, black] (A) to (L);
\end{tikzpicture}
```

### Solution: generally do not include confounders that are measured before the exposure

To address the problem of mediator bias, when interested in total effects do not condition on a mediator. This can be done by ensuring that $L$ occurs before $A$ (and $Y$). Again we discover the importance of an explicit temporal ordering for our variables. Although note, if $L$ is associated with $Y$ but is not associated with $A$ conditioning on $L$ will improve the efficiency of the causal effect estimate of $A$ on $Y$. However, if $A$ might affect $L$, then $L$ might be a mediator, and including $L$ risks bias. As with some much in causal estimation, we must understand the context.

```{tikz}
#| label: fig-dag-mediator-solution
#| fig-cap: "Ensure confounders occur before exposures."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=black] (L) at (0, 0) {L$_{t0}$};
\node [ellipse, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [rectangle, draw=white] (Y) at (8, 0) {Y$_{t2}$};
\draw [-latex, draw=white] (A) to (Y);
\draw [-latex, bend left, draw =black] (L) to (Y);
\draw [-latex, black] (L) to (A);
\end{tikzpicture}
```

### 4. Conditioning on a descendant

Say $X$ is a cause of $X\prime$. If we condition on X we partially condition on $X\prime$.

There are both negative and positive implications for causal estimation in real-world scenarios.

First the negative. Suppose there is a confounder $L$ that is caused by an unobserved variable $U$, and is affected by the treatment $A$. Suppose further that $U$ causes the outcome $Y$. In this scenario, as described in @fig-dag-descendent, conditioning on $L$, which is a descendant of $A$ and $U$, can lead to a spurious association between $A$ and $Y$ through the path $A \to L \to U \to Y$.

```{tikz}
#| label: fig-dag-descendent
#| fig-cap: "Confounding by descent"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [ellipse, draw=white] (A) at (2, 0) {A$_{t0}$};
\node [rectangle, draw=black](L) at (4, 0) {L$_{t1}$};
\node [ellipse, draw=white] (Y) at (6, 0) {Y$_{t2}$};

\draw [-latex, bend right=50] (U) to (L);
\draw [-latex, bend left, draw=black] (U) to (Y);
\draw [-latex,draw=black] (A) to (L);
\draw [-latex, bend left, draw=red, dashed] (A) to (Y);

\end{tikzpicture}

```

### Solution: consider the role of descendents carefully

Ensuring the confounder ($L$) is measured before the exposure ($A$) has two benefits.

First, if $L$ is a confounder, that is, if $L$ is a variable which if we fail to condition on it will bias the association between treatment and outcome, the strategy of including only pre-treatment indicators of $L$ will reduce bias.

Secondly, if an unmeasured confounder $U$ affects $A$, $Y$, and $L\prime$, then adjusting for $L\prime$ may help to reduce confounding caused by $U$. Note that $L\prime$ may occur after the exposure, and indeed after the outcome.

```{tikz}
#| label: fig-dag-descendent-solution
#| fig-cap: "Solution: again, ensure temporal ordering in all measured variables."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black] (L) at (2, 0) {L$_{t0}$};
\node [rectangle, draw=white](A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (Y) at (6, 0) {Y$_{t2}$};

\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, draw=blue, dotted] (A) to (Y);
\draw [-latex, bend right=50, draw =black] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);

\end{tikzpicture}

```

```{tikz}
#| label: fig-dag-descendent-solution-2
#| fig-cap: "Solution: note that conditioning on a confounder that occurs after the exposure and outcome addresses the problem of unmeasured confounding. The dotted paths denote that the effect of U on A and Y is partially adjusted by conditioning on L, even though L occurs after the outcome. The dotted blue path suggest suppressing of the biased relationship between A and Y under the null. A genetic factor that affects the exposure and the outcome early in life, and that also expresses a measured indicator late in life, might constitute an example for which post-outcome confounding control might be possible."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black] (L) at (6, -1) {L$_{t3}$};
\node [rectangle, draw=white](A) at (2, 0) {A$_{t1}$};
\node [ellipse, draw=white] (Y) at (4, 0) {Y$_{t2}$};

\draw [-latex, bend right = 10, draw=black] (U) to (L);
\draw [-latex, draw=blue, dotted] (A) to (Y);
\draw [-latex, bend right=20, draw =black, dotted] (U) to (Y);
\draw [-latex, draw =black, dotted] (U) to (A);

\end{tikzpicture}

```

**This ends the examples of canonical casual diagrammes**

## Part 3. Applications

### On the benefits of three wave designs

<!-- ```{tikz} -->

<!-- #| label: fig-dag-1 -->

<!-- #| fig-cap: "Common cause of exposure and outcome: example" -->

<!-- #| out-width: 80% -->

<!-- #| echo: false -->

<!-- \usetikzlibrary{positioning} -->

<!-- \usetikzlibrary{shapes.geometric} -->

<!-- \usetikzlibrary{arrows} -->

<!-- \usetikzlibrary{decorations} -->

<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->

<!-- \tikzset{>=latex} -->

<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->

<!-- \node [ellipse, draw=white] (L) at (0, 0) {t0/Male}; -->

<!-- \node [rectangle, draw=white] (A) at (4, 0) {t1/DoctorVisit}; -->

<!-- \node [rectangle, draw=white] (Y) at (8, 0) {t2/Heart Attack}; -->

<!-- \draw [-latex, draw=red, dashed] (A) to (Y); -->

<!-- \draw [-latex, bend left, draw =black] (L) to (Y); -->

<!-- \draw [-latex, black] (L) to (A); -->

<!-- \end{tikzpicture} -->

<!-- ``` -->

<!-- ### Solution: Adjust for Confounder -->

<!-- ```{tikz} -->

<!-- #| label: fig-dag-2 -->

<!-- #| fig-cap: "Solution to this problem." -->

<!-- #| out-width: 80% -->

<!-- #| echo: false -->

<!-- \usetikzlibrary{positioning} -->

<!-- \usetikzlibrary{shapes.geometric} -->

<!-- \usetikzlibrary{arrows} -->

<!-- \usetikzlibrary{decorations} -->

<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->

<!-- \tikzset{>=latex} -->

<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->

<!-- \node [rectangle, draw=black] (L) at (0, 0) {t0/Male}; -->

<!-- \node [ellipse, draw=white] (A) at (4, 0) {t1/DoctorVisit}; -->

<!-- \node [rectangle, draw=white] (Y) at (8, 0) {t2/Heart Attack}; -->

<!-- \draw [-latex, draw=white] (A) to (Y); -->

<!-- \draw [-latex, bend left, draw =black] (L) to (Y); -->

<!-- \draw [-latex, black] (L) to (A); -->

<!-- \end{tikzpicture} -->

<!-- ``` -->

<!-- ### Bias: exposure at baseline is a common cause of the exposure at t1 and outcome at t2 -->

<!-- ```{tikz} -->

<!-- #| label: fig-dag-3 -->

<!-- #| fig-cap: "Causal graph reveals bias from pre-exosure indicator" -->

<!-- #| out-width: 80% -->

<!-- #| echo: false -->

<!-- \usetikzlibrary{positioning} -->

<!-- \usetikzlibrary{shapes.geometric} -->

<!-- \usetikzlibrary{arrows} -->

<!-- \usetikzlibrary{decorations} -->

<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->

<!-- \tikzset{>=latex} -->

<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->

<!-- \node [rectangle, draw=white] (L) at (0, 0) {t0/Heart Attack}; -->

<!-- \node [ellipse, draw=white] (A) at (4, 0) {t1/Doctor Visit}; -->

<!-- \node [rectangle, draw=white] (Y) at (8, 0) {t2/Heart Attack}; -->

<!-- \draw [-latex, draw=red, dashed] (A) to (Y); -->

<!-- \draw [-latex, bend left, draw =black] (L) to (Y); -->

<!-- \draw [-latex, black] (L) to (A); -->

<!-- \end{tikzpicture} -->

<!-- ``` -->

<!-- ### Solution: adjust for confounder at baseline -->

<!-- ```{tikz} -->

<!-- #| label: fig-dag-4 -->

<!-- #| fig-cap: "Solution to this problem" -->

<!-- #| out-width: 80% -->

<!-- #| echo: false -->

<!-- \usetikzlibrary{positioning} -->

<!-- \usetikzlibrary{shapes.geometric} -->

<!-- \usetikzlibrary{arrows} -->

<!-- \usetikzlibrary{decorations} -->

<!-- \tikzstyle{Arrow} = [->, thin, preaction = {decorate}] -->

<!-- \tikzset{>=latex} -->

<!-- \begin{tikzpicture}[{every node/.append style}=draw] -->

<!-- \node [rectangle, draw=white, align=left] (L) at (0, 0) {t0/Heart Attack}; -->

<!-- \node [ellipse, draw=white] (A) at (4, 0) {t1/Doctor Visit}; -->

<!-- \node [rectangle, draw=white] (Y) at (8, 0) {t2/Heart Attack}; -->

<!-- \draw [-latex, draw=red, dashed] (A) to (Y); -->

<!-- \draw [-latex, bend left, draw =black] (L) to (Y); -->

<!-- \draw [-latex, black] (L) to (A); -->

<!-- \end{tikzpicture} -->

<!-- ``` -->

### Confounding control by three-wave panel designs

```{tikz}
#| label: fig-dag-6
#| fig-cap: "Causal graph: three-wave panel design"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {L$_{t0}$ \\A$_{t0}$ \\Y$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (Y) at (6, 0) {Y$_{t2}$};
\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, draw=red, dotted] (A) to (Y);
\draw [-latex, bend left=50, draw =black] (L) to (Y);
\draw [-latex, bend right=50, draw =black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw =black, dotted] (U) to (A);


\end{tikzpicture}
```

### Selection bias: there are several types

#### Unmeasured confounder affects selection and the outcome

```{tikz}
#| label: fig-dag-8
#| fig-cap: "Causal graph: three-wave panel design with selection bias"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {L$_{t0}$ \\A$_{t0}$ \\Y$_{t0}$};
\node [rectangle, draw=white] (A) at (4, 0) {A$_{t1}$};
\node [ellipse, draw=white] (US) at (4, -2) {U};
\node [rectangle, draw=black](S) at (6, 0) {S};
\node [ellipse, draw=white] (Y) at (8, 0) {Y$_{t2}$};

\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, bend left=50, draw=black] (L) to (Y);
\draw [-latex, bend right=50, draw=black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw=black, dotted] (U) to (A);
\draw [-latex, draw=black] (A) to (S);
\draw [-latex, draw=black] (US) to (S);
\draw [-latex, draw=black] (US) to (Y);
\draw [-latex, bend left = 40, draw=red, dashed] (A) to (Y);

\draw [cor, draw=red, bend right=20, dashed] (A) to (US);


\end{tikzpicture}


```

#### Unmeasured confounder affects a measured confounder of selection and the outcome, and there are unmeasured confounders that affect the measured confounder

```{tikz}
#| label: fig-dag-8-2
#| fig-cap: "Causal graph: three-wave panel design with selection bias: example 2"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}


% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black, align=left] (L) at (2, 0) {t0/L \\t0/A \\t0/Y};
\node [rectangle, draw=white] (A) at (4, 0) {t1/A};
\node [ellipse, draw=white] (US) at (4, -2) {U};
\node [rectangle, draw=white](L2) at (6, 0) {t2/L};
\node [rectangle, draw=black](S) at (8, 0) {S};
\node [ellipse, draw=white] (Y) at (10, 0) {t2/Y};

\draw [-latex, draw=black] (U) to (L);
\draw [-latex, draw=black] (L) to (A);
\draw [-latex, bend left=50, draw=black] (L) to (Y);
\draw [-latex, bend right=50, draw=black, dotted] (U) to (Y);
\draw [-latex, bend left=50, draw=black, dotted] (U) to (A);
\draw [-latex, draw=black] (A) to (L2);
\draw [-latex, draw=black] (L2) to (S);
\draw [-latex, draw=black] (US) to (L2);
\draw [-latex, draw=black, bend right=40] (US) to (Y);
\draw [-latex, bend left = 40, draw=red, dashed] (A) to (Y);

\draw [cor, draw=red, bend right=20, dashed] (A) to (US);


\end{tikzpicture}


```

#### Unmeasured confounder affects slection into the study and also attrition

```{tikz}
#| label: fig-dag-8-4
#| fig-cap: "Causal graph: three-wave panel design with selection bias: selection into the study (D) affects attrition"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}


% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (D) at (0, 0) {D};
\node [rectangle, draw=white] (A) at (2, 0) {t1/A};
\node [ellipse, draw=white] (US) at (0, -2) {U};
\node [rectangle, draw=black](S) at (4, 0) {S};
\node [ellipse, draw=white] (Y) at (6, 0) {t2/Y};

\draw [-latex, bend left=80, draw=black] (D) to (Y);
\draw [-latex, draw = black] (D) to (A);
\draw [-latex, draw=black, bend left=60] (D) to (S);
\draw [-latex, draw=black] (US) to (S);
\draw [-latex, draw=black] (US) to (Y);
\draw [-latex, bend left=40, draw=red, dashed] (A) to (Y);

\draw [cor, draw=red, bend right=10, dashed] (D) to (US);


\end{tikzpicture}

```

#### Outcome and exposure affect attrition

```{tikz}
#| label: fig-dag-8-5
#| fig-cap: "Causal graph:outcome and exposure affect attrition (Y measured with directed measurement error)"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]

\begin{tikzpicture}[{every node/.append style}=draw]


\node [rectangle, draw=white] (A) at (0, 0) {t1/A};
\node [ellipse, draw=white] (Y) at (3, 0) {t2/Y};
\node [rectangle, draw=black] (S) at (6, 0) {S};

\draw [-latex, bend left=80, draw=black] (A) to (S);
\draw [-latex, draw=black] (Y) to (S);
\draw [-latex, draw=red, dashed] (A) to (Y);



\end{tikzpicture}

```

#### Outcome and exposure affect attrition: we may approach this problem as one of directed measurement error.

```{tikz}
#| label: fig-directed-measurement-error
#| fig-cap: "TBA"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]

%\node [rectangle, draw=white] (ULAY) at (0, 4) {U$_{t0/LAY}$};
\node [rectangle, draw=white] (UA) at (4, 3) {U$_{t1/A}$};
\node [rectangle, draw=white] (UY) at (8, 3) {U$_{t2/Y}$};

%\node [rectangle, draw=black] (L0) at (0, 1) {LAY$^{t0}$};
\node [rectangle, draw=black] (A1) at (4, 1) {A$^{t1}$};
\node [rectangle, draw=black] (Y2) at (8, 1) {Y$^{t2}$};
%\node [rectangle, draw=white] (Leta0) at (0, 0) {L$^{t0}_\eta$};
\node [rectangle, draw=white] (Aeta1) at (4, 0) {A$^{t1}_\eta$};
\node [rectangle, draw=white] (Yeta2) at (8, 0) {Y$^{t2}_\eta$};


%\draw [-latex, draw=red] (ULAY) to (UA);
%\draw [-latex, draw=red] (ULAY) to (UY);

\draw [-latex, draw=black] (UA) to (A1);
\draw [-latex, draw=red] (UY) to (Y2);
%\draw [-latex, draw=black] (ULAY) to (L0);
%\draw [-latex, draw=black] (Leta0) to (L0);
%\draw [-latex, draw=black] (Leta0) to (Aeta1);
%\draw [-latex, draw=red, bend right=30] (Leta0) to (Yeta2);

\draw [-latex, draw=red] (Aeta1) to (A1);
\draw [-latex, draw=black] (Yeta2) to (Y2);

\draw [-latex, draw=red] (Aeta1) to (UY);
%\draw [-latex, draw=red] (Leta0) to (UA);



%\draw [cor, draw=red, dashed,bend right=80] (ULAY) to (Leta0);
%\draw [cor, draw=red, dashed, bend right = 80] (UA) to (Aeta1);
%\draw [cor, draw=red, dashed, bend left = 80] (UY) to (Yeta2);

\end{tikzpicture}
```

## Important Causal Diagrammes

## How do we draw interactions?

## Common cause of exposure and outcome.

```{tikz}
#| label: fig-dag-effect-modfication
#| fig-cap: "A simple graph for effect-modification."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}


\begin{tikzpicture}[{every node/.append style}=draw]
\node [ellipse, draw=white] (G) at (0, 0) {t0/G};
\node [rectangle, draw=white] (A) at (4, 0) {t1/A};
\node [rectangle, draw=white] (Y) at (8, 0) {t2/Y};
\draw [-latex, draw=black] (A) to (Y);
\draw [-latex, bend left, draw =black] (G) to (Y);
\end{tikzpicture}
```

### Another graph for interaction

```{tikz}
#| label: fig-dag-effect-modfication-2
#| fig-cap: "A simple graph for effect-modification."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}


\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (A) at (0, 0) {t0/A};
\node [ellipse, draw=white] (G) at (4, 0) {t1/G};
\node [rectangle, draw=white] (Y) at (8, 0) {t2/Y};
\draw [-latex, bend left, draw=black] (A) to (Y);
\draw [-latex, draw =black] (G) to (Y);
\end{tikzpicture}
```

### What if mediation is of interest?

Consider the assumptions required for mediation analysis:

1.  No unmeasured exposure-outcome confounders given $L$

$$Y(a,m)\coprod A|L$$ 2. No unmeasured meadiator-outcome confounders given $L$

$$Y(a,m)\coprod M|L$$

3.  No unmeasured exposure-mediator confounders given $L$

$$M(a)\coprod A|L$$

4.  No mediator-outcome confounder affected by the exposure (no red arrow)

$$Y(a,m)\coprod M^{a*}|L$$

```{tikz}
#| label: fig-dag-mediation-assuptions
#| fig-cap: "Assumptions for mediation analysis"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [rectangle, draw=black] (L1) at (0, 1) {t0/L1};
\node [rectangle, draw=black] (L3) at (0, -1) {t0/L3};
\node [ellipse, draw=white] (A) at (3, 0) {t1/A};
\node [rectangle, draw=black](L2) at (6, -1) {t2/L2};
\node [rectangle, draw=white](M) at (9, 0) {t2*/M};
\node [rectangle, draw=white](Y) at (12, 0) {t3/Y};


\draw [-latex, draw=brown] (L1) to (A);
\draw [-latex, draw=brown, bend left] (L1) to (Y);
\draw [-latex, draw=green] (L3) to (A);
\draw [-latex, draw=green] (L3) to (M);
\draw [-latex, draw= gray, dashed] (A) to (M);
\draw [-latex, draw= gray, dashed, bend left] (A) to (Y);
\draw [-latex, draw=red] (A) to (L2);
\draw [-latex, draw=blue] (L2) to (M);
\draw [-latex, draw=blue] (L2) to (Y);
\draw [-latex, draw= gray, dashed] (M) to (Y);





\end{tikzpicture}

```

### Confounder-Treatment Feedback

```{tikz}
#| label: fig-dag-9
#| fig-cap: "Confounder Treatement Feedback"
#| out-width: 80%
#| echo: false


\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (U) at (0, 0) {U};
\node [rectangle, draw=black] (L0) at (2, 0) {t0/L};
\node [rectangle, draw=white] (A1) at (4, 0) {t1/A};
\node [rectangle, draw=black] (Y2) at (6, 0) {t2/Y};
\node [rectangle, draw=black] (L2) at (8, 0) {t2/L};
\node [rectangle, draw=white] (A2) at (10, 0) {t3/A};
\node [rectangle, draw=black] (Y3) at (12, 0) {t4/Y};

\draw [-latex, draw=black] (U) to (L0);
\draw [-latex, draw=black] (L0) to (A1);
\draw [-latex, draw=black] (L2) to (A2);

\draw [-latex, bend right, draw=black] (U) to (Y2);
\draw [-latex, bend right, draw=black] (U) to (L2);
\draw [-latex, bend right, draw=black] (U) to (Y3);

\draw [-latex, bend right, draw=red, dashed] (A1) to (Y3);
\draw [-latex, bend left, draw=red] (A1) to (L2);


\end{tikzpicture}
```

By the end of this section you will:

1.  Understand the causal assumptions implied by the factor analytic interpretation of the formative and reflective models.

2.  Be able to distinguish between statistical and structural interpretations of these models.

3.  Understand why Vanderweele thinks consistent causal estimation is possible using the theory of multiple versions of treatments for constructs with multiple indicators

## Two ways of thinking about measurement in psychometric research.

In psychometric research, formative and reflective models describe the relationship between latent variables and their respective indicators. VanderWeele discusses this in the assigned reading for this week [@vanderweele2022].

### Reflective Model (Factor Analysis)

In a reflective measurement model, also known as an effect indicator model, the latent variable is understood to cause the observed variables. In this model, changes in the latent variable cause changes in the observed variables. Each indicator (observed variable) is a 'reflection' of the latent variable. In other words, they are effects or manifestations of the latent variable. These relations are presented in @fig-dag-latent-1.

The reflective model may be expressed:

$$X_i = \lambda_i \eta + \varepsilon_i$$

Here, $X_i$ is an observed variable (indicator), $\lambda_i$ is the factor loading for $X_i$, $\eta$ is the latent variable, and $\varepsilon_i$ is the error term associated with $X_i$. It is assumed that all the indicators are interchangeable and have a common cause, which is the latent variable $\eta$.

In the conventional approach of factor analysis, the assumption is that a common latent variable is responsible for the correlation seen among the indicators. Thus, any fluctuation in the latent variable should immediately lead to similar changes in the indicators.These assumptions are presented in @fig-dag-latent-1.

```{tikz}
#| label: fig-dag-latent-1
#| fig-cap: "Reflective model: assume univariate latent variable η giving rise to indicators X1...X3. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 80%
#| echo: false
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}



\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (eta) at (0, 0) {$\eta$};
\node [rectangle, draw=white] (X1) at (6, 1) {X$_1$};
\node [rectangle, draw=white] (X2) at (6, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (6, -1) {X$_n$};

\draw [-latex, draw=black] (eta) to (X1);
\draw [-latex, draw=black] (eta) to (X2);
\draw [-latex, draw=black] (eta) to (Xn);

\end{tikzpicture}
```

### The Formative Model (Factor Analysis)

In a formative measurement model, the observed variables are seen as causing or determining the latent variable. Here again, there is a single latent variable. However this latent variable is taken to be an effect of the underlying indicators. These relations are presented in @fig-dag-latent-formative_0.

The formative model may be expressed:

$$\eta = \sum_i\lambda_i X_i + \varepsilon$$

In this equation, $\eta$ is the latent variable, $\lambda_i$ is the weight for $X_i$ (the observed variable), and $\varepsilon$ is the error term. The latent variable $\eta$ is a composite of the observed variables $X_i$.

In the context of a formative model, correlation or interchangeability between indicators is not required. Each indicator contributes distinctively to the latent variable. As such, a modification in one indicator doesn't automatically imply a corresponding change in the other indicators.

```{tikz}
#| label: fig-dag-latent-formative_0
#| fig-cap: "Formative model:: assume univariate latent variable from which the indicators X1...X3 give rise. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 80%
#| echo: false
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}



\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=black] (X1) at (0, 1) {X1};
\node [rectangle, draw=white] (X2) at (0, 0) {$\vdots$};
\node [rectangle, draw=black] (Xn) at (0, -1) {X$_n$};
\node [rectangle, draw=white] (eta) at (6, 0) {$\eta$};


\draw [-latex, draw=black] (X1) to (eta);
\draw [-latex, draw=black] (X2) to (eta);
\draw [-latex, draw=black] (Xn) to (eta);

\end{tikzpicture}
```

## Structural Interpretation of the formative model and reflective models (Factor Analysis)

> However, this analysis of reflective and formative models assumed that the latent η was causally efficacious. This may not be the case (VanderWeele 2022)

VanderWeele distinguishes between statistical and structural interpretations of the equations preesented above.

1.  **Statistical Model:** a mathematical construct that shows how observable variables, also known as indicators, are related to latent or unseen variables. These are presented in the equations above

2.  **Structural Model:** A structural model refers to the causal assumptions or hypotheses about the relationships among variables in a statistical model. The assumptions of the factor analytic tradition are presented in @fig-dag-latent-formative_0 and @fig-dag-latent-1 are structural models.

We have seen that the **reflective model** statistically implies that the observed variables (indicators) are reflections or manifestations of the latent variable, expressed as $X_i = \lambda_i \eta + \varepsilon_i$. However, the factor analytic tradition makes the additional structural assumption that a univariate latent variable is causally efficacious and influences the observed variables, as in: @fig-structural-assumptions-reflective-model.

We have also seen that the **formative model** statistically implies that the latent variable is formed or influenced by the observed variables, expressed as $\eta = \sum_i\lambda_i X_i + \varepsilon$. However, the factor analytic tradition makes the additional assumption that the observed variables give rise to a univariate latent variable, as in @fig-dag-reflective-assumptions_note.

```{tikz}
#| label: fig-structural-assumptions-reflective-model
#| fig-cap: "Reflective Model: causal assumptions. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=black] (L) at (0, 0) {L};
\node [rectangle, draw=white] (eta) at (2, 0) {$\eta$};
\node [rectangle, draw=white] (X1) at (4, 1) {X1};
\node [rectangle, draw=white] (X2) at (4, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (4, -1) {X$_n$};
\node [rectangle, draw=white] (A) at (6, 0) {A};

\node [rectangle, draw=white] (Y) at (8, 0) {Y};

\draw [-latex, bend right=80, draw=black] (L) to (Y);
\draw [-latex, draw=black] (L) to (eta);
\draw [-latex, bend left=90, draw=red] (eta) to (Y);
\draw [-latex, draw=black] (eta) to (X1);
\draw [-latex, draw=black] (eta) to (X2);
\draw [-latex, draw=black] (eta) to (Xn);

\draw [-latex, draw=black] (X1) to (A);
\draw [-latex, draw=black] (X2) to (A);
\draw [-latex, draw=black] (Xn) to (A);

\end{tikzpicture}
```

```{tikz}
#| label: fig-dag-reflective-assumptions_note
#| fig-cap: "Formative model: causal assumptions. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [draw=black] (L) at (0, 0) {L};
\node [rectangle, draw=black] (X1) at (3, 1) {X1};
\node [rectangle, draw=white] (X2) at (3, 0) {$\vdots$};
\node [rectangle, draw=black] (Xn) at (3, -1) {X$_n$};
\node [rectangle, draw=white] (eta) at (6, 0) {$\eta$};
\node [rectangle, draw=white] (Y) at (9, 0) {Y};



\draw [-latex, draw=black] (X1) to (eta);
\draw [-latex, draw=black] (X2) to (eta);
\draw [-latex, draw=black] (Xn) to (eta);
\draw [-latex, bend right=80, draw=black] (L) to (Y);
\draw [-latex, draw=black, bend left = 80] (L) to (eta);
\draw [-latex, draw=red] (eta) to (Y);


\end{tikzpicture}
```

The reflective model implies $X_i = \lambda_i \eta + \varepsilon_i$, which factor analysts take to imply @fig-structural-assumptions-reflective-model.

The formative model implies $\eta = \sum_i\lambda_i X_i + \varepsilon$, which factor analysts take to imply @fig-dag-reflective-assumptions_note.

## Problems with the structural interpretations of the reflective and formative factor models.

While the statistical model $X_i = \lambda_i \eta + \varepsilon_i$ aligns with @fig-structural-assumptions-reflective-model, it also alings with @fig-dag-formative-assumptions-compatible. Cross-sectional data, unfortunately, do not provide enough information to discern between these different structural interpretations.

Similarly, the statistical model $\eta = \sum_i\lambda_i X_i + \varepsilon$ agrees with @fig-dag-reflective-assumptions_note but it also agrees with @fig-dag-reflectiveassumptions-compatible_again. Here too, cross-sectional data cannot decide between these two potential structural interpretations.

There are other, compatible structural interprestations as well. The formative and reflective conceptions of factor analysis are compatible with indicators having causal effects as shown in @fig_dag_multivariate_reality_again. They are also compatible with a multivariate reality giving rise to multiple indicators as shown in @fig-dag-multivariate-reality-bulbulia.

```{tikz}
#| label: fig-dag-formative-assumptions-compatible
#| fig-cap: "Formative model is compatible with indicators causing outcome.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false


\begin{tikzpicture}[{every node/.append style}=draw]
%\node [rectangle, draw=white] (L) at (0, 0) {L};
\node [rectangle, draw=white] (eta) at (2, 0) {$\eta$};
\node [rectangle, draw=white] (X1) at (4, 1) {X1};
\node [rectangle, draw=white] (X2) at (4, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (4, -1) {X$_n$};
\node [rectangle, draw=white] (Y) at (6, 0) {Y};

%\draw [-latex, bend right=80, draw=black] (L) to (Y);
%\draw [-latex, bend left=60, draw=black] (L) to (X1);
%\draw [-latex, bend left=40, draw=black] (L) to (X2);
%\draw [-latex, bend right=60, draw=black] (L) to (Xn);

\draw [-latex, draw=black] (eta) to (X1);
\draw [-latex, draw=black] (eta) to (X2);
\draw [-latex, draw=black] (eta) to (Xn);

\draw [-latex, draw=red] (X1) to (Y);
\draw [-latex, draw=red] (X2) to (Y);
\draw [-latex, draw=red] (Xn) to (Y);


\end{tikzpicture}
```

```{tikz}
#| label: fig-dag-reflectiveassumptions-compatible_again
#| fig-cap: "Reflective model is compatible with indicators causing the outcome. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


%\node [draw=white] (L) at (0, 0) {L};
\node [rectangle, draw=white] (X1) at (2, 1) {X1};
\node [rectangle, draw=white] (X2) at (2, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (2, -1) {X$_n$};
\node [rectangle, draw=white] (eta) at (4, 0) {$\eta$};
\node [rectangle, draw=white] (Y) at (6, 0) {Y};



\draw [-latex, draw=black] (X1) to (eta);
\draw [-latex, draw=black] (X2) to (eta);
\draw [-latex, draw=black] (Xn) to (eta);
%\draw [-latex, bend left=80, draw=black] (L) to (Y);
\draw [-latex, bend left=60, draw=red] (X1) to (Y);
\draw [-latex, bend left=40, draw=red] (X2) to (Y);
\draw [-latex, bend right =60,  draw=red] (Xn) to (Y);



\end{tikzpicture}
```

```{tikz}
#| label: fig_dag_multivariate_reality_again
#| fig-cap: "Multivariate reality gives rise to the indicators, from which we draw our measures. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [draw=white] (eta1) at (0, 1) {$\eta_1$};
\node [rectangle, draw=white] (eta2) at (0, 0) {$\vdots$};
\node [rectangle, draw=white] (etan) at (0, -1) {$\eta_n$};
\node [rectangle, draw=white] (X1) at (2, 1) {X$_1$};
\node [rectangle, draw=white] (X2) at (2, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (2, -1 ) {X$_n$};
\node [rectangle, draw=white] (A) at (4, 0 ) {A};
\node [rectangle, draw=white] (Y) at (6, 0 ) {Y};



\draw [-latex, draw=black] (eta1) to (X1);
\draw [-latex, draw=black] (eta2) to (X2);
\draw [-latex, draw=black] (etan) to (Xn);

\draw [-latex, draw=black] (X1) to (A);
\draw [-latex, draw=black] (X2) to (A);
\draw [-latex, draw=black] (Xn) to (A);
\draw [-latex, bend left=80, draw=red] (eta1) to (Y);
\draw [-latex, bend right=80, draw=red] (etan) to (Y);



\end{tikzpicture}
```

```{tikz}
#| label: fig-dag-multivariate-reality-bulbulia
#| fig-cap: "Although we take our constructs, A, to be functions of indicators, X, such that, perhaps only one or several of the indicators are efficacious.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [draw=white] (eta1) at (0, 1) {$\eta_1$};
\node [rectangle, draw=white] (eta2) at (0, 0) {$\vdots$};
\node [rectangle, draw=white] (etan) at (0, -1) {$\eta_n$};
\node [rectangle, draw=white] (X1) at (2, 1) {X$_1$};
\node [rectangle, draw=white] (X2) at (2, 0) {$\vdots$};
\node [rectangle, draw=white] (Xn) at (2, -1 ) {X$_n$};
\node [rectangle, draw=white] (Y) at (6, 0 ) {Y};



\draw [-latex, draw=black] (eta1) to (X1);
\draw [-latex, draw=black] (eta2) to (X2);
\draw [-latex, draw=black] (etan) to (Xn);


\draw [-latex, bend left=80, draw=red] (eta1) to (Y);



\end{tikzpicture}
```

VanderWeele's key observation is this:

**While cross-sectional data can provide insights into the relationships between variables, they cannot conclusively determine the causal direction of these relationships.**

This results is worrying. The structural assumptions of factor analysis underpin nearly all psychological research. If the cross-sectional data used to derive factor structures cannot decide whether the structural interpretations of factor models are accurate, where does that leave us?

More worrying still, VanderWeele discusses several longitudinal tests for structural interpretations of univariate latent variables that do not pass.

Where does that leave us? In psychology we have heard about a replication crisis. We might describe the reliance on factor models as an aspect of a much larger, and more worrying "causal crisis"

## Review of the theory of multiple versions of treatment

```{tikz}
#| label: fig_dag_multiple_version_treatment_dag
#| fig-cap: "Multiple Versions of treatment. Heae, A is regarded to bbe a coarseneed version of K"
#| out-width: 100%
#| echo: false


\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}



\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=black] (L0) at (0, 0) {L};
\node [rectangle, draw=white] (K1) at (2, 0) {K};
\node [rectangle, draw=black] (A1) at (4, 0) {A};
\node [rectangle, draw=white] (Y2) at (6, 0) {Y$_k$};

\draw [-latex, draw=black] (L0) to (K1);
\draw [-latex, bend right, draw=black] (L0) to (Y2);
\draw [-latex, draw=black] (K1) to (A1);
\draw [-latex, draw=black, bend left] (K1) to (Y2);

\end{tikzpicture}
```

Perhaps not all is lost. VanderWeele looks to the theory of multiple versions of treatment for solace.

Recall, a causal effect is defined as the difference in the expected potential outcome when everyone is exposed (perhaps contrary to fact) to one level of a treatment, conditional on their levels of a confounder, with the expected potential outcome when everyone is exposed to a a different level of a treatement (perhaps contrary to fact), conditional on their levels of a counfounder.

$$ \delta = \sum_l \left( \mathbb{E}[Y|A=a,l] - \mathbb{E}[Y|A=a^*,l] \right) P(l)$$

where $\delta$ is the causal estimand on the difference scale $(\mathbb{E}[Y^0 - Y^0])$.

In causal inference, the multiple versions of treatment theory allows us to handle situations where the treatment isn't uniform, but instead has several variations. Each variation of the treatment, or "version", can have a different impact on the outcome. Consistency is not violated because it is redefined: for each version of the treatment, the outcome under that version is equal to the observed outcome when that version is received. Put differently we may think of the indicator $A$ as corresponding to many version of the true treament $K$. Where conditional independence holds such that there is a absence of confounding for the effect of $K$ on $Y$ given $L$, we have: $Y_k \coprod A|K,L$. This states conditional on $L$, $A$ gives no information about $Y$ once $K$ and $L$ are accounted for. When $Y = Y_k$ if $K = k$ and Y$_k$ is independent of $K$, condition on $L$, then $A$ may be thought of as a coarsened indicator of $K$, as shown in @fig_dag_multiple_version_treatment_dag. We may estimate consistent causal effects where:

$$ \delta = \sum_{k,l} \mathbb{E}[Y_k|l] P(k|a,l) P(l) - \sum_{k,l} \mathbb{E}[Y_k|l] P(k|a^*,l) P(l)$$

The scenario represents a hypothetical randomised trial where within strata of covariates $L$, individuals in one group receive a treatment $K$ version randomly assigned from the distribution of $K$ distribution $(A = 1, L = l)$ sub-population. Meanwhile, individuals in the other group receive a randomly assigned $K$ version from $(A = 0, L = l)$

This theory finds its utility in practical scenarios where treatments seldom resemble each other -- we discussed the example of obesity last week (see: [@vanderweele2013]).

### Reflective and formative measurement models may be approached as multiple versions of treatment

Vanderweele applies the following substitution:

$$\delta = \sum_{\eta,l} \mathbb{E}[Y_\eta|l] P(\eta|A=a+1,l) P(l) - \sum_{\eta,l} \mathbb{E}[Y_\eta|l] P(\eta|A=a,l) P(l)$$

Specifically, we substitue $K$ with $\eta$ from the previous section, and compare the measurement response $A = a + 1$ with $A = a$. We discover that if the influence of $\eta$ on $Y$ is not confounded given $L$, then the multiple versions of reality consistent with the reflective and formative statistical models of reality will not lead to biased estimation. $\delta$ retains its interpretability as a comparison in a hypothetical randomised trial in which the distribution of coarsened measures of $\eta_A$ are balanced within levels of the treatment, conditional on $\eta_L$.

This connection between measurement and the multiple versions of treatment framework provides a hope for consistent causal inference varying reliabilities of measurement.

However, as with the theory of multiple treatments, we might not known how to interpret our results because we don't know the true relationships between our measured indicators and underlying reality.

How can we do better?

```{tikz}
#| label: fig-dag-multiple-version-treatment-applied-measurement
#| fig-cap: "Multiple Versions of treatment applied to measuremen.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false


\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}



\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=black] (L0) at (0, 0) {L};
\node [rectangle, draw=white] (K1) at (2, 0) {$\eta$=K};
\node [rectangle, draw=white] (X1) at (5, 0) {$(X_1, X_2, \dots X_n)$};
\node [rectangle, draw=black] (A1) at (8, 0) {A};
\node [rectangle, draw=white] (Y2) at (10, 0) {Y$_k$};

\draw [-latex, draw=black] (L0) to (K1);
\draw [-latex, bend right, draw=black] (L0) to (Y2);
\draw [-latex, draw=black] (K1) to (X1);
\draw [-latex, draw=black] (X1) to (A1);
%\draw [-latex, draw=white, bend left] (K1) to (Y2); # fix later

\end{tikzpicture}
```

## VanderWeele's model of reality

VanderWeele's article concludes as follows:

> A preliminary outline of a more adequate approach to the construction and use of psychosocial measures might thus be summarized by the following propositions, that I have argued for in this article: (1) Traditional univariate reflective and formative models do not adequately capture the relations between the underlying causally relevant phenomena and our indicators and measures. (2) The causally relevant constituents of reality related to our constructs are almost always multidimensional, giving rise both to our indicators from which we construct measures, and also to our language and concepts, from which we can more precisely define constructs. (3) In measure construction, we ought to always specify a definition of the underlying construct, from which items are derived, and by which analytic relations of the items to the definition are made clear. (4) The presumption of a structural univariate reflective model impairs measure construction, evaluation, and use. (5) If a structural interpretation of a univariate reflective factor model is being proposed this should be formally tested, not presumed; factor analysis is not sufficient for assessing the relevant evidence. (6) Even when the causally relevant constituents of reality are multidimensional, and a univariate measure is used, we can still interpret associations with outcomes using theory for multiple versions of treatment, though the interpretation is obscured when we do not have a clear sense of what the causally relevant constituents are. (7) When data permit, examining associations item-by-item, or with conceptually related item sets, may give insight into the various facets of the construct.

> A new integrated theory of measurement for psychosocial constructs is needed in light of these points -- one that better respects the relations between our constructs, items, indicators, measures, and the underlying causally relevant phenomena. (VanderWeele 2022)

```{tikz}
#| label: fig-dag-multivariate-reality-complete
#| fig-cap: "Multivariate reality gives rise to the latent variables.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\begin{tikzpicture}[{every node/.append style}=draw]


\node [rectangle, draw=white] (R) at (0, 0 ) {$\mathcal{R}$};
\node [rectangle, draw=white] (c) at (2, -1 ) {concepts};
\node [rectangle, draw=white] (cs) at (4, -2 ) {constructs};
\node [rectangle, draw=white] (eta) at (4, 0 ) {$\eta$};
\node [rectangle, draw=white] (X) at (6, 0 ) {(X$_1 \dots$X$_n$)};
\node [rectangle, draw=white] (A) at (8, 0 ) {A};
\node [rectangle, draw=white] (Y) at (10, 0 ) {Y};



\draw [-latex, draw=black, dashed] (R) to (c);
\draw [-latex, draw=black, dashed] (c) to (cs);
\draw [-latex, draw=black] (R) to (eta);
\draw [-latex, draw=black] (eta) to (X);
\draw [-latex, draw=black] (X) to (A);



\draw [-latex, bend left=80, draw=red] (eta) to (Y);



\end{tikzpicture}
```

This seems to me sensible. However, @fig-dag-multivariate-reality-complete this is not a causal graph. The arrows to not clearly represent causal relations. It leaves me unclear about what to practically do.

Let's return to the three wave many-outcomes model described in previous weeks. How should we revise this model in light of measurement theory?

## How theory of dependent and directed measurement error might be usefully employed to develop a pragmatic responses to construct measurement

```{tikz}
#| label: fig-dag-uu-null
#| fig-cap: "Uncorrelated non-differential  measurement error does not bias estimates under the null. Note, however, we assume that L is measured with sufficient precision to block the path from A_eta --> L_eta --> Y_eta, which, otherwise, we would assume to be open."
#| out-width: 100%
#| echo: false
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (UL) at (0, 1) {U$_L$};
\node [rectangle, draw=white] (UA) at (6, 2) {U$_A$};
\node [rectangle, draw=white] (UY) at (9, 3) {U$_Y$};

\node [rectangle, draw=black] (L0) at (3, 1) {L$_{f(X_1\dots X_n)}^{t0}$};
\node [rectangle, draw=black] (A1) at (7, 1) {A$_{f(X_1\dots X_n)}^{t1}$};
\node [rectangle, draw=black] (Y2) at (11, 1) {Y$_{f(X_1\dots X_n)}^{t2}$};

\node [rectangle, draw=white] (Leta0) at (3, 0) {L$^{t0}_\eta$};
\node [rectangle, draw=white] (Aeta1) at (7, 0) {A$^{t1}_\eta$};
\node [rectangle, draw=white] (Yeta2) at (11, 0) {Y$^{t2}_\eta$};


\draw [-latex, draw=black] (UL) to (L0);
\draw [-latex, draw=black,bend left=20] (UA) to (A1);
\draw [-latex, draw=black,bend left=30] (UY) to (Y2);
\draw [-latex, draw=black] (Leta0) to (L0);
\draw [-latex, draw=black] (Leta0) to (Aeta1);
\draw [-latex, draw=black, bend right=30] (Leta0) to (Yeta2);
\draw [-latex, draw=black] (Aeta1) to (A1);
\draw [-latex, draw=black] (Yeta2) to (Y2);


\draw [cor, draw=black, dashed,bend right=80] (UL) to (Leta0);
\draw [cor, draw=black, dashed, bend right = 80] (UA) to (Aeta1);
\draw [cor, draw=black, dashed, bend right = 80] (UY) to (Yeta2);



\end{tikzpicture}
```

Consider a study that seeks to use this dataset to investigate the effect of regular exercise on psychological distress. In contrast to previous graphs, let us allow for latent reality to affect our measurements, as well as the discrepencies between our measurements and true underlying reality. We shall use @fig-dag-uu-null as our initial guide.

We represent the true exercise by $\eta_A$. We represent true psychological distress by $\eta_Y$. Let $\eta_L$ denote a persons true workload, and assume that this state of work affects both levels of excercise and psychological distress.

To bring the model into contact with measurement theory, Let us describe measurements of these latent true underlying realities as functions of multiple indicators: $L_{f(X_1\dots X_n)}$, $A_{f(X_1\dots X_n)}$, and $Y_{f(X_1\dots X_n)}$. These constructs are measured realisations of the underlying true states. We assume that the true states of these variables affect their corresponding measured states, and so draw arrows from $\eta_L\rightarrow{L_{f(X_1\dots X_n)}}$, $\eta_A\rightarrow{A_{f(X_1\dots X_n)}}$, $\eta_Y\rightarrow{Y_{f(X_1\dots X_n)}}$.

We also assume unmeasured sources of error that affect the measurements: $U_{L} \rightarrow$ $L_{f(X_1\dots X_n)}$, $U_{A} \rightarrow$ $A_{f(X_1\dots X_n)}$, and $U_{Y} \rightarrow$ $Y_{f(X_1\dots X_n)}$. That is, we allow that our measured indicators may "see as through a mirror, in darkness," the underlying true reality they hope to capture (Corinthians 13:12). We use $U_{L}$, $U_{A}$ and $U_{Y}$ to denote the unmeasured sources of error in the measured indicators. These are the unknown, and perhaps unknowable, darkness and mirror.

Allow that the true underlying reality represented by the $\eta_{var}$ may be multivariate. Similarly, allow the true underlying reality represented by $U_{var}$ is multivariate.

We now have a causal diagramme that more precisely captures VanderWeele's thinking as presented in @fig-dag-multivariate-reality-complete. In our @fig-dag-uu-null, we have fleshed out $\mathcal{R}$ in a way that may include natural language concepts and scientific language, or constructs, as latent realities and latent unmeasured sources of error in our constructs.

The utility of describing the measurement dynamics using causal graphs is apparrent. We can understand that the measured states, once conditioned upon create *collider biases* which opens path between the unmeasured sources of error and the true underlying state that gives rise to our measurements. This is depicted by a the arrows $U_{var}$ and from $\eta_{var}$ into each $var_{f(X1, X2,\dots X_n)}$

Notice: **where true unmeasured (multivariate) psycho-physical states are related to true unmeasured (multivariate) sources of error in the measurement of those states, the very act of measurement opens pathways to confounding.**

If for each measured construct $var_{f(X1, X2,\dots X_n)}$, the sources of error $U_{var}$ and the unmeasured consituents of reality that give rise to our measures $\eta_{var}$ are uncorrelated with other variables $U\prime_{var}$ and from $\eta\prime_{var}$ and $var\prime_{f(X1, X2,\dots X_n)}$, our estimates may be downwardly biased toward the null. However, d-separation is preserved. Where errors are uncorrelated with true latent realities, there is no new pathway that opens information between our exposure and outcome. Consider the relations presented in @fig-dag-dep-udir-effect-confounders-3wave

```{tikz}
#| label: fig-dag-dep-udir-effect-confounders-3wave
#| fig-cap: "Measurement error opens an additional pathway to confounding if either there are correlated errors, or a directed effect of the exposure on the errors of measured outcome."
#| out-width: 100%
#| echo: false
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}



\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

\tikzset{blackArrowRedTip/.style={
  decoration={markings, mark=at position 1 with {\arrow[red, thick]{latex}}},
  postaction={decorate},
  shorten >=0.4pt}}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (ULAY) at (0, 5) {$U_{L}$};
\node [rectangle, draw=white] (UA) at (5, 4) {$U_{A}$};
\node [rectangle, draw=white] (UY) at (10, 5) {$U_{Y}$};

\node [rectangle, draw=black] (L0) at (0, 2) {L$_{f(X_1\dots X_n)}^{t0}$};
\node [rectangle, draw=black] (A1) at (5, 2) {A$_{f(X_1\dots X_n)}^{t1}$};
\node [rectangle, draw=black] (Y2) at (10, 2) {Y$_{f(X_1\dots X_n)}^{t2}$};
\node [rectangle, draw=white] (Leta0) at (0, 0) {$\eta_L^{t0}$};
\node [rectangle, draw=white] (Aeta1) at (5, 0) {$\eta_A^{t1}$};
\node [rectangle, draw=white] (Yeta2) at (10, 0) {$\eta_Y^{t2}$};


\draw [-latex, draw=red] (ULAY) to (UA);
\draw [-latex, draw=red] (ULAY) to (UY);

\draw [-latex, draw=black] (UA) to (A1);
\draw [-latex, draw=red] (UY) to (Y2);
\draw [-latex, draw=black] (ULAY) to (L0);
\draw [-latex, draw=black] (Leta0) to (L0);
\draw [-latex, draw=black] (Leta0) to (Aeta1);
\draw [-latex, draw=black, bend right=30] (Leta0) to (Yeta2);

\draw [-latex, draw = black] (Aeta1) to (A1);
\draw [-latex, draw=black] (Yeta2) to (Y2);

\draw [-latex, draw=red] (Aeta1) to (UY);
\draw [-latex, draw=red] (Leta0) to (UA);





%\draw [-latex, draw=black] (Leta0) to (UA);



\draw [cor, draw=red, dashed,bend right=80] (ULAY) to (Leta0);
\draw [cor, draw=red, dashed, bend right = 80] (UA) to (Aeta1);
\draw [cor, draw=red, dashed, bend left = 80] (UY) to (Yeta2);

\end{tikzpicture}
```

Here,

$\eta_L \rightarrow L$: We assume that the true workload state affects its measurement. This measurement, however, may be affected by an unmeasured error source, $U_{L}$. Personal perceptions of workload can introduce this error. For instance, a person may perceive their workload differently based on recent personal experiences or cultural backgrounds. Additionally, unmeasured cultural influences like societal expectations of productivity could shape their responses independently of the true workload state. There may be cultural differences - Americans may verstate; the British may present effortless superiority.

$\eta_A \rightarrow A$: When it comes to exercise, the true state may affect the measured frequency (questions about exercise are not totally uninformative). However, this measurement is also affected by an unmeasured source of error, which we denote by $U_{A}$. For example, a cultural shift towards valuing physical health might prompt participants toreport higher activity levels, introducing an error, $U_{A}$.

$\eta_Y \rightarrow Y$: We assume questions about distress are not totally uninformative: actual distress affects the measured distress. However this measurement is subject to unmeasured error: $U_{Y}$. For instance, an increased societal acceptance of mental health might change how distress is reported creating an error, $U_{Y}$, in the measurement of distress. Such norms, moreover, may change over time.

$U_{L} \rightarrow L$, $U_{A} \rightarrow A$, and $U_{Y} \rightarrow Y$: These edges between the nodes indicate how each unmeasured error source can influence its corresponding measurement, leading to a discrepancy between the true state and the measured state.

$U_{L} \rightarrow U_{A}$ and $U_{L} \rightarrow U_{Y}$: These relationships indicate that the error in the stress measurement can correlate with those in the exercise and mood measurements. This could stem from a common cultural bias affecting how a participant self-reports across these areas.

$\eta_A \rightarrow U_{Y}$ and $\eta_L \rightarrow U_{A}$: These relationships indicate that the actual state of one variable can affect the error in another variable's measurement. For example, a cultural emphasis on physical health leading to increased exercise might, in turn, affect the reporting of distress levels, causing an error, $U_{Y}$, in the distress measurement. Similarly, if a cultural trend pushes people to work more, it might cause them to over or underestimate their exercise frequency, introducing an error, $U_{A}$, in the exercise measurement.

### Confounding control by baseline measures of exposure and outcome: Dependent Directed Measurement Error in Three-Wave Panels

1.  We propose a three-wave panel design to control confounding. This design adjusts for baseline measurements of both exposure and the outcome.

2.  Understanding this approach in the context of potential directed and correlated measurement errors gives us a clearer picture of its strengths and limitations.

3.  This three-wave panel design incorporates baseline measurements of both exposure and confounders. As a result, any bias that could come from unmeasured sources of measurement errors should be uncorrelated with their baseline effects.

4.  For instance, if individuals have a social desirability bias at the baseline, they would have to develop a different bias unrelated to the initial one for new bias to occur due to correlated unmeasured sources of measurement errors.

5.  However, we cannot completely eliminate the possibility of such new bias development. There could also be potential new sources of bias from directed effects of the exposure on the error term of the outcome, which can often occur due to panel attrition.

6.  To mitigate this risk, we adjust for panel attrition/non-response using methods like multiple imputation. We also consistently perform sensitivity analyses to detect any unanticipated bias.

7.  Despite these potential challenges, it is worth noting that by including measures of both exposure and outcome at baseline, the chances of new confounding are significantly reduced.

8.  Therefore, adopting this practice should be a standard procedure in multi-wave studies as it substantially minimizes the likelihood of introducing novel confounding factors.

```{tikz}
#| label: fig-dag-dep-udir-effect-confounders-3wave-new
#| fig-cap: "TBA"
#| out-width: 100%
#| echo: false
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}

% Define a simple decoration
\tikzstyle{cor} = [-, dotted, preaction = {decorate}]


\begin{tikzpicture}[{every node/.append style}=draw]

\node [rectangle, draw=white] (ULAY) at (0, 2) {U$_{t0/LAY}$};
\node [rectangle, draw=white] (UA) at (6, 4) {U$_{t1/A}$};
\node [rectangle, draw=white] (UY) at (8, 5) {U$_{t2/Y}$};

\node [rectangle, draw=black] (L0) at (4, 2) {LAY$^{t0}$};
\node [rectangle, draw=black] (A1) at (6, 2) {A$^{t1}$};
\node [rectangle, draw=black] (Y2) at (8, 2) {Y$^{t2}$};
\node [rectangle, draw=white] (Leta0) at (4, 0) {L$^{t0}_\eta$};
\node [rectangle, draw=white] (Aeta1) at (6, 0) {A$^{t1}_\eta$};
\node [rectangle, draw=white] (Yeta2) at (8, 0) {Y$^{t2}_\eta$};


\draw [-latex, draw=black, dotted, bend left = 20] (ULAY) to (UA);
\draw [-latex, draw=black, dotted, bend left = 30] (ULAY) to (UY);

\draw [-latex, draw=black] (UA) to (A1);
\draw [-latex, draw=red] (UY) to (Y2);
\draw [-latex, draw=black] (ULAY) to (L0);
\draw [-latex, draw=black] (Leta0) to (L0);
\draw [-latex, draw=black] (Leta0) to (Aeta1);
\draw [-latex, draw=black, bend right=30] (Leta0) to (Yeta2);

\draw [-latex, draw=black] (Aeta1) to (A1);
\draw [-latex, draw=black] (Yeta2) to (Y2);

\draw [-latex, draw=red] (Aeta1) to (UY);
\draw [-latex, draw=black] (Leta0) to (UA);



\draw [cor, draw=black, dashed,bend right=30] (ULAY) to (Leta0);
\draw [cor, draw=black, dashed, bend right = 30] (UA) to (Aeta1);
\draw [cor, draw=black, dashed, bend right = 100] (ULAY) to (Yeta2);

\end{tikzpicture}
```

### Comment on slow changes

Over long periods of time we can expect additional sources of confounding. Changes in cultural norms and attitudes can occur over the duration of a longitudinal study like the NZAVS, leading to residual confounding. For example, if there is a cultural shift towards increased acceptance of mental health issues, this might change how psychological distress is reported over time, irrespective of baseline responses.

<!-- It's also important to consider that cultural influences might not be entirely captured by the survey. Factors such as societal expectations, shared beliefs, and norms within a culture could influence both exercise behaviour and distress states. These could change over time due to sociocultural shifts, and if these changes aren't accounted for, could lead to residual confounding. For example, a societal shift towards valuing physical health might encourage more exercise independently of baseline responses -->

<!-- 1.  **Baseline Measures and Cultural Differences:** The NZAVS contains data from diverse cultural backgrounds. Therefore, controlling for baseline measures of exercise and distress would also help account for cultural differences that might influence these variables at the outset. For instance, certain cultural groups might have different baseline physical activity or baseline distress states due to various socio-cultural factors. -->

<!-- 2.  **Residual Confounding and Exercise:** Let's consider the construct $\eta_{A}$, representing the true state of exercise behaviour. If we control for baseline exercise, we're adjusting for the initial state of this behaviour. However, there could still be cultural factors that impact how exercise changes over time. For instance, a cultural event or festival that significantly increases physical activity for a certain period might occur. This change might be independent of the baseline state of exercise, thus leading to residual confounding. -->

<!-- 3.  **Residual Confounding and Depression:** Similarly for $\eta_{Y}$, the true state of Depression/Anxiety. Controlling for baseline states adjusts for the initial emotional state. However, cultural factors such as societal norms or expectations about emotional expression could change over time independently of the baseline distress. These changes could result in residual confounding. For example, a significant cultural event might induce communal feelings of joy or sadness, influencing the distress state irrespective of the baseline level. -->

<!-- 4.  **Unmeasured Cultural Factors**: It's also important to consider that cultural influences might not be entirely captured by the survey. Factors such as societal expectations, shared beliefs, and norms within a culture could influence both exercise behaviour and distress states. These could change over time due to sociocultural shifts, and if these changes aren't accounted for, could lead to residual confounding. For example, a societal shift towards valuing physical health might encourage more exercise independently of baseline responses -->

<!-- 5.  **Change over time**: Finally, time itself can be a factor. Changes in cultural norms and attitudes can occur over the duration of a longitudinal study like the NZAVS. If the timing of these changes isn't aligned with the measurement times, this can also lead to residual confounding. For example, if there is a cultural shift towards increased acceptance of mental health issues, this might change how mood is reported over time, irrespective of baseline responses. -->

<!-- 6.  **Directed Measurement Error:** Consider a situation where individuals from certain cultural backgrounds might systematically under-report their physical activity due to societal norms or expectations, introducing a directed measurement error. Similarly, reporting of mood states might also be influenced by cultural perspectives on expressing emotions. These culturally influenced errors in measurement can introduce bias, even after controlling for baseline measures. -->

<!-- 7.  **Undirected Measurement Error:** Undirected errors could also occur due to random variations in understanding or interpreting survey questions across different cultures, introducing variability in the data. If these random errors correlate with the error in measuring other variables (for instance, if misunderstanding of exercise questions correlates with misunderstanding of mood questions), this can introduce bias. -->

<!-- 8.  **Correlated Errors and Cultural Differences:** The culturally influenced measurement errors ($U_{A}$, $U_{Y}$) could be correlated, as the cultural factors influencing the reporting of exercise might also influence the reporting of mood. This correlation between errors introduces further complexity and potential bias. -->

<!-- 9.  **Residual Confounding:** Despite controlling for baseline measures, there can still be residual confounding due to unmeasured cultural factors. For instance, even if we control for baseline exercise and mood, there might still be cultural factors that impact the changes in these variables over time independently of the baseline measures. -->

<!-- In short, controlling for baseline measures in the NZAVS helps to reduce some bias and account for cultural differences that influence the exposure and outcome. However, potential bias due to unmeasured confounding and measurement error, for example, if these are influenced by cultural factors, still remain. -->

10. **Need for Sensitivity Analysis** The Key takehome message is that we must always perform sensitivity analyses because we can never be certain that our confounding control strategy has worked.

## Add Graph on when we might want to condition on a post treatment indicator

## Stray points to address

1.  Structural equation models are not causal diagrammes
2.  Causal diagrammes are non-parametric
3.  Causal diagrammes represent interactions A -- \> Y \<--- B (two arrows into the outcome)
4.  We may distinguish between effect modification and interaction.

## References
